{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"AI Course","text":""},{"location":"module-1/breakdown-of-transformers/","title":"Breakdown of Transformers","text":"<p>Transformers have become the backbone of many modern NLP tasks due to their innovative architecture. Here\u2019s a breakdown of the key components that make them powerful and versatile.</p>"},{"location":"module-1/breakdown-of-transformers/#1-embeddings","title":"1. Embeddings","text":"<p>Embeddings are a way to convert words or tokens into numerical vectors that transformers can process. In NLP, words need to be transformed into a format that a model can work with, and embeddings serve this purpose. Technically, an embedding is a dense vector representation of a word in a continuous vector space, where similar words have closer representations. The idea is to capture semantic meanings and relationships between words. In transformers, the input tokens are first mapped to their corresponding embeddings using a pre-trained embedding layer or through training from scratch.</p> <p>For example, the word \"cat\" might be represented as a 300-dimensional vector in a way that it's closer to \"dog\" than \"car.\" Embeddings allow transformers to understand and differentiate words based on context and usage, rather than just syntactic similarities. A key advantage of embeddings is their ability to capture relationships beyond simple word matching, like capturing polysemy (words with multiple meanings) in a single vector space. However, they have limitations, such as not inherently understanding out-of-vocabulary words without retraining the embeddings or using dynamic methods like subword tokenization, as seen in BERT and GPT models.</p>"},{"location":"module-1/breakdown-of-transformers/#2-positional-encoding","title":"2. Positional Encoding","text":"<p>Positional encoding is crucial in transformers because, unlike recurrent models, transformers don\u2019t process inputs in sequence by default\u2014they process tokens in parallel. Positional encoding injects information about the position of each token in the input sequence, allowing the model to understand the order of words. This is achieved by adding positional vectors to the input embeddings. These vectors use a combination of sine and cosine functions at varying frequencies, allowing the model to distinguish between positions in the sequence. For example, a word at the start of a sentence has a different positional encoding than the same word at the end. This mechanism is key to preserving the sequence structure without relying on recurrent connections, enabling transformers to handle long-range dependencies more effectively.</p>"},{"location":"module-1/breakdown-of-transformers/#3-attention-mechanism","title":"3. Attention Mechanism","text":"<p>The attention mechanism is the core innovation behind transformers. It allows the model to focus on different parts of the input sequence when making predictions, rather than processing all input tokens equally. Technically, the mechanism computes a set of attention scores that determine how much influence each token should have when processing a given token. In transformers, this is implemented using the scaled dot-product attention formula:</p> <p>[ \\text{Attention}(Q, K, V) = \\text{softmax}\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V ]</p> <p>Here, (Q) (Query), (K) (Key), and (V) (Value) are matrices derived from the input embeddings. The dot product of queries and keys calculates how relevant a key is to a query, and the softmax function normalizes these scores into probabilities. Multiplying these scores by the value vectors allows the model to create a context-aware representation of the input tokens.</p> <p>The self-attention mechanism in transformers means each token attends to every other token, including itself. This results in capturing dependencies regardless of their distance in the input sequence, which is a massive advantage over models like RNNs that struggle with long-range dependencies. Multi-head attention is an extension of this mechanism, where the model learns different aspects of the input through multiple sets of queries, keys, and values, enhancing the model\u2019s ability to capture various linguistic features.</p> <p>Advantages and Disadvantages:</p> <ul> <li>Advantages: Enables parallel processing, captures complex dependencies, and significantly improves context understanding.</li> <li>Disadvantages: Computationally intensive, especially as sequence length grows, due to the need to calculate attention scores between all token pairs.</li> </ul> <p>Examples of Use:</p> <ul> <li>In machine translation, attention helps the model focus on the relevant parts of the source sentence for each word it generates in the target sentence.</li> <li>In text generation, attention ensures that the generated text remains contextually coherent by maintaining focus on pertinent parts of the input.</li> </ul>"},{"location":"module-1/breakdown-of-transformers/#4-add-and-norm","title":"4. Add and Norm","text":"<p>The Add and Norm layer is a component of transformer architecture that helps stabilize and optimize the training process. In each sub-layer (like attention and feed-forward), a residual connection is applied, which involves adding the input of the sub-layer to its output. This \"Add\" step helps mitigate the problem of vanishing gradients, allowing deeper networks to be trained effectively. Following the addition, the result is passed through a layer normalization process, which normalizes the summed output across features. This normalization step helps to stabilize the learning process by reducing internal covariate shift, where the distribution of layer inputs changes during training, ensuring that each layer receives input with zero mean and unit variance.</p>"},{"location":"module-1/breakdown-of-transformers/#5-feed-forward","title":"5. Feed Forward","text":"<p>Each transformer layer includes a feed-forward neural network applied to each position separately and identically. This component consists of two linear transformations with a ReLU activation in between. The purpose is to further process the output from the attention mechanism by adding a non-linear transformation. Mathematically, it\u2019s expressed as:</p> <p>[ \\text{FFN}(x) = \\max(0, xW_1 + b_1)W_2 + b_2 ]</p> <p>where (W_1, W_2) are weight matrices, and (b_1, b_2) are biases. This feed-forward step allows the model to mix information across different dimensions and add non-linearity, which is crucial for complex decision boundaries. Since the same feed-forward network is applied at every position, it maintains the parallel nature of the transformer architecture.</p> <p>Advantages: Efficient parallel processing, simple to implement, and provides a non-linear transformation that enriches the learned representations.</p> <p>Disadvantages: It does not consider positional information directly and relies entirely on prior mechanisms like attention and positional encodings.</p>"},{"location":"module-1/breakdown-of-transformers/#6-softmax-layer","title":"6. Softmax Layer","text":"<p>The Softmax layer is typically used at the final stage of a transformer\u2019s output to produce probability distributions over the possible outputs, making it essential for tasks like classification, sequence generation, and token prediction. In classification tasks, the softmax function converts the raw scores (logits) output by the network into probabilities that sum to one. Mathematically, for a set of scores (z), the softmax function for the (i)-th class is:</p> <p>[ \\text{Softmax}(z_i) = \\frac{e^{z_i}}{\\sum_{j} e^{z_j}} ]</p> <p>This makes it straightforward to interpret the output as the most likely prediction. In the context of transformers, particularly in language models, the softmax layer is crucial in determining the next word in a sequence during text generation by selecting the token with the highest probability.</p> <p>Advantages: Provides interpretable outputs, suitable for making final decisions in classification and generation tasks.</p> <p>Disadvantages: Can be prone to producing overconfident predictions, especially in cases where the model hasn\u2019t been adequately regularized or when handling ambiguous inputs.</p> <p>These components collectively form the backbone of the transformer architecture, each playing a specific role in handling different aspects of sequence processing and making transformers one of the most powerful tools in NLP today.</p>"},{"location":"module-1/intro-to-transformers/","title":"Introduction to Transformers","text":""},{"location":"module-1/intro-to-transformers/#definition","title":"Definition","text":"<p>A transformer model is a neural network that learns context and thus meaning by tracking relationships in sequential data like the words in this sentence.</p> <p>Transformer models apply an evolving set of mathematical techniques, called attention or self-attention, to detect subtle ways even distant data elements in a series influence and depend on each other.</p> <p>First described in\u00a0a 2017 paper\u00a0from Google, transformers are among the newest and one of the most powerful classes of models invented to date. They\u2019re driving a wave of advances in machine learning some have dubbed transformer AI.</p> <p>(from NVIDIA)</p>"},{"location":"module-1/intro-to-transformers/#applications-of-transformers","title":"Applications of Transformers","text":"<p>Transformers have revolutionized natural language processing (NLP), enabling machines to understand and generate human-like text. Let\u2019s dive into some key applications of transformers in real-world scenarios.</p>"},{"location":"module-1/intro-to-transformers/#text-generation","title":"Text Generation","text":"<p>Transformers, especially models like GPT-4, Claude Sonnet 3.5 are widely used for text generation. This means they can create coherent and contextually relevant text based on a given prompt. For example, transformer can be used to generate content such as articles, marketing copies, or social media posts. They are also being used for highly personalised content such as emails, LinkedIn/X messages etc with the required style and tone. Another cool application is in creative writing\u2014authors can get suggestions for story continuations or even dialogue generation for characters, sparking creativity and saving time.</p>"},{"location":"module-1/intro-to-transformers/#summarization","title":"Summarization","text":"<p>Summarization is about condensing information while preserving its core message. For instance, news websites/apps use summarization models to create brief versions of long articles, allowing readers to quickly grasp the main points. In a business setting, imagine sifting through lengthy reports or customer feedback forms\u2014summarization tools can quickly generate executive summaries, making it easier for decision-makers to stay informed without drowning in data. Another practical use is in summarizing legal documents or academic papers, where brevity and accuracy are crucial.</p>"},{"location":"module-1/intro-to-transformers/#question-answering","title":"Question Answering","text":"<p>Question answering (QA) models allow users to ask questions in natural language and get precise answers from a given context. LLMs are more and more being used by mainstream AI assistants such as Google Assistant and Siri. In a more specialized application, companies are using QA models to create intelligent chatbots for customer support, where the bot can provide accurate responses based on a knowledge base or documentation. For example, a QA model can help troubleshoot common software issues for users or even assist in navigating complex medical or technical documents by pinpointing answers to user-specific queries.</p>"},{"location":"module-1/intro-to-transformers/#named-entity-recognition-ner","title":"Named Entity Recognition (NER)","text":"<p>NER involves identifying and categorizing entities in text, such as names, dates, locations, and organizations. Transformers can perform NER tasks with high accuracy, making them invaluable in fields like finance, where extracting key information from financial reports, news, or even tweets can provide a competitive edge. For example, an investment firm might use NER to pull out company names and significant events from a news feed, helping analysts quickly spot opportunities or risks. Similarly, NER is used in healthcare to extract relevant patient information from clinical notes, streamlining administrative tasks and improving data management.</p>"},{"location":"module-1/intro-to-transformers/#sentiment-analysis","title":"Sentiment Analysis","text":"<p>Sentiment analysis identifies the emotional tone behind a piece of text. Businesses use sentiment analysis models built on transformers to gauge customer opinions on their products, services, or even their brand in general. For instance, a company might use this technology to analyze reviews or social media mentions to understand customer satisfaction and adjust their strategies accordingly. Another real-life use case is in market research\u2014brands can assess public sentiment about competitors, trending topics, or industry shifts, providing insights that can inform product development or marketing campaigns.</p>"},{"location":"module-1/intro-to-transformers/#translation","title":"Translation","text":"<p>Transformers have set new benchmarks in machine translation, outperforming traditional rule-based and statistical models. Services like Google Translate use transformer-based models to provide translations that are more accurate and contextually appropriate. Beyond everyday use, translation models are crucial for global businesses operating across multiple regions. For example, e-commerce platforms rely on these models to translate product descriptions, reviews, and customer queries into various languages, enhancing user experience and accessibility.</p>"},{"location":"module-1/intro-to-transformers/#zero-shot-classification","title":"Zero-Shot Classification","text":"<p>Zero-shot classification is a game-changer\u2014it allows a model to classify data into categories it hasn\u2019t explicitly been trained on. This is particularly useful when new categories emerge frequently, like in news reporting or social media monitoring. For example, a news aggregator might use zero-shot classification to tag articles with topics not predefined in its system, improving content organization and retrieval. Another application is in content moderation, where a model might flag inappropriate content based on criteria it hasn\u2019t specifically been trained on, providing a more flexible and scalable approach to content management. This adaptability makes zero-shot classification highly valuable in dynamic environments where training data is sparse or constantly evolving.</p>"},{"location":"module-1/intro-to-transformers/#types-of-transformers","title":"Types of Transformers","text":"<p>Understanding the various types of transformers is crucial to grasp how they fit into different AI applications. Let\u2019s break down some key distinctions: encoder vs. decoder models, open vs. closed source models, and small vs. large language models.</p>"},{"location":"module-1/intro-to-transformers/#encoder-vs-decoder-models","title":"Encoder vs. Decoder Models","text":"<p>Technically, transformer models are divided into encoders, decoders, or a combination of both. Encoder models, like BERT (Bidirectional Encoder Representations from Transformers), are designed to understand and process input data by learning contextual representations of text. They excel in tasks that require understanding and classification, such as sentiment analysis and named entity recognition. Encoder models process input data in a parallel fashion, making them efficient and highly scalable.</p> <p>Decoder models, such as GPT (Generative Pre-trained Transformer), focus on generating text. They take input and predict subsequent tokens, making them ideal for tasks like text generation, translation, and summarization. Decoder models are autoregressive, generating text one token at a time, which makes them slower compared to encoders.</p> <p>Advantages and Disadvantages:</p> <ul> <li>Encoder Models:</li> <li>Advantages: Great for understanding text and classification tasks, efficient in parallel processing.</li> <li>Disadvantages: Limited in generative tasks; they don\u2019t generate new text beyond what is available in the input.</li> <li>Decoder Models:</li> <li>Advantages: Excellent for generative tasks like text completion and creation.</li> <li>Disadvantages: Slower due to sequential processing, can be less efficient and more computationally intensive.</li> </ul> <p>Examples:</p> <ul> <li>Encoder: ALBERT,  BERTDistilBERT ELECTRA RoBERTa</li> <li>Decoder: GPT-3, GPT-4, Anthropic Claude Models, Google Gemini Models</li> <li>Both: - BART mBART Marian T5</li> </ul>"},{"location":"module-1/intro-to-transformers/#open-vs-closed-source-models","title":"Open vs. Closed Source Models","text":"<p>Open source models are available to the public, allowing anyone to inspect, modify, and use the model as they see fit. Examples include models like BERT, GPT-2, and T5, which are accessible through platforms like Hugging Face and GitHub. Open source models are excellent for education, experimentation, and community-driven improvements. They foster innovation because developers can build upon existing models, customize them for specific tasks, and share their findings.</p> <p>Closed source models, on the other hand, are proprietary and not publicly available for direct use or modification. These models are often developed by private companies, such as OpenAI\u2019s GPT-3 (initially closed) and Google's Bard. Closed source models may offer superior performance or access to more sophisticated datasets, but they come with limitations regarding transparency, customization, and cost.</p> <p>Advantages and Disadvantages:</p> <ul> <li>Open Source:</li> <li>Advantages: Promotes transparency, collaboration, and innovation. Free to use and customize.</li> <li>Disadvantages: May not be as optimized or trained on the most recent or expansive datasets. Security and bias issues might be prevalent.</li> <li>Closed Source:</li> <li>Advantages: Often backed by significant computational resources and proprietary data, potentially leading to superior performance.</li> <li>Disadvantages: Lack of transparency, limited customizability, and often expensive.</li> </ul> <p>Examples:</p> <ul> <li>Open Source: BERT, GPT-2, Llama 2, Llama 3</li> <li>Closed Source: GPT-4, Gemini, Claude</li> </ul>"},{"location":"module-1/intro-to-transformers/#small-vs-large-language-models","title":"Small vs. Large Language Models","text":"<p>Language models can vary dramatically in size, usually measured by the number of parameters\u2014the components that a model learns from data. Small language models might have millions to a few billion parameters, whereas large language models, like GPT-3 or GPT-4, have hundreds of billions or even trillions of parameters. Small models are often more lightweight, easier to deploy, and require less computational power, making them suitable for applications where resources are limited or speed is essential.</p> <p>Large models, however, are capable of understanding and generating text with much higher complexity and nuance. They excel in handling a broader range of tasks and understanding subtle language variations due to their extensive training on massive datasets. However, they demand substantial computational resources, both in training and inference, and can be cost-prohibitive for many use cases.</p> <p>Advantages and Disadvantages:</p> <ul> <li>Small Models:</li> <li>Advantages: Faster, more resource-efficient, and easier to deploy on smaller devices or in low-latency applications.</li> <li>Disadvantages: Limited in complexity and understanding; may struggle with more nuanced tasks or generate lower-quality text.</li> <li>Large Models:</li> <li>Advantages: Superior performance in complex tasks, capable of generalizing across a wide range of topics and languages.</li> <li>Disadvantages: High computational and financial cost, slower inference times, and potentially more prone to privacy and security concerns.</li> </ul> <p>Examples:</p> <ul> <li>Small Models: DistilBERT, TinyBERT.</li> <li>Large Models: GPT-3, GPT-4, LLaMA.</li> </ul> <p>By understanding these distinctions, one can better decide which transformer models suit specific applications and the trade-offs involved in each choice.</p>"},{"location":"module-1/nlp-before-transformers/","title":"NLP Before Transformers","text":""},{"location":"module-1/nlp-before-transformers/#rnns-recurrent-neural-networks","title":"RNNs (Recurrent Neural Networks)","text":"<p>RNNs, or Recurrent Neural Networks, are a type of neural network designed for sequential data, where the current output depends not just on the current input, but also on previous inputs. This is achieved by maintaining a hidden state that captures information about previous time steps. At each step, the hidden state is updated based on the current input and the previous hidden state, allowing the network to learn dependencies over time. RNNs are commonly used for tasks like language modeling, speech recognition, and time series forecasting, where understanding the context of prior data points is crucial. However, standard RNNs struggle with long-term dependencies due to issues like vanishing gradients, where the influence of earlier time steps diminishes significantly as the sequence length increases, limiting their ability to remember information over extended periods.</p>"},{"location":"module-1/nlp-before-transformers/#lstm-long-short-term-memory","title":"LSTM (Long Short-Term Memory)","text":"<p>LSTM, or Long Short-Term Memory, is a specialized form of RNN designed to address the problem of long-term dependency retention that standard RNNs face. LSTMs introduce a gating mechanism\u2014consisting of input, forget, and output gates\u2014that controls the flow of information through the network. These gates regulate which information is added to the cell state (the memory of the network), which information is removed, and what part of the cell state is used to produce the output. By doing so, LSTMs can maintain and update relevant information over longer periods, effectively mitigating the vanishing gradient problem.</p> <p>LSTMs are particularly useful in tasks that require understanding and retaining long-term dependencies, such as text generation, machine translation, and speech recognition. For example, in language translation, understanding the context of a word within a longer sentence is crucial for accurate translation. LSTMs enable the model to keep track of this context more effectively than standard RNNs, making them a popular choice in NLP before the rise of transformer-based models. However, despite these improvements, LSTMs can still struggle with very long sequences and require more computational resources than simpler RNNs.</p>"},{"location":"module-1/nlp-before-transformers/#comparison-with-transformers","title":"Comparison with Transformers","text":"<p>Transformers fundamentally differ from RNNs and LSTMs in how they handle sequential data. While RNNs and LSTMs process sequences step-by-step (sequentially), transformers leverage an attention mechanism that allows them to process entire sequences in parallel. This key distinction leads to several advantages and disadvantages when comparing transformers with RNNs and LSTMs.</p> <p>Advantages of Transformers:</p> <ul> <li>Parallel Processing: Transformers handle data in parallel, making them significantly faster, especially for long sequences, as there\u2019s no need to wait for one step to complete before processing the next.</li> <li>Handling Long-Range Dependencies: Transformers excel at capturing long-range dependencies because their self-attention mechanism evaluates relationships between all tokens in a sequence at once, rather than relying on sequential processing where earlier information can be diluted.</li> <li>Scalability: With the ability to process large datasets efficiently, transformers can be scaled up with more parameters and data, improving performance on complex tasks.</li> </ul> <p>Disadvantages of Transformers:</p> <ul> <li>Computational Intensity: The parallel nature of transformers, combined with the need to calculate attention scores between all token pairs, makes them more computationally intensive. They require more memory and processing power compared to RNNs and LSTMs, particularly as sequence length increases.</li> <li>Data-Hungry: Transformers require large amounts of data to train effectively, which can be a limiting factor in domains with less available data.</li> </ul> <p>Advantages of RNNs and LSTMs:</p> <ul> <li>Lower Computational Cost: RNNs and LSTMs, particularly when not dealing with extremely long sequences, can be less demanding in terms of computational resources, making them suitable for smaller-scale applications or where parallel processing isn\u2019t a priority.</li> <li>Sequential Learning: For tasks where step-by-step processing mirrors the nature of the problem (like streaming data or real-time predictions), RNNs and LSTMs can be more intuitive and easier to implement. They are much better at tasks such as stock price prediction compared to Transformer models</li> </ul> <p>Disadvantages of RNNs and LSTMs:</p> <ul> <li>Slower for Long Sequences: The sequential nature of RNNs and LSTMs makes them slower for long sequences, as each step depends on the previous one.</li> <li>Difficulty with Long-Term Dependencies: Despite LSTM\u2019s improvements, both RNNs and LSTMs can still struggle with very long-term dependencies compared to transformers.</li> </ul> <p>While transformers generally outperform RNNs and LSTMs on a wide range of tasks due to their ability to handle long-term dependencies and parallel processing, they do so at a higher computational cost and with a need for large amounts of data. RNNs and LSTMs still hold value in specific contexts, particularly when computational resources are limited or when the problem inherently benefits from sequential learning.</p>"},{"location":"module-2/introduction/","title":"Introduction","text":"In\u00a0[2]: Copied! <pre>prompt_template = \"\"\"\nYou are a helpful assistant that provides accurate and concise answers to questions based on current news articles.\n\n### Context:\n{context}\n\n### Input:\n{input}\n\n### Response Format:\n{response_format}\n\"\"\"\n\ncontext = \"Yesterday (on 12/01/2011), the stock market crashed due to the ongoing trade war between the US and China. The Dow Jones Industrial Average dropped by 800 points, the worst single-day drop of the year. Investors are concerned about the impact of the trade war on the global economy. The US President has announced new tariffs on Chinese goods, and China has responded with retaliatory measures. The trade tensions have escalated, leading to fears of a prolonged economic downturn.\"\nquestion = \"What caused the stock market crash yesterday?\"\n\nresponse_format = {\n    \"response\": \"\",\n    \"date\": \"\",\n}\n\nprompt = prompt_template.format(context=context, input=question, response_format=response_format)\nprint(prompt)\n</pre> prompt_template = \"\"\" You are a helpful assistant that provides accurate and concise answers to questions based on current news articles.  ### Context: {context}  ### Input: {input}  ### Response Format: {response_format} \"\"\"  context = \"Yesterday (on 12/01/2011), the stock market crashed due to the ongoing trade war between the US and China. The Dow Jones Industrial Average dropped by 800 points, the worst single-day drop of the year. Investors are concerned about the impact of the trade war on the global economy. The US President has announced new tariffs on Chinese goods, and China has responded with retaliatory measures. The trade tensions have escalated, leading to fears of a prolonged economic downturn.\" question = \"What caused the stock market crash yesterday?\"  response_format = {     \"response\": \"\",     \"date\": \"\", }  prompt = prompt_template.format(context=context, input=question, response_format=response_format) print(prompt)  <pre>\nYou are a helpful assistant that provides accurate and concise answers to questions based on current news articles.\n\n### Context:\nYesterday (on 12/01/2011), the stock market crashed due to the ongoing trade war between the US and China. The Dow Jones Industrial Average dropped by 800 points, the worst single-day drop of the year. Investors are concerned about the impact of the trade war on the global economy. The US President has announced new tariffs on Chinese goods, and China has responded with retaliatory measures. The trade tensions have escalated, leading to fears of a prolonged economic downturn.\n\n### Input:\nWhat caused the stock market crash yesterday?\n\n### Response Format:\n{'response': '', 'date': ''}\n\n</pre> In\u00a0[7]: Copied! <pre>from dotenv import load_dotenv\nfrom openai import OpenAI\n\nload_dotenv(\"../.env\")\n\nclient = OpenAI()\n\nresponse = client.chat.completions.create(\n    model=\"gpt-4o-mini\",\n    messages=[\n        {\"role\": \"user\", \"content\": prompt}\n    ]\n)\n\nresponse = response.choices[0].message.content\nresponse\n</pre> from dotenv import load_dotenv from openai import OpenAI  load_dotenv(\"../.env\")  client = OpenAI()  response = client.chat.completions.create(     model=\"gpt-4o-mini\",     messages=[         {\"role\": \"user\", \"content\": prompt}     ] )  response = response.choices[0].message.content response Out[7]: <pre>\"{'response': 'The stock market crash yesterday was caused by escalating trade tensions between the US and China, including the announcement of new tariffs by the US and retaliatory measures from China, which raised concerns about the global economy.', 'date': '12/01/2011'}\"</pre> In\u00a0[14]: Copied! <pre>prompt = \"Write a short description (less than 15 words) about the ocean\"\n\ndef complete(prompt, temperature):\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        temperature=temperature,\n        messages=[\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n    ).choices[0].message.content\n\nprint(\"Temp 0: \",complete(prompt, 0))\n\nprint(\"Temp 1.5: \",complete(prompt, 1.5))\n</pre> prompt = \"Write a short description (less than 15 words) about the ocean\"  def complete(prompt, temperature):     return client.chat.completions.create(         model=\"gpt-4o-mini\",         temperature=temperature,         messages=[             {\"role\": \"user\", \"content\": prompt}         ]     ).choices[0].message.content  print(\"Temp 0: \",complete(prompt, 0))  print(\"Temp 1.5: \",complete(prompt, 1.5)) <pre>Temp 0:  The ocean is a vast, mysterious expanse teeming with diverse life and ecosystems.\nTemp 1.5:  The ocean is a vast, fluid expanse, teeming with diverse life and mysteries.\n</pre> In\u00a0[18]: Copied! <pre>prompt = \"explain photosynsthesis.\"\n\ndef complete(prompt, max_tokens):\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        max_tokens=max_tokens,\n        messages=[\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n    ).choices[0].message.content\n\nprint(\"Max tokens 10: \",complete(prompt, 10))\nprint(\"Max tokens 30:\",complete(prompt, 30))\n</pre> prompt = \"explain photosynsthesis.\"  def complete(prompt, max_tokens):     return client.chat.completions.create(         model=\"gpt-4o-mini\",         max_tokens=max_tokens,         messages=[             {\"role\": \"user\", \"content\": prompt}         ]     ).choices[0].message.content  print(\"Max tokens 10: \",complete(prompt, 10)) print(\"Max tokens 30:\",complete(prompt, 30)) <pre>Max tokens 10:  Photosynthesis is the biochemical process by which green plants\nMax tokens 30: Photosynthesis is a biochemical process through which green plants, algae, and certain bacteria convert light energy, usually from the sun, into chemical energy in the\n</pre> In\u00a0[22]: Copied! <pre>prompt = \"Describe a Sunset in less than 20 words.\"\n\ndef complete(prompt, top_p):\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        top_p=top_p,\n        messages=[\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n    ).choices[0].message.content\n\nprint(\"Top p 0.2: \",complete(prompt, 0.1))\nprint(\"Top p 0.9: \",complete(prompt, 0.9))\n</pre> prompt = \"Describe a Sunset in less than 20 words.\"  def complete(prompt, top_p):     return client.chat.completions.create(         model=\"gpt-4o-mini\",         top_p=top_p,         messages=[             {\"role\": \"user\", \"content\": prompt}         ]     ).choices[0].message.content  print(\"Top p 0.2: \",complete(prompt, 0.1)) print(\"Top p 0.9: \",complete(prompt, 0.9)) <pre>Top p 0.2:  The sun dipped below the horizon, painting the sky in hues of orange, pink, and purple, whispering day\u2019s farewell.\nTop p 0.9:  The sky blazes in fiery oranges and pinks, as the sun dips below the horizon, casting a warm, golden glow.\n</pre> In\u00a0[23]: Copied! <pre>prompt = \"Tell me about dogs in less than 20 words.\"\n\ndef complete(prompt, frequency_penalty):\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        frequency_penalty=frequency_penalty,\n        messages=[\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n    ).choices[0].message.content\n\nprint(\"Freq penalty -1\",complete(prompt, -1))\nprint(\"Freq penalty 1.5\",complete(prompt, 1.5))\n</pre> prompt = \"Tell me about dogs in less than 20 words.\"  def complete(prompt, frequency_penalty):     return client.chat.completions.create(         model=\"gpt-4o-mini\",         frequency_penalty=frequency_penalty,         messages=[             {\"role\": \"user\", \"content\": prompt}         ]     ).choices[0].message.content  print(\"Freq penalty -1\",complete(prompt, -1)) print(\"Freq penalty 1.5\",complete(prompt, 1.5)) <pre>Top p 0.2:  Dogs are loyal companions, known for their intelligence, friendliness, and diverse breeds, serving roles in work and love.\nTop p 0.9:  Dogs are loyal, social animals known for companionship, intelligence, and diverse breeds. They bond closely with humans.\n</pre> In\u00a0[25]: Copied! <pre>prompt = \"Discuss space exploration in less than 50 words.\"\n\ndef complete(prompt, presence_penalty):\n    return client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        presence_penalty=presence_penalty,\n        messages=[\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n    ).choices[0].message.content\n\nprint(\"Presence penalty -1: \",complete(prompt, -1))\nprint(\"Presence penalty 1.5: \",complete(prompt, 1.5))\n</pre> prompt = \"Discuss space exploration in less than 50 words.\"  def complete(prompt, presence_penalty):     return client.chat.completions.create(         model=\"gpt-4o-mini\",         presence_penalty=presence_penalty,         messages=[             {\"role\": \"user\", \"content\": prompt}         ]     ).choices[0].message.content  print(\"Presence penalty -1: \",complete(prompt, -1)) print(\"Presence penalty 1.5: \",complete(prompt, 1.5)) <pre>Presence penalty -1:  Space exploration involves the investigation of celestial bodies, using technology to gather data and understand the universe. It enhances our knowledge of planetary systems, potential extraterrestrial life, and Earth's origins. Notable missions include the Apollo moon landings, Mars rovers, and the Hubble Space Telescope, shaping humanity's view of space.\nPresence penalty 1.5:  Space exploration involves studying celestial bodies and phenomena beyond Earth, advancing our understanding of the universe. It encompasses robotic missions, crewed spaceflights, and telescopic observations, aiming to uncover cosmic origins, search for extraterrestrial life, and foster technological innovations, ultimately expanding humanity's presence in space.\n</pre>"},{"location":"module-2/introduction/#introduction","title":"Introduction\u00b6","text":"<p>Prompt: a \"prompt\" is the input text given to the model to generate a response. It is the question, command, or instruction that you provide to guide the model's output.</p>"},{"location":"module-2/introduction/#elements-of-a-prompt","title":"Elements of a Prompt\u00b6","text":"<ul> <li>Instruction: the main text of the prompt that tells the model what to do.</li> <li>Context: External information that the model should consider to generate a more relevant and accurate response.</li> <li>Input: The question or input that the model must answer or respond to.</li> <li>Response Format: The structure or format that the model must adhere to when generating a response. Typically format is provided as a json object or a pydantic object.</li> </ul> <p>source: Prompt Engineering Guide</p>"},{"location":"module-2/introduction/#example","title":"Example\u00b6","text":""},{"location":"module-2/introduction/#llm-settings","title":"LLM Settings\u00b6","text":"<p>Large Language Models (LLMs) have various settings that control their output behavior. Understanding these settings can help us generate more appropriate responses.</p>"},{"location":"module-2/introduction/#temperature","title":"Temperature\u00b6","text":"<p>This setting controls how random or predictable the model\u2019s outputs are. A lower temperature makes the model more predictable, often picking the most likely next word. This is good for tasks like answering factual questions. A higher temperature adds randomness, which can make outputs more creative or varied\u2014useful for things like creative writing. Basically, lower temperatures are for concise, factual responses, while higher temperatures are for creativity.</p> <p>Effect:</p> <ul> <li>Low Temperature: Predictable and repetitive responses.</li> <li>High Temperature: More varied and creative responses.</li> </ul>"},{"location":"module-2/introduction/#maximum-tokens","title":"Maximum Tokens\u00b6","text":"<p>This controls how many words the model generates. Setting a max length helps you avoid overly long or off-topic responses and also keeps costs down.</p> <p>Effect:</p> <ul> <li>Low Maximum Tokens: Very short responses.</li> <li>High Maximum Tokens: Longer, more detailed responses.</li> </ul>"},{"location":"module-2/introduction/#top-p-nucleus-sampling","title":"Top P (Nucleus Sampling)\u00b6","text":"<p>Explanation: This is another setting that influences randomness. If Top P is low, the model only considers the most confident words for the response. If Top P is higher, model considers a wider range of words, making the responses more diverse. Generally, tweak either Temperature or Top P, not both.</p> <p>Effect:</p> <ul> <li>Low Top P: Only very high-probability words are considered, resulting in more predictable responses.</li> <li>High Top P: More diversity and creativity in responses by including lower-probability words.</li> </ul>"},{"location":"module-2/introduction/#frequency-penalty","title":"Frequency Penalty\u00b6","text":"<p>This reduces the chance of words repeating by applying a penalty based on how often they\u2019ve already appeared. A higher frequency penalty means the model repeats words less, keeping responses varied.</p> <p>Effect:</p> <ul> <li>Low Frequency Penalty: More repetitions.</li> <li>High Frequency Penalty: Less repetition, encourages use of varied words.</li> </ul>"},{"location":"module-2/introduction/#presence-penalty","title":"Presence Penalty\u00b6","text":"<p>This also discourages repetition but treats all repeats the same, whether a word appears twice or ten times. A higher presence penalty makes the output more varied, while a lower one keeps it more focused. Use higher values for creative text and lower ones for more consistent, on-topic responses. Alter either one of Frequency Penalty or Presence Penalty, not both.</p> <p>Effect:</p> <ul> <li>Low Presence Penalty: Sticks closely to the main topic.</li> <li>High Presence Penalty: Introduces new and varied topics.</li> </ul>"},{"location":"module-2/introduction/#effect-on-response-when-each-setting-is-decreased-or-increased","title":"Effect on Response When Each Setting is Decreased or Increased\u00b6","text":"Setting Decrease Increase Temperature More predictable and repetitive output. More creative, diverse, and risk-taking. Maximum Tokens Shorter, less detailed responses. Longer, more detailed responses. Top P Limited to high-probability words; safer output. Broader word choice; more varied output. Frequency Penalty More repetition of words or phrases. Less repetition; more varied vocabulary. Presence Penalty Sticks closely to current topics. More new topics and ideas introduced."},{"location":"module-2/introduction/#general-best-practices","title":"General Best Practices\u00b6","text":"<p>Prompt engineering tactics recommended by OpenAI</p>"},{"location":"module-2/prompting_techniques/","title":"Prompting Techniques","text":"In\u00a0[1]: Copied! <pre>from dotenv import load_dotenv\nfrom openai import OpenAI\n\nload_dotenv(\"../.env\")\nclient = OpenAI()\n\nmodel = \"gpt-4o-mini\"\n</pre> from dotenv import load_dotenv from openai import OpenAI  load_dotenv(\"../.env\") client = OpenAI()  model = \"gpt-4o-mini\"   In\u00a0[2]: Copied! <pre>prompt = \"\"\"\nClassify the following text as either positive, neutral or negative sentiment:\nText: I love this product, it's the best!\nSentiment:\n\"\"\"\n\ndef complete(prompt):\n    return client.chat.completions.create(\n        model=model,\n        temperature=0,\n        messages=[\n            {\"role\": \"user\", \"content\": prompt},\n        ]\n    ).choices[0].message.content\n\ncomplete(prompt)\n</pre> prompt = \"\"\" Classify the following text as either positive, neutral or negative sentiment: Text: I love this product, it's the best! Sentiment: \"\"\"  def complete(prompt):     return client.chat.completions.create(         model=model,         temperature=0,         messages=[             {\"role\": \"user\", \"content\": prompt},         ]     ).choices[0].message.content  complete(prompt) Out[2]: <pre>'Sentiment: Positive'</pre> In\u00a0[3]: Copied! <pre>prompt = \"\"\"\nText: I hate this product, it's the worst!\nSentiment: negative\nText: This product is damn good!\nSentiment: positive\nText: This product is okayish\nSentiment: neutral\nText: not sure this I want to buy this product\nSentiment: negative\nText: this product is good, not great\nSentiment: positive\nText: I think this product suits my needs\nSentiment: \n\"\"\"\ncomplete(prompt)\n</pre> prompt = \"\"\" Text: I hate this product, it's the worst! Sentiment: negative Text: This product is damn good! Sentiment: positive Text: This product is okayish Sentiment: neutral Text: not sure this I want to buy this product Sentiment: negative Text: this product is good, not great Sentiment: positive Text: I think this product suits my needs Sentiment:  \"\"\" complete(prompt) Out[3]: <pre>'Sentiment: positive'</pre> In\u00a0[4]: Copied! <pre>prompt = \"\"\"\nSolve the below problem by thinking step by step:\nOn average Joe throws 25 punches per minute. \nIn one fight, he lasts 5 rounds of 3 minutes. \nIn another match, he lasts 4 rounds of 5 minutes.\nHow many punches did he throw in total?\n\"\"\"\nprint(complete(prompt))\n</pre> prompt = \"\"\" Solve the below problem by thinking step by step: On average Joe throws 25 punches per minute.  In one fight, he lasts 5 rounds of 3 minutes.  In another match, he lasts 4 rounds of 5 minutes. How many punches did he throw in total? \"\"\" print(complete(prompt)) <pre>To find out how many punches Joe threw in total, we need to calculate the number of punches he threw in each fight and then sum them up.\n\n1. **First Fight:**\n   - Joe lasts 5 rounds of 3 minutes each.\n   - Total time in minutes for the first fight = 5 rounds \u00d7 3 minutes/round = 15 minutes.\n   - Joe throws 25 punches per minute.\n   - Total punches thrown in the first fight = 15 minutes \u00d7 25 punches/minute = 375 punches.\n\n2. **Second Fight:**\n   - Joe lasts 4 rounds of 5 minutes each.\n   - Total time in minutes for the second fight = 4 rounds \u00d7 5 minutes/round = 20 minutes.\n   - Joe throws 25 punches per minute.\n   - Total punches thrown in the second fight = 20 minutes \u00d7 25 punches/minute = 500 punches.\n\n3. **Total Punches:**\n   - Total punches thrown = punches from the first fight + punches from the second fight.\n   - Total punches = 375 punches + 500 punches = 875 punches.\n\nTherefore, Joe threw a total of **875 punches**.\n</pre> In\u00a0[5]: Copied! <pre>budget_limits = {\n    \"food\": 500,\n    \"entertainment\": 200,\n    \"electronics\": 1000,\n    \"clothing\": 300,\n    \"miscellaneous\": 150\n}\n\ncurrent_spending = {\n    \"food\": 40,\n    \"entertainment\": 10,\n    \"electronics\": 80,\n    \"clothing\": 0,\n    \"miscellaneous\": 0\n}\n\nexpense_keywords = {\n    \"food\": [\"grocery\", \"restaurant\", \"food\", \"meal\", \"snack\"],\n    \"entertainment\": [\"movie\", \"concert\", \"game\", \"book\", \"music\"],\n    \"electronics\": [\"computer\", \"phone\", \"gadget\", \"laptop\", \"tablet\"],\n    \"clothing\": [\"shirt\", \"pants\", \"shoes\", \"jacket\", \"dress\"],\n    \"miscellaneous\": [\"gift\", \"household\", \"stationery\"]\n}\n\ndef calculate(expression):\n    \"\"\"Performs basic arithmetic operations.\"\"\"\n    try:\n        return eval(expression)\n    except:\n        return \"Invalid expression\"\n\ndef get_expense_category(description):\n    \"\"\"Categorizes an expense based on keywords.\"\"\"\n    description = description.lower()\n    for category, keywords in expense_keywords.items():\n        if any(keyword in description for keyword in keywords):\n            return category\n    return \"miscellaneous\"\n\ndef get_budget_limit(category):\n    \"\"\"Returns the budget limit for a given category.\"\"\"\n    return budget_limits.get(category, 0)\n\ndef get_current_spending(category):\n    \"\"\"Returns the current spending for a given category.\"\"\"\n    return current_spending.get(category, 0)\n\ndef add_expense(amount, description):\n    \"\"\"Adds an expense to the current spending.\"\"\"\n    category = get_expense_category(description)\n    current_spending[category] += amount\n    return f\"Added ${amount} to {category} category.\"\n\ndef get_remaining_budget(category):\n    \"\"\"Calculates the remaining budget for a category.\"\"\"\n    limit = get_budget_limit(category)\n    spent = get_current_spending(category)\n    return limit - spent\n\ndef check_budget_status(category):\n    \"\"\"Checks the budget status for a category.\"\"\"\n    limit = get_budget_limit(category)\n    spent = get_current_spending(category)\n    remaining = limit - spent\n    percentage = (spent / limit) * 100 if limit &gt; 0 else 0\n    return f\"Category: {category}\\nSpent: ${spent}\\nBudget: ${limit}\\nRemaining: ${remaining}\\nPercentage used: {percentage:.2f}%\"\n</pre> budget_limits = {     \"food\": 500,     \"entertainment\": 200,     \"electronics\": 1000,     \"clothing\": 300,     \"miscellaneous\": 150 }  current_spending = {     \"food\": 40,     \"entertainment\": 10,     \"electronics\": 80,     \"clothing\": 0,     \"miscellaneous\": 0 }  expense_keywords = {     \"food\": [\"grocery\", \"restaurant\", \"food\", \"meal\", \"snack\"],     \"entertainment\": [\"movie\", \"concert\", \"game\", \"book\", \"music\"],     \"electronics\": [\"computer\", \"phone\", \"gadget\", \"laptop\", \"tablet\"],     \"clothing\": [\"shirt\", \"pants\", \"shoes\", \"jacket\", \"dress\"],     \"miscellaneous\": [\"gift\", \"household\", \"stationery\"] }  def calculate(expression):     \"\"\"Performs basic arithmetic operations.\"\"\"     try:         return eval(expression)     except:         return \"Invalid expression\"  def get_expense_category(description):     \"\"\"Categorizes an expense based on keywords.\"\"\"     description = description.lower()     for category, keywords in expense_keywords.items():         if any(keyword in description for keyword in keywords):             return category     return \"miscellaneous\"  def get_budget_limit(category):     \"\"\"Returns the budget limit for a given category.\"\"\"     return budget_limits.get(category, 0)  def get_current_spending(category):     \"\"\"Returns the current spending for a given category.\"\"\"     return current_spending.get(category, 0)  def add_expense(amount, description):     \"\"\"Adds an expense to the current spending.\"\"\"     category = get_expense_category(description)     current_spending[category] += amount     return f\"Added ${amount} to {category} category.\"  def get_remaining_budget(category):     \"\"\"Calculates the remaining budget for a category.\"\"\"     limit = get_budget_limit(category)     spent = get_current_spending(category)     return limit - spent  def check_budget_status(category):     \"\"\"Checks the budget status for a category.\"\"\"     limit = get_budget_limit(category)     spent = get_current_spending(category)     remaining = limit - spent     percentage = (spent / limit) * 100 if limit &gt; 0 else 0     return f\"Category: {category}\\nSpent: ${spent}\\nBudget: ${limit}\\nRemaining: ${remaining}\\nPercentage used: {percentage:.2f}%\"  In\u00a0[6]: Copied! <pre>tools_desc = {\n    \"calculate\": {\n        \"description\": \"Performs basic arithmetic operations (add, subract, multiply, divide) on the provided mathematical expression.\",\n        \"input_params\": {\n            \"expression\": \"A string containing a mathematical expression, e.g., '2 + 3 * 4'.\"\n        }\n    },\n    \"get_expense_category\": {\n        \"description\": \"Categorizes an expense based on keywords found in the description. Matches against predefined categories like food, entertainment, electronics, clothing, and miscellaneous.\",\n        \"input_params\": {\n            \"description\": \"A string describing the expense, e.g., 'Bought a new phone'.\"\n        }\n    },\n    \"get_budget_limit\": {\n        \"description\": \"Returns the budget limit for a given category based on predefined limits.\",\n        \"input_params\": {\n            \"category\": \"A string representing the category, e.g., 'food', 'electronics'.\"\n        }\n    },\n    \"get_current_spending\": {\n        \"description\": \"Returns the current spending amount for a given category.\",\n        \"input_params\": {\n            \"category\": \"A string representing the category, e.g., 'clothing', 'entertainment'.\"\n        }\n    },\n    \"add_expense\": {\n        \"description\": \"Adds a specified expense amount to the current spending of the appropriate category, determined based on the description.\",\n        \"input_params\": {\n            \"amount\": \"A number representing the expense amount, e.g., 50.\",\n            \"description\": \"A string describing the expense, e.g., 'Dinner at a restaurant'.\"\n        }\n    },\n    \"get_remaining_budget\": {\n        \"description\": \"Calculates the remaining budget for a specified category by subtracting the current spending from the budget limit.\",\n        \"input_params\": {\n            \"category\": \"A string representing the category, e.g., 'miscellaneous', 'food'.\"\n        }\n    },\n    \"check_budget_status\": {\n        \"description\": \"Checks the budget status for a specified category, providing details on the total budget, amount spent, remaining budget, and percentage of budget used.\",\n        \"input_params\": {\n            \"category\": \"A string representing the category, e.g., 'electronics', 'food'.\"\n        }\n    }\n}\n\ntools_available = {\n    \"calculate\": calculate,\n    \"get_expense_category\": get_expense_category,\n    \"get_budget_limit\": get_budget_limit,\n    \"get_current_spending\": get_current_spending,\n    \"add_expense\": add_expense,\n    \"get_remaining_budget\": get_remaining_budget,\n    \"check_budget_status\": check_budget_status\n}\n</pre> tools_desc = {     \"calculate\": {         \"description\": \"Performs basic arithmetic operations (add, subract, multiply, divide) on the provided mathematical expression.\",         \"input_params\": {             \"expression\": \"A string containing a mathematical expression, e.g., '2 + 3 * 4'.\"         }     },     \"get_expense_category\": {         \"description\": \"Categorizes an expense based on keywords found in the description. Matches against predefined categories like food, entertainment, electronics, clothing, and miscellaneous.\",         \"input_params\": {             \"description\": \"A string describing the expense, e.g., 'Bought a new phone'.\"         }     },     \"get_budget_limit\": {         \"description\": \"Returns the budget limit for a given category based on predefined limits.\",         \"input_params\": {             \"category\": \"A string representing the category, e.g., 'food', 'electronics'.\"         }     },     \"get_current_spending\": {         \"description\": \"Returns the current spending amount for a given category.\",         \"input_params\": {             \"category\": \"A string representing the category, e.g., 'clothing', 'entertainment'.\"         }     },     \"add_expense\": {         \"description\": \"Adds a specified expense amount to the current spending of the appropriate category, determined based on the description.\",         \"input_params\": {             \"amount\": \"A number representing the expense amount, e.g., 50.\",             \"description\": \"A string describing the expense, e.g., 'Dinner at a restaurant'.\"         }     },     \"get_remaining_budget\": {         \"description\": \"Calculates the remaining budget for a specified category by subtracting the current spending from the budget limit.\",         \"input_params\": {             \"category\": \"A string representing the category, e.g., 'miscellaneous', 'food'.\"         }     },     \"check_budget_status\": {         \"description\": \"Checks the budget status for a specified category, providing details on the total budget, amount spent, remaining budget, and percentage of budget used.\",         \"input_params\": {             \"category\": \"A string representing the category, e.g., 'electronics', 'food'.\"         }     } }  tools_available = {     \"calculate\": calculate,     \"get_expense_category\": get_expense_category,     \"get_budget_limit\": get_budget_limit,     \"get_current_spending\": get_current_spending,     \"add_expense\": add_expense,     \"get_remaining_budget\": get_remaining_budget,     \"check_budget_status\": check_budget_status } In\u00a0[7]: Copied! <pre># ReAct Prompt\nPROMPT_TEMPLATE = \"\"\"\nYou are an AI assistant capable of reasoning and acting to answer complex questions. Your task is to use the tools provide and the steps already taken to the answer the given question.\n\n# You have access to the following tools:\n{tools_desc}\n\n# Steps so far:\n{steps}\n\n# To solve the problem, follow these steps:\n1. Analyse the question use the ONE tool which could help you the most to answer the question.\n2. Observe whether the response the of the tool is enough to answer the question.\n3. If not enough, use the another tools that can help you to answer the question.\n4. If one tool does not provide the required information, then use try using another tool.\n5. Repeat the process until you have enough information to answer the question.\n6. Once you have the final answer, respond ONLY with the answer.\n\n\nShow your reasoning and actions for each step. Use the format:\nThought: your thought process on the question\nAction: the tool to be used that can help you to answer the question and its input\n\nAnswer the following question:\n{question}\n\n{{\n    \"is_done\": true or false, whether the questions has been satisfactorily answered,\n    \"thought\": 'thought process',\n    \"action\": {{'tool_name': '', tool_input: {{}} }},\n    \"answer\": \"provide only this key in the response to respond with final answer\"\n}}\n\"\"\"\n</pre> # ReAct Prompt PROMPT_TEMPLATE = \"\"\" You are an AI assistant capable of reasoning and acting to answer complex questions. Your task is to use the tools provide and the steps already taken to the answer the given question.  # You have access to the following tools: {tools_desc}  # Steps so far: {steps}  # To solve the problem, follow these steps: 1. Analyse the question use the ONE tool which could help you the most to answer the question. 2. Observe whether the response the of the tool is enough to answer the question. 3. If not enough, use the another tools that can help you to answer the question. 4. If one tool does not provide the required information, then use try using another tool. 5. Repeat the process until you have enough information to answer the question. 6. Once you have the final answer, respond ONLY with the answer.   Show your reasoning and actions for each step. Use the format: Thought: your thought process on the question Action: the tool to be used that can help you to answer the question and its input  Answer the following question: {question}  {{     \"is_done\": true or false, whether the questions has been satisfactorily answered,     \"thought\": 'thought process',     \"action\": {{'tool_name': '', tool_input: {{}} }},     \"answer\": \"provide only this key in the response to respond with final answer\" }} \"\"\" In\u00a0[8]: Copied! <pre>from openai import OpenAI\nfrom dotenv import load_dotenv\nimport json\n\nload_dotenv(\"../.env\")\n\nclass ReActAgent:\n    def __init__(self, tools_available, tools_desc: dict, model: str, verbose:bool = True):\n        self.tools_available = tools_available\n        self.tools_desc = tools_desc\n        self.model = model\n        self.client = OpenAI()\n        self.verbose = verbose\n\n    def complete(self, question, steps) -&gt; dict:\n        prompt = PROMPT_TEMPLATE.format(\n            tools_desc=self.tools_desc,\n            steps=steps,\n            question=question\n        )\n\n        response = self.client.chat.completions.create(\n            model=self.model,\n            response_format={ \"type\": \"json_object\" },\n            messages=[\n                {\"role\": \"system\", \"content\": \"You are a helpful asssistant who responds in JSON\"},\n                {\"role\": \"user\", \"content\": prompt}\n            ]\n        )\n\n        return json.loads(response.choices[0].message.content)\n    \n    def query(self, question):\n        step_count = 0\n        steps = []\n        final_response = \"\"\n\n        while True:\n            response = self.complete(question, steps)\n            step_count += 1\n\n            if response[\"is_done\"]:\n                final_response = response[\"answer\"]\n                break\n            \n            tool_name, tool_input = response[\"action\"][\"tool_name\"], response[\"action\"][\"tool_input\"]\n            tool_output = self.tools_available[tool_name](**tool_input)\n            step = f\"\"\"\n            Thought: {response[\"thought\"]}\n            Action: {tool_name}({tool_input})\n            Observation: {tool_output}\n            \"\"\"\n            print(step) if self.verbose else None\n            steps.append(step)\n        \n\n        return {\n            \"content\": final_response,\n            \"steps\": steps\n        }\n</pre> from openai import OpenAI from dotenv import load_dotenv import json  load_dotenv(\"../.env\")  class ReActAgent:     def __init__(self, tools_available, tools_desc: dict, model: str, verbose:bool = True):         self.tools_available = tools_available         self.tools_desc = tools_desc         self.model = model         self.client = OpenAI()         self.verbose = verbose      def complete(self, question, steps) -&gt; dict:         prompt = PROMPT_TEMPLATE.format(             tools_desc=self.tools_desc,             steps=steps,             question=question         )          response = self.client.chat.completions.create(             model=self.model,             response_format={ \"type\": \"json_object\" },             messages=[                 {\"role\": \"system\", \"content\": \"You are a helpful asssistant who responds in JSON\"},                 {\"role\": \"user\", \"content\": prompt}             ]         )          return json.loads(response.choices[0].message.content)          def query(self, question):         step_count = 0         steps = []         final_response = \"\"          while True:             response = self.complete(question, steps)             step_count += 1              if response[\"is_done\"]:                 final_response = response[\"answer\"]                 break                          tool_name, tool_input = response[\"action\"][\"tool_name\"], response[\"action\"][\"tool_input\"]             tool_output = self.tools_available[tool_name](**tool_input)             step = f\"\"\"             Thought: {response[\"thought\"]}             Action: {tool_name}({tool_input})             Observation: {tool_output}             \"\"\"             print(step) if self.verbose else None             steps.append(step)                   return {             \"content\": final_response,             \"steps\": steps         } In\u00a0[9]: Copied! <pre>agent1 = ReActAgent(tools_available, tools_desc, model)\n\nquestions = [\n    \"I just spent $40 on dinner at a restaurant. How much of my food budget is left for the month?\",\n    \"If I buy a $900 laptop and a $200 smartphone, will I exceed my electronics budget?\",\n    \"What percentage of my entertainment budget have I used so far, and how much is left?\",\n    \"I'm planning to buy clothes for $250 and a gift for $100. Can I afford both within my respective budgets?\",\n    \"I've spent $150 on groceries and $50 on a restaurant meal this week. How much more can I spend on food this month?\",\n    \"What categories have I overspent on, and by how much?\"\n]\n\nquestion = questions[0]\nprint(f\"Question: {question}\")\nresponse = agent1.query(question)\nresponse[\"content\"]\n</pre> agent1 = ReActAgent(tools_available, tools_desc, model)  questions = [     \"I just spent $40 on dinner at a restaurant. How much of my food budget is left for the month?\",     \"If I buy a $900 laptop and a $200 smartphone, will I exceed my electronics budget?\",     \"What percentage of my entertainment budget have I used so far, and how much is left?\",     \"I'm planning to buy clothes for $250 and a gift for $100. Can I afford both within my respective budgets?\",     \"I've spent $150 on groceries and $50 on a restaurant meal this week. How much more can I spend on food this month?\",     \"What categories have I overspent on, and by how much?\" ]  question = questions[0] print(f\"Question: {question}\") response = agent1.query(question) response[\"content\"] <pre>Question: I just spent $40 on dinner at a restaurant. How much of my food budget is left for the month?\n\n            Thought: To determine how much of the food budget is left for the month after spending $40 on dinner, I first need to categorize the expense to update the current spending in the food category. I will then check the budget limit for the food category, calculate the remaining budget, and provide the final answer.\n            Action: add_expense({'amount': 40, 'description': 'Dinner at a restaurant'})\n            Observation: Added $40 to food category.\n            \n\n            Thought: I have already added the $40 expense to the food category. Now I need to check the budget limit for the food category so I can calculate the remaining budget.\n            Action: get_budget_limit({'category': 'food'})\n            Observation: 500\n            \n</pre> Out[9]: <pre>''</pre>"},{"location":"module-2/prompting_techniques/#prompting-techniques","title":"Prompting Techniques\u00b6","text":""},{"location":"module-2/prompting_techniques/#zero-shot-prompting","title":"Zero Shot Prompting\u00b6","text":"<p>'Zero Shot' means that the prompt will not contain any examples of the desired output. The model will be expected to generate the output from the instruction alone.</p>"},{"location":"module-2/prompting_techniques/#few-shot-prompting","title":"Few Shot Prompting\u00b6","text":"<p>'Few Shot' means that the prompt will contain a few examples that can help the model have a more nuanced understanding of the task. Few shot prompting helps in steering model towards more sophisticated outputs.</p>"},{"location":"module-2/prompting_techniques/#cot-chain-of-thought-prompting","title":"CoT (Chain of Thought) Prompting\u00b6","text":"<p>CoT prompting simulates complex reasoning capabilities by chaining multiple intermediate prompts together. The model is expected to breakdown the task into smaller sub-tasks, explain each step and eventually generate the final output.</p>"},{"location":"module-2/prompting_techniques/#react-reasoning-action-prompting","title":"ReAct (Reasoning + Action) Prompting\u00b6","text":""},{"location":"module-2/sample/","title":"Sample Notebook","text":"In\u00a0[6]: Copied! <pre>print(\"hello world\")\n\ndef add(a,b):\n    return a+b\n\nsum = add(1,2)\nprint(f\"Sum: {sum}\")\n</pre> print(\"hello world\")  def add(a,b):     return a+b  sum = add(1,2) print(f\"Sum: {sum}\") <pre>hello world\nSum: 3\n</pre>"},{"location":"module-2/sample/#sample-notebook","title":"Sample Notebook\u00b6","text":""},{"location":"module-2/sample/#hello-world","title":"Hello World\u00b6","text":"<p>Lorem ipsum dolor sit amet, consectetur adipiscing elit sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.</p>"},{"location":"module-2/advance-prompting-techniques/function_calling/","title":"Function Calling","text":"In\u00a0[58]: Copied! <pre>budget_limits = {\n    \"food\": 500,\n    \"entertainment\": 200,\n    \"electronics\": 1000,\n    \"clothing\": 300,\n    \"miscellaneous\": 150\n}\n\ncurrent_spending = {\n    \"food\": 40,\n    \"entertainment\": 10,\n    \"electronics\": 80,\n    \"clothing\": 0,\n    \"miscellaneous\": 0\n}\n\nexpense_keywords = {\n    \"food\": [\"grocery\", \"restaurant\", \"food\", \"meal\", \"snack\"],\n    \"entertainment\": [\"movie\", \"concert\", \"game\", \"book\", \"music\"],\n    \"electronics\": [\"computer\", \"phone\", \"gadget\", \"laptop\", \"tablet\"],\n    \"clothing\": [\"shirt\", \"pants\", \"shoes\", \"jacket\", \"dress\"],\n    \"miscellaneous\": [\"gift\", \"household\", \"stationery\"]\n}\n\ndef calculate(expression):\n    \"\"\"Performs basic arithmetic operations.\"\"\"\n    try:\n        return eval(expression)\n    except:\n        return \"Invalid expression\"\n\ndef get_expense_category(description):\n    \"\"\"Categorizes an expense based on keywords.\"\"\"\n    description = description.lower()\n    for category, keywords in expense_keywords.items():\n        if any(keyword in description for keyword in keywords):\n            return category\n    return \"miscellaneous\"\n\ndef get_budget_limit(category):\n    \"\"\"Returns the budget limit for a given category.\"\"\"\n    return budget_limits.get(category, 0)\n\ndef get_current_spending(category):\n    \"\"\"Returns the current spending for a given category.\"\"\"\n    return current_spending.get(category, 0)\n\ndef add_expense(amount, description):\n    \"\"\"Adds an expense to the current spending.\"\"\"\n    category = get_expense_category(description)\n    current_spending[category] += amount\n    return f\"Added ${amount} to {category} category.\"\n\ndef get_remaining_budget(category):\n    \"\"\"Calculates the remaining budget for a category.\"\"\"\n    limit = get_budget_limit(category)\n    spent = get_current_spending(category)\n    return limit - spent\n\ndef check_budget_status(category):\n    \"\"\"Checks the budget status for a category.\"\"\"\n    limit = get_budget_limit(category)\n    spent = get_current_spending(category)\n    remaining = limit - spent\n    percentage = (spent / limit) * 100 if limit &gt; 0 else 0\n    return f\"Category: {category}\\nSpent: ${spent}\\nBudget: ${limit}\\nRemaining: ${remaining}\\nPercentage used: {percentage:.2f}%\"\n\ntools_available = {\n    \"calculate\": calculate,\n    \"get_expense_category\": get_expense_category,\n    \"get_budget_limit\": get_budget_limit,\n    \"get_current_spending\": get_current_spending,\n    \"get_remaining_budget\": get_remaining_budget,\n    \"add_expense\": add_expense,\n    \"check_budget_status\": check_budget_status\n}\n</pre> budget_limits = {     \"food\": 500,     \"entertainment\": 200,     \"electronics\": 1000,     \"clothing\": 300,     \"miscellaneous\": 150 }  current_spending = {     \"food\": 40,     \"entertainment\": 10,     \"electronics\": 80,     \"clothing\": 0,     \"miscellaneous\": 0 }  expense_keywords = {     \"food\": [\"grocery\", \"restaurant\", \"food\", \"meal\", \"snack\"],     \"entertainment\": [\"movie\", \"concert\", \"game\", \"book\", \"music\"],     \"electronics\": [\"computer\", \"phone\", \"gadget\", \"laptop\", \"tablet\"],     \"clothing\": [\"shirt\", \"pants\", \"shoes\", \"jacket\", \"dress\"],     \"miscellaneous\": [\"gift\", \"household\", \"stationery\"] }  def calculate(expression):     \"\"\"Performs basic arithmetic operations.\"\"\"     try:         return eval(expression)     except:         return \"Invalid expression\"  def get_expense_category(description):     \"\"\"Categorizes an expense based on keywords.\"\"\"     description = description.lower()     for category, keywords in expense_keywords.items():         if any(keyword in description for keyword in keywords):             return category     return \"miscellaneous\"  def get_budget_limit(category):     \"\"\"Returns the budget limit for a given category.\"\"\"     return budget_limits.get(category, 0)  def get_current_spending(category):     \"\"\"Returns the current spending for a given category.\"\"\"     return current_spending.get(category, 0)  def add_expense(amount, description):     \"\"\"Adds an expense to the current spending.\"\"\"     category = get_expense_category(description)     current_spending[category] += amount     return f\"Added ${amount} to {category} category.\"  def get_remaining_budget(category):     \"\"\"Calculates the remaining budget for a category.\"\"\"     limit = get_budget_limit(category)     spent = get_current_spending(category)     return limit - spent  def check_budget_status(category):     \"\"\"Checks the budget status for a category.\"\"\"     limit = get_budget_limit(category)     spent = get_current_spending(category)     remaining = limit - spent     percentage = (spent / limit) * 100 if limit &gt; 0 else 0     return f\"Category: {category}\\nSpent: ${spent}\\nBudget: ${limit}\\nRemaining: ${remaining}\\nPercentage used: {percentage:.2f}%\"  tools_available = {     \"calculate\": calculate,     \"get_expense_category\": get_expense_category,     \"get_budget_limit\": get_budget_limit,     \"get_current_spending\": get_current_spending,     \"get_remaining_budget\": get_remaining_budget,     \"add_expense\": add_expense,     \"check_budget_status\": check_budget_status }  In\u00a0[59]: Copied! <pre>tools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"calculate\",\n            \"description\": \"Performs basic arithmetic operations (add, subract, multiply, divide) on the provided mathematical expression.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"expression\": {\n                        \"type\": \"string\",\n                        \"description\": \"A string containing a mathematical expression, e.g., '2 + 3 * 4'.\"\n                    }\n                },\n                \"required\": [\"expression\"]\n            }\n        }\n    },\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_expense_category\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"description\": {\n                        \"type\": \"string\",\n                        \"description\": \"Categorizes an expense based on keywords found in the description. Matches against predefined categories like food, entertainment, electronics, clothing, and miscellaneous\"\n                    }\n                },\n                \"required\": [\"description\"]\n            }\n        }\n    },\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_budget_limit\",\n            \"description\": \"Returns the budget limit for a given category based on predefined limits.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"category\": {\n                        \"type\": \"string\",\n                        \"description\": \"A string representing the category, e.g., 'food', 'electronics'.\"\n                    }\n                },\n                \"required\": [\"category\"]\n            }\n        }\n    },\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_current_spending\",\n            \"description\": \"Returns the current spending amount for a given category.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"category\": {\n                        \"type\": \"string\",\n                        \"description\": \"A string representing the category, e.g., 'clothing', 'entertainment'.\"\n                    }\n                },\n                \"required\": [\"category\"]\n            }\n        }\n    },\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"add_expense\",\n            \"description\": \"Adds a specified expense amount to the current spending of the appropriate category, determined based on the description.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"amount\": {\n                        \"type\": \"integer\",\n                        \"description\": \"A number representing the expense amount, e.g., 50.\"\n                    },\n                    \"description\": {\n                        \"type\": \"string\",\n                        \"description\": \"A string describing the expense, e.g., 'Dinner at a restaurant'.\"\n                    }\n                },\n                \"required\": [\"amount\", \"description\"]\n            }\n        }\n    },\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_remaining_budget\",\n            \"description\": \"Calculates the remaining budget for a specified category by subtracting the current spending from the budget limit.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"category\": {\n                        \"type\": \"string\",\n                        \"description\": \"A string representing the category, e.g., 'miscellaneous', 'food'.\"\n                    }\n                },\n                \"required\": [\"category\"]\n            }\n        }\n    },\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"check_budget_status\",\n            \"description\": \"Checks the budget status for a specified category, providing details on the total budget, amount spent, remaining budget, and percentage of budget used.\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"category\": {\n                        \"type\": \"string\",\n                        \"description\": \"A string representing the category, e.g., 'electronics', 'food'.\"\n                    }\n                },\n                \"required\": [\"category\"]\n            }\n        }\n    }\n]\n</pre> tools = [     {         \"type\": \"function\",         \"function\": {             \"name\": \"calculate\",             \"description\": \"Performs basic arithmetic operations (add, subract, multiply, divide) on the provided mathematical expression.\",             \"parameters\": {                 \"type\": \"object\",                 \"properties\": {                     \"expression\": {                         \"type\": \"string\",                         \"description\": \"A string containing a mathematical expression, e.g., '2 + 3 * 4'.\"                     }                 },                 \"required\": [\"expression\"]             }         }     },     {         \"type\": \"function\",         \"function\": {             \"name\": \"get_expense_category\",             \"parameters\": {                 \"type\": \"object\",                 \"properties\": {                     \"description\": {                         \"type\": \"string\",                         \"description\": \"Categorizes an expense based on keywords found in the description. Matches against predefined categories like food, entertainment, electronics, clothing, and miscellaneous\"                     }                 },                 \"required\": [\"description\"]             }         }     },     {         \"type\": \"function\",         \"function\": {             \"name\": \"get_budget_limit\",             \"description\": \"Returns the budget limit for a given category based on predefined limits.\",             \"parameters\": {                 \"type\": \"object\",                 \"properties\": {                     \"category\": {                         \"type\": \"string\",                         \"description\": \"A string representing the category, e.g., 'food', 'electronics'.\"                     }                 },                 \"required\": [\"category\"]             }         }     },     {         \"type\": \"function\",         \"function\": {             \"name\": \"get_current_spending\",             \"description\": \"Returns the current spending amount for a given category.\",             \"parameters\": {                 \"type\": \"object\",                 \"properties\": {                     \"category\": {                         \"type\": \"string\",                         \"description\": \"A string representing the category, e.g., 'clothing', 'entertainment'.\"                     }                 },                 \"required\": [\"category\"]             }         }     },     {         \"type\": \"function\",         \"function\": {             \"name\": \"add_expense\",             \"description\": \"Adds a specified expense amount to the current spending of the appropriate category, determined based on the description.\",             \"parameters\": {                 \"type\": \"object\",                 \"properties\": {                     \"amount\": {                         \"type\": \"integer\",                         \"description\": \"A number representing the expense amount, e.g., 50.\"                     },                     \"description\": {                         \"type\": \"string\",                         \"description\": \"A string describing the expense, e.g., 'Dinner at a restaurant'.\"                     }                 },                 \"required\": [\"amount\", \"description\"]             }         }     },     {         \"type\": \"function\",         \"function\": {             \"name\": \"get_remaining_budget\",             \"description\": \"Calculates the remaining budget for a specified category by subtracting the current spending from the budget limit.\",             \"parameters\": {                 \"type\": \"object\",                 \"properties\": {                     \"category\": {                         \"type\": \"string\",                         \"description\": \"A string representing the category, e.g., 'miscellaneous', 'food'.\"                     }                 },                 \"required\": [\"category\"]             }         }     },     {         \"type\": \"function\",         \"function\": {             \"name\": \"check_budget_status\",             \"description\": \"Checks the budget status for a specified category, providing details on the total budget, amount spent, remaining budget, and percentage of budget used.\",             \"parameters\": {                 \"type\": \"object\",                 \"properties\": {                     \"category\": {                         \"type\": \"string\",                         \"description\": \"A string representing the category, e.g., 'electronics', 'food'.\"                     }                 },                 \"required\": [\"category\"]             }         }     } ] In\u00a0[60]: Copied! <pre>from dotenv import load_dotenv\nfrom openai import OpenAI\nimport json\n\nload_dotenv(\"../../.env\")\nclient = OpenAI()\n\n\nclass Agent:\n    def __init__(self, tools, model=\"gpt-4o-mini\", verbose: bool = True):\n        self.tools = tools\n        self.model = model\n        self.verbose = verbose\n\n    def complete(self, messages: list):\n        response = client.chat.completions.create(\n            messages=messages,\n            model=self.model,\n            tools=self.tools\n        )\n        return response.choices[0].message\n\n    def query(self, question: str):\n        messages = [\n            {\"role\": \"system\", \"content\": \"You are a helpful customer support assistant. Use the supplied tools to assist the user. You MUST use only one tool at a time\"},\n            {\"role\": \"user\", \"content\": question}\n        ]\n\n        while True:\n            response = self.complete(messages)\n            messages.append(response)\n\n            if response.tool_calls:\n                for tool_call in response.tool_calls:\n                    func_name, func_args = tool_call.function.name, json.loads(tool_call.function.arguments)\n                    print(f\"Action: {func_name}({func_args})\") if self.verbose else None\n                    tool_response = tools_available[func_name](**func_args) \n                    print(f\"Observation: {tool_response}\\n{'-'*10}\") if self.verbose else None\n                    messages.append(\n                        {\n                            \"tool_call_id\": tool_call.id,\n                            \"role\": \"tool\",\n                            \"name\": func_name,\n                            \"content\": str(tool_response),\n                        }\n                    )\n            else:\n                return response.content\n</pre> from dotenv import load_dotenv from openai import OpenAI import json  load_dotenv(\"../../.env\") client = OpenAI()   class Agent:     def __init__(self, tools, model=\"gpt-4o-mini\", verbose: bool = True):         self.tools = tools         self.model = model         self.verbose = verbose      def complete(self, messages: list):         response = client.chat.completions.create(             messages=messages,             model=self.model,             tools=self.tools         )         return response.choices[0].message      def query(self, question: str):         messages = [             {\"role\": \"system\", \"content\": \"You are a helpful customer support assistant. Use the supplied tools to assist the user. You MUST use only one tool at a time\"},             {\"role\": \"user\", \"content\": question}         ]          while True:             response = self.complete(messages)             messages.append(response)              if response.tool_calls:                 for tool_call in response.tool_calls:                     func_name, func_args = tool_call.function.name, json.loads(tool_call.function.arguments)                     print(f\"Action: {func_name}({func_args})\") if self.verbose else None                     tool_response = tools_available[func_name](**func_args)                      print(f\"Observation: {tool_response}\\n{'-'*10}\") if self.verbose else None                     messages.append(                         {                             \"tool_call_id\": tool_call.id,                             \"role\": \"tool\",                             \"name\": func_name,                             \"content\": str(tool_response),                         }                     )             else:                 return response.content In\u00a0[62]: Copied! <pre>questions = [\n    \"I just spent $40 on dinner at a restaurant. How much of my food budget is left for the month?\",\n    \"If I buy a $900 laptop and a $200 smartphone, will I exceed my electronics budget?\",\n    \"What percentage of my entertainment budget have I used so far, and how much is left?\",\n    \"I'm planning to buy clothes for $250 and a gift for $100. Can I afford both within my respective budgets?\",\n    \"I've just spent $150 on groceries and $50 on a restaurant meal this week. How much more can I spend on food this month?\",\n    \"What categories have I overspent on, and by how much?\"\n]\nquestion = questions[1]\nprint(f\"Question: {question}\")\n\nagent = Agent(tools)\nresponse = agent.query(question)\n\nprint(response)\n</pre> questions = [     \"I just spent $40 on dinner at a restaurant. How much of my food budget is left for the month?\",     \"If I buy a $900 laptop and a $200 smartphone, will I exceed my electronics budget?\",     \"What percentage of my entertainment budget have I used so far, and how much is left?\",     \"I'm planning to buy clothes for $250 and a gift for $100. Can I afford both within my respective budgets?\",     \"I've just spent $150 on groceries and $50 on a restaurant meal this week. How much more can I spend on food this month?\",     \"What categories have I overspent on, and by how much?\" ] question = questions[1] print(f\"Question: {question}\")  agent = Agent(tools) response = agent.query(question)  print(response) <pre>Question: If I buy a $900 laptop and a $200 smartphone, will I exceed my electronics budget?\nAction: get_budget_limit({'category': 'electronics'})\nObservation: 1000\n----------\nAction: get_current_spending({'category': 'electronics'})\nObservation: 80\n----------\nYour electronics budget limit is $1000, and your current spending is $80. \n\nIf you buy a $900 laptop and a $200 smartphone, your total spending will be $80 + $900 + $200 = $1180.\n\nSince $1180 exceeds your budget limit of $1000, you will indeed exceed your electronics budget.\n</pre>"},{"location":"module-2/advance-prompting-techniques/function_calling/#function-calling","title":"Function Calling\u00b6","text":"<p>Function calling allows you to connect external tools to the model. This technique is specially useful when you used with CoT prompting or ReAct prompting for tasks which uses external tools.</p>"},{"location":"module-2/advance-prompting-techniques/function_calling/#steps-to-use-function-calling","title":"Steps to use function calling:\u00b6","text":""},{"location":"module-2/advance-prompting-techniques/function_calling/#1-define-functions-which-will-be-used-as-tools","title":"1. Define functions which will be used as tools\u00b6","text":""},{"location":"module-2/advance-prompting-techniques/function_calling/#2-describe-the-functions-so-the-model-know-how-to-use-it","title":"2. Describe the functions so the model know how to use it.\u00b6","text":""},{"location":"module-2/advance-prompting-techniques/function_calling/#3-generate-response","title":"3. Generate Response\u00b6","text":""},{"location":"module-2/advance-prompting-techniques/structured_outputs/","title":"Structured Outputs","text":"In\u00a0[10]: Copied! <pre>article_content = \"\"\"\nFDA Approves First Hearing Aid Software For Apple's AirPods\n\nTy Roush\nForbes Staff\nTy Roush is a breaking news reporter based in New York City.\n\nSep 12, 2024,12:55pm EDT\n\nThe Food and Drug Administration on Thursday allowed the first over-the-counter hearing aid software device to hit the market, a feature Apple announced earlier this week would be compatible with its latest earbuds to assist consumers they say may be unaware they have hearing loss.\n\nKey Facts\nThe FDA approved the software device, \u201cHearing Aid Feature,\u201d which the agency said could be installed on Apple's AirPods Pro headphones to amplify sounds for anyone 18 or older with mild to moderate hearing impairment.\n\nApple announced Monday its upcoming Apple AirPods Pro 2 could \u201ctransform\u201d into over-the-counter hearing aids through an upcoming software update that would increase some sounds in real-time, including voices or other sounds in a user's environment.\n\nApple said it expects to include the hearing aid software in an update in the fall.\n\nMore than 30 million. That's how many American adults have reported some degree of hearing loss, which can be caused by aging, exposure to loud noises and certain medical conditions, among other factors, the FDA said.\n\nKey Background\nThe Hearing Aid Feature is new software intended to expand access to hearing support, the FDA said. Access was previously much more limited, the FDA noted, before the agency announced new regulations in 2022 allowing consumers with hearing impairments to purchase hearing aids directly from stores or online retailers without a medical exam or prescription. Apple has advertised the software as a benefit for \u201cmillions of people\u201d unaware they are living with hearing loss, adding users can receive hearing tests through their iPhones. The software was evaluated in a study involving 118 participants with mild to moderate hearing loss, indicating patients who used the software received similar benefits to those who used traditional hearing aids, the FDA said.\n\nCrucial Quote\nMichelle Tarver, director of the FDA's Center for Devices and Radiological Health, said in a statement the software's authorization \u201cadvances the availability, accessibility and acceptability\u201d of hearing support for adults.\n\n\"\"\"\n</pre> article_content = \"\"\" FDA Approves First Hearing Aid Software For Apple's AirPods  Ty Roush Forbes Staff Ty Roush is a breaking news reporter based in New York City.  Sep 12, 2024,12:55pm EDT  The Food and Drug Administration on Thursday allowed the first over-the-counter hearing aid software device to hit the market, a feature Apple announced earlier this week would be compatible with its latest earbuds to assist consumers they say may be unaware they have hearing loss.  Key Facts The FDA approved the software device, \u201cHearing Aid Feature,\u201d which the agency said could be installed on Apple's AirPods Pro headphones to amplify sounds for anyone 18 or older with mild to moderate hearing impairment.  Apple announced Monday its upcoming Apple AirPods Pro 2 could \u201ctransform\u201d into over-the-counter hearing aids through an upcoming software update that would increase some sounds in real-time, including voices or other sounds in a user's environment.  Apple said it expects to include the hearing aid software in an update in the fall.  More than 30 million. That's how many American adults have reported some degree of hearing loss, which can be caused by aging, exposure to loud noises and certain medical conditions, among other factors, the FDA said.  Key Background The Hearing Aid Feature is new software intended to expand access to hearing support, the FDA said. Access was previously much more limited, the FDA noted, before the agency announced new regulations in 2022 allowing consumers with hearing impairments to purchase hearing aids directly from stores or online retailers without a medical exam or prescription. Apple has advertised the software as a benefit for \u201cmillions of people\u201d unaware they are living with hearing loss, adding users can receive hearing tests through their iPhones. The software was evaluated in a study involving 118 participants with mild to moderate hearing loss, indicating patients who used the software received similar benefits to those who used traditional hearing aids, the FDA said.  Crucial Quote Michelle Tarver, director of the FDA's Center for Devices and Radiological Health, said in a statement the software's authorization \u201cadvances the availability, accessibility and acceptability\u201d of hearing support for adults.  \"\"\" In\u00a0[11]: Copied! <pre>response_format = {\n    \"title\": \"\",\n    \"author\": \"\",\n    \"date\": \"\",\n    \"summary\": \"\",\n    \"sentiment\": \"\",\n    \"keywords\": [],\n    \"main_company\": \"\",\n    \"other_orgs\": \"list of other organizations mentioned in the article\",\n}\n</pre> response_format = {     \"title\": \"\",     \"author\": \"\",     \"date\": \"\",     \"summary\": \"\",     \"sentiment\": \"\",     \"keywords\": [],     \"main_company\": \"\",     \"other_orgs\": \"list of other organizations mentioned in the article\", } In\u00a0[12]: Copied! <pre>from dotenv import load_dotenv\nfrom openai import OpenAI\nimport json\n\nload_dotenv(\"../../.env\")\n\nclient = OpenAI()\n\nPROMPT_TEMPLATE = \"\"\"\nYou are a news summarizer. Your task is to summarize the following article:\n\n## Content:\n{content}\n\n## Response Format:\n{response_format}\n\n## Response:\n\n\"\"\"\n\ndef complete(article_content, response_format):\n    prompt = PROMPT_TEMPLATE.format(\n        content=article_content, \n        response_format=response_format\n    )\n\n    response = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        response_format={\"type\": \"json_object\"},\n        messages=[\n            {\"role\": \"system\", \"content\": \"you are an assistant that responds in JSON\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ]\n    )\n\n    return json.loads(response.choices[0].message.content)\n</pre> from dotenv import load_dotenv from openai import OpenAI import json  load_dotenv(\"../../.env\")  client = OpenAI()  PROMPT_TEMPLATE = \"\"\" You are a news summarizer. Your task is to summarize the following article:  ## Content: {content}  ## Response Format: {response_format}  ## Response:  \"\"\"  def complete(article_content, response_format):     prompt = PROMPT_TEMPLATE.format(         content=article_content,          response_format=response_format     )      response = client.chat.completions.create(         model=\"gpt-4o-mini\",         response_format={\"type\": \"json_object\"},         messages=[             {\"role\": \"system\", \"content\": \"you are an assistant that responds in JSON\"},             {\"role\": \"user\", \"content\": prompt}         ]     )      return json.loads(response.choices[0].message.content) In\u00a0[13]: Copied! <pre>response = complete(article_content, response_format)\nresponse\n</pre> response = complete(article_content, response_format) response Out[13]: <pre>{'title': \"FDA Approves First Hearing Aid Software For Apple's AirPods\",\n 'author': 'Ty Roush',\n 'date': 'Sep 12, 2024',\n 'summary': \"The FDA has approved a new software feature that allows Apple's AirPods Pro to function as over-the-counter hearing aids for adults with mild to moderate hearing impairment. This software, set to be released in a fall update, will amplify sounds in real-time, making it easier for users to hear voices and environmental sounds. The approval aims to provide wider access to hearing support, particularly as over 30 million American adults experience some level of hearing loss.\",\n 'sentiment': 'positive',\n 'keywords': ['FDA',\n  'Hearing Aid Feature',\n  'Apple AirPods Pro',\n  'hearing loss',\n  'software update',\n  'accessibility'],\n 'main_company': 'Apple',\n 'other_orgs': ['FDA']}</pre> In\u00a0[20]: Copied! <pre>from pydantic import BaseModel\nfrom enum import Enum\n\nclass Sentiment(str, Enum):\n    very_negative = \"very negative\"\n    negative = \"negative\"\n    neutral = \"neutral\"\n    positive = \"positive\"\n    very_positive = \"very positive\"\n\nclass Article(BaseModel):\n    title: str\n    author: str\n    date: str\n    summary: str\n    sentiment: Sentiment\n    keywords: list[str]\n    main_company: str\n    other_orgs: list[str]\n</pre> from pydantic import BaseModel from enum import Enum  class Sentiment(str, Enum):     very_negative = \"very negative\"     negative = \"negative\"     neutral = \"neutral\"     positive = \"positive\"     very_positive = \"very positive\"  class Article(BaseModel):     title: str     author: str     date: str     summary: str     sentiment: Sentiment     keywords: list[str]     main_company: str     other_orgs: list[str] In\u00a0[23]: Copied! <pre>def complete(article_content, response_format):\n    response = client.beta.chat.completions.parse(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"you are a new summarizer that will extract key details from news article content.\"},\n            {\"role\": \"user\", \"content\": article_content}\n        ],\n        response_format=response_format\n    )\n\n    return response.choices[0].message.parsed\n</pre> def complete(article_content, response_format):     response = client.beta.chat.completions.parse(         model=\"gpt-4o-mini\",         messages=[             {\"role\": \"system\", \"content\": \"you are a new summarizer that will extract key details from news article content.\"},             {\"role\": \"user\", \"content\": article_content}         ],         response_format=response_format     )      return response.choices[0].message.parsed In\u00a0[25]: Copied! <pre>article = complete(article_content,Article)\narticle.model_dump()\n</pre> article = complete(article_content,Article) article.model_dump() Out[25]: <pre>{'title': \"FDA Approves First Hearing Aid Software For Apple's AirPods\",\n 'author': 'Ty Roush',\n 'date': 'Sep 12, 2024,12:55pm EDT',\n 'summary': 'The FDA has approved an over-the-counter hearing aid software that can be installed on Apple AirPods Pro headphones, aimed at helping adults aged 18 and older with mild to moderate hearing impairments. This feature, expected to roll out in a fall update, allows users to amplify real-time sounds. Over 30 million American adults have reported some degree of hearing loss, and this new regulation aims to improve access to hearing aids.',\n 'sentiment': &lt;Sentiment.positive: 'positive'&gt;,\n 'keywords': ['FDA',\n  'hearing aid',\n  'Apple',\n  'AirPods Pro',\n  'hearing loss',\n  'technology'],\n 'main_company': 'Apple',\n 'other_orgs': ['FDA']}</pre>"},{"location":"module-2/advance-prompting-techniques/structured_outputs/#structured-outputs","title":"Structured Outputs\u00b6","text":""},{"location":"module-2/advance-prompting-techniques/structured_outputs/#json-mode","title":"JSON Mode\u00b6","text":"<p>JSON mode will ensure that the model outputs valid JSON.the JSON schema should be provided within the prompt in one of the messages. To enable JSON mode <code>response_format</code> needs to be set to <code>{ \"type\": \"json_object\" }</code></p>"},{"location":"module-2/advance-prompting-techniques/structured_outputs/#example","title":"Example:\u00b6","text":"<p>Let's use an use case such as news summarization to see how JSON mode can be used. News Article</p>"},{"location":"module-2/advance-prompting-techniques/structured_outputs/#structured-outputs-using-pydantic","title":"Structured Outputs using Pydantic\u00b6","text":"<p>This is a new and better method to ensure generattion of structured Outputs.</p> <p>Pydantic is a data validation and settings management using Python type annotations. Pydantic enforces type hints at runtime, and provides user friendly errors when data is invalid.</p> <p>Pydantic models can be used to define the schema of the output. The model can be used to validate the output and ensure that the output is in the correct format.</p>"},{"location":"module-2/advance-prompting-techniques/structured_outputs/#there-are-some-changes-from-compared-to-the-normal-way-of-completions-endpoint","title":"There are some changes from compared to the normal way of completions endpoint:\u00b6","text":"<ol> <li>Use <code>client.beta.chat.completions.parse()</code> instead of <code>client.chat.completions.create()</code></li> <li>Set <code>response_format</code> to the pydantic schema defined.</li> <li>Use the <code>response.choices[0].message.parsed</code> to get the output in the desired format.</li> </ol>"},{"location":"module-3/chunking_strategies/","title":"Chunking Strategies","text":"In\u00a0[1]: Copied! <pre>from langchain_text_splitters import RecursiveCharacterTextSplitter\n\nwith open(\"./sample.txt\", \"r\") as f:\n    text = f.read()\n\ntext_splitter = RecursiveCharacterTextSplitter(\n    chunk_size=100,\n    chunk_overlap=10,\n)\n\nchunks = text_splitter.split_text(text)\nchunks\n</pre> from langchain_text_splitters import RecursiveCharacterTextSplitter  with open(\"./sample.txt\", \"r\") as f:     text = f.read()  text_splitter = RecursiveCharacterTextSplitter(     chunk_size=100,     chunk_overlap=10, )  chunks = text_splitter.split_text(text) chunks Out[1]: <pre>['TXT test file\\nPurpose: Provide example of this file type\\nDocument file type: TXT\\nVersion: 1.0',\n 'Remark:',\n 'Example content:',\n 'The names \"John Doe\" for males, \"Jane Doe\" or \"Jane Roe\" for females, or \"Jonnie Doe\" and \"Janie',\n '\"Janie Doe\" for children, or just \"Doe\" non-gender-specifically are used as placeholder names for a',\n 'for a party whose true identity is unknown or must be withheld in a legal action, case, or',\n 'case, or discussion. The names are also used to refer to acorpse or hospital patient whose identity',\n 'identity is unknown. This practice is widely used in the United States and Canada, but is rarely',\n 'is rarely used in other English-speaking countries including the United Kingdom itself, from where',\n 'where the use of \"John Doe\" in a legal context originates. The names Joe Bloggs or John Smith are',\n 'Smith are used in the UK instead, as well as in Australia and New Zealand.',\n 'John Doe is sometimes used to refer to a typical male in other contexts as well, in a similar',\n 'a similar manner to John Q. Public, known in Great Britain as Joe Public, John Smith or Joe Bloggs.',\n 'Bloggs. For example, the first name listed on a form is often John Doe, along with a fictional',\n 'fictional address or other fictional information to provide an example of how to fill in the form.',\n 'the form. The name is also used frequently in popular culture, for example in the Frank Capra film',\n 'film Meet John Doe. John Doe was also the name of a 2002 American television series.',\n 'Similarly, a child or baby whose identity is unknown may be referred to as Baby Doe. A notorious',\n 'notorious murder case in Kansas City, Missouri, referred to the baby victim as Precious Doe. Other',\n 'Other unidentified female murder victims are Cali Doe and Princess Doe. Additional persons may be',\n 'may be called James Doe, Judy Doe, etc. However, to avoid possible confusion, if two anonymous or',\n 'or unknown parties are cited in a specific case or action, the surnames Doe and Roe may be used',\n 'be used simultaneously; for example, \"John Doe v. Jane Roe\". If several anonymous parties are',\n 'are referenced, they may simply be labelled John Doe #1, John Doe #2, etc. (the U.S. Operation',\n 'Operation Delego cited 21 (numbered) \"John Doe\"s) or labelled with other variants of Doe / Roe /',\n '/ Roe / Poe / etc. Other early alternatives such as John Stiles and Richard Miles are now rarely',\n 'rarely used, and Mary Major has been used in some American federal cases.',\n 'File created by https://www.online-convert.com',\n 'More example files: https://www.online-convert.com/file-type',\n 'Text of Example content: Wikipedia (https://en.wikipedia.org/wiki/John_Doe)',\n 'License: Attribution-ShareAlike 4.0 (https://creativecommons.org/licenses/by-sa/4.0/)',\n 'Feel free to use and share the file according to the license above.']</pre> In\u00a0[2]: Copied! <pre>from langchain_text_splitters import HTMLHeaderTextSplitter\n\nwith open(\"./sample.html\", \"r\") as f:\n    text = f.read()\n\n\nheaders_to_split_on = [\n    (\"h1\", \"Header 1\"),\n    (\"h2\", \"Header 2\"),\n    (\"h3\", \"Header 3\"),\n]\n\nhtml_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\nchunks = html_splitter.split_text(text)\nchunks\n</pre> from langchain_text_splitters import HTMLHeaderTextSplitter  with open(\"./sample.html\", \"r\") as f:     text = f.read()   headers_to_split_on = [     (\"h1\", \"Header 1\"),     (\"h2\", \"Header 2\"),     (\"h3\", \"Header 3\"), ]  html_splitter = HTMLHeaderTextSplitter(headers_to_split_on=headers_to_split_on) chunks = html_splitter.split_text(text) chunks Out[2]: <pre>[Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century'}, page_content='Introduction'),\n Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century', 'Header 2': 'Introduction'}, page_content='Technology has grown at an unprecedented rate in the 21st century, transforming every facet of human life. From the ways we communicate to how we work, learn, and entertain ourselves, technological advancements have redefined the modern world.'),\n Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century'}, page_content='The Rise of the Internet and Mobile Technology'),\n Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century', 'Header 2': 'The Rise of the Internet and Mobile Technology'}, page_content='The early 2000s witnessed the rise of personal computers and the internet, which revolutionized the way people accessed information. Before this period, gathering information meant visiting libraries, reading books, or consulting experts in person.  \\nAs internet infrastructure improved, mobile technology followed. The introduction of smartphones in the late 2000s, particularly with the release of the iPhone in 2007, marked a turning point.'),\n Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century'}, page_content='Cloud Computing and AI'),\n Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century', 'Header 3': 'Cloud Computing and AI'}, page_content='One of the most significant advancements of this era has been the growth of cloud computing. Companies no longer needed to invest in expensive hardware to store data. Instead, cloud services like Amazon Web Services (AWS) and Microsoft Azure allowed businesses to store and process data remotely.'),\n Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century'}, page_content='Automation and its Challenges'),\n Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century', 'Header 3': 'Automation and its Challenges'}, page_content='Automation is another area that has seen rapid growth. Robotics and AI have been integrated into manufacturing, agriculture, and even healthcare.  \\nHowever, this rapid advancement has not come without challenges, such as job displacement and privacy concerns.'),\n Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century', 'Header 2': 'Conclusion'}, page_content='In conclusion, the 21st century has been marked by rapid technological advancements that have reshaped society in countless ways. Balancing innovation with ethical considerations will be key to ensuring a future where technology benefits all of humanity.')]</pre> <p>By setting <code>return_each_element</code> to <code>True</code>, the text splitter splits and returns every element in the HTML DOM with it's associated header, instead just splitting upto the last header given.</p> <p>Arguments like <code>chunk_size</code> and <code>chunk_overlap</code> is present in the HTML splitter as well.</p> In\u00a0[3]: Copied! <pre>html_splitter = HTMLHeaderTextSplitter(\n    headers_to_split_on=headers_to_split_on,\n    return_each_element=True,\n)\nchunks = html_splitter.split_text(text)\nchunks\n</pre> html_splitter = HTMLHeaderTextSplitter(     headers_to_split_on=headers_to_split_on,     return_each_element=True, ) chunks = html_splitter.split_text(text) chunks Out[3]: <pre>[Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century'}, page_content='Introduction'),\n Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century', 'Header 2': 'Introduction'}, page_content='Technology has grown at an unprecedented rate in the 21st century, transforming every facet of human life. From the ways we communicate to how we work, learn, and entertain ourselves, technological advancements have redefined the modern world.'),\n Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century'}, page_content='The Rise of the Internet and Mobile Technology'),\n Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century', 'Header 2': 'The Rise of the Internet and Mobile Technology'}, page_content='The early 2000s witnessed the rise of personal computers and the internet, which revolutionized the way people accessed information. Before this period, gathering information meant visiting libraries, reading books, or consulting experts in person.'),\n Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century', 'Header 2': 'The Rise of the Internet and Mobile Technology'}, page_content='As internet infrastructure improved, mobile technology followed. The introduction of smartphones in the late 2000s, particularly with the release of the iPhone in 2007, marked a turning point.'),\n Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century'}, page_content='Cloud Computing and AI'),\n Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century', 'Header 3': 'Cloud Computing and AI'}, page_content='One of the most significant advancements of this era has been the growth of cloud computing. Companies no longer needed to invest in expensive hardware to store data. Instead, cloud services like Amazon Web Services (AWS) and Microsoft Azure allowed businesses to store and process data remotely.'),\n Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century'}, page_content='Automation and its Challenges'),\n Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century', 'Header 3': 'Automation and its Challenges'}, page_content='Automation is another area that has seen rapid growth. Robotics and AI have been integrated into manufacturing, agriculture, and even healthcare.'),\n Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century', 'Header 3': 'Automation and its Challenges'}, page_content='However, this rapid advancement has not come without challenges, such as job displacement and privacy concerns.'),\n Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century', 'Header 2': 'Conclusion'}, page_content='In conclusion, the 21st century has been marked by rapid technological advancements that have reshaped society in countless ways. Balancing innovation with ethical considerations will be key to ensuring a future where technology benefits all of humanity.')]</pre> In\u00a0[4]: Copied! <pre>from langchain_text_splitters import CharacterTextSplitter\n\nwith open(\"./sample.txt\", \"r\") as f:\n    text = f.read()\n\ntext_splitter = CharacterTextSplitter(\n    separator=\"\\n\\n\",\n    chunk_size=500,\n    chunk_overlap=50\n) # Splits the text is there is a new para.\n\nchunks = text_splitter.split_text(text)\nchunks\n</pre> from langchain_text_splitters import CharacterTextSplitter  with open(\"./sample.txt\", \"r\") as f:     text = f.read()  text_splitter = CharacterTextSplitter(     separator=\"\\n\\n\",     chunk_size=500,     chunk_overlap=50 ) # Splits the text is there is a new para.  chunks = text_splitter.split_text(text) chunks  <pre>Created a chunk of size 579, which is longer than the specified 500\nCreated a chunk of size 631, which is longer than the specified 500\n</pre> Out[4]: <pre>['Technology has grown at an unprecedented rate in the 21st century, transforming every facet of human life. From the ways we communicate to how we work, learn, and entertain ourselves, technological advancements have redefined the modern world. This rapid growth, driven by the convergence of the internet, artificial intelligence (AI), and automation, has opened up new possibilities and challenges alike.',\n 'The early 2000s witnessed the rise of personal computers and the internet, which revolutionized the way people accessed information. Before this period, gathering information meant visiting libraries, reading books, or consulting experts in person. The internet democratized knowledge by making it accessible to anyone with a connection. Search engines, such as Google, became essential tools for finding information instantly.',\n 'As internet infrastructure improved, mobile technology followed. The introduction of smartphones in the late 2000s and early 2010s, particularly with the release of the iPhone in 2007, marked a turning point. Smartphones brought the internet into everyone\u2019s pocket, allowing for constant connectivity. Apps like Facebook, Instagram, and WhatsApp further expanded the digital landscape, making social media a central part of modern life. People now had the ability to stay connected with friends and family across the globe, share their experiences, and consume content on the go.',\n 'One of the most significant advancements of this era has been the growth of cloud computing. Companies no longer needed to invest in expensive hardware to store data. Instead, cloud services like Amazon Web Services (AWS) and Microsoft Azure allowed businesses to store and process data remotely, enabling flexibility and scalability. The shift to the cloud has also supported the rise of AI and machine learning. With access to large datasets stored in the cloud, AI systems can be trained to perform tasks that were once thought to be exclusive to humans, such as recognizing patterns in images or making decisions based on data.',\n 'Automation is another area that has seen rapid growth. Robotics and AI have been integrated into manufacturing, agriculture, and even healthcare. Factories are increasingly automated, reducing the need for manual labor. In agriculture, drones are being used to monitor crops and automate irrigation systems. Meanwhile, in healthcare, AI-driven diagnostic tools help doctors identify diseases more accurately.',\n 'However, this rapid advancement has not come without challenges. One major concern is the impact on jobs. As machines take over routine tasks, there are fears that many jobs will become obsolete. Workers in industries such as manufacturing and customer service may face significant changes. Governments and organizations are now focusing on reskilling and upskilling workers to adapt to this new reality.',\n 'Privacy is another growing concern. As people become more connected, personal data is increasingly being shared online. Social media platforms and tech companies collect vast amounts of information on user behavior, leading to concerns about how this data is used. Regulations such as the General Data Protection Regulation (GDPR) in Europe have been introduced to give people more control over their data, but the debate over privacy is far from settled.',\n 'Looking ahead, the pace of technological development shows no signs of slowing down. Quantum computing, 5G networks, and advancements in renewable energy technologies are just some of the innovations on the horizon. These technologies have the potential to further transform industries and create new opportunities.',\n 'In conclusion, the 21st century has been marked by rapid technological advancements that have reshaped society in countless ways. While these advancements have brought about unprecedented opportunities, they also come with significant challenges. As we move forward, balancing innovation with ethical considerations will be key to ensuring a future where technology benefits all of humanity.']</pre> In\u00a0[5]: Copied! <pre>from langchain_text_splitters import MarkdownHeaderTextSplitter\n\nwith open(\"./sample.md\", \"r\") as f:\n    md_text = f.read()\n\nheaders_to_split_on = [\n    (\"#\", \"Header 1\"),\n    (\"##\", \"Header 2\"),\n    (\"###\", \"Header 3\"),\n]\n\nmarkdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on)\nchunks = markdown_splitter.split_text(md_text)\nchunks\n</pre> from langchain_text_splitters import MarkdownHeaderTextSplitter  with open(\"./sample.md\", \"r\") as f:     md_text = f.read()  headers_to_split_on = [     (\"#\", \"Header 1\"),     (\"##\", \"Header 2\"),     (\"###\", \"Header 3\"), ]  markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on) chunks = markdown_splitter.split_text(md_text) chunks Out[5]: <pre>[Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century', 'Header 2': 'Introduction'}, page_content='Technology has grown at an unprecedented rate in the 21st century, transforming every facet of human life. From the ways we communicate to how we work, learn, and entertain ourselves, technological advancements have redefined the modern world.'),\n Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century', 'Header 2': 'The Rise of the Internet and Mobile Technology'}, page_content='The early 2000s witnessed the rise of personal computers and the internet, which revolutionized the way people accessed information. Before this period, gathering information meant visiting libraries, reading books, or consulting experts in person.  \\nAs internet infrastructure improved, mobile technology followed. The introduction of smartphones in the late 2000s, particularly with the release of the iPhone in 2007, marked a turning point.'),\n Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century', 'Header 2': 'The Rise of the Internet and Mobile Technology', 'Header 3': 'Cloud Computing and AI'}, page_content='One of the most significant advancements of this era has been the growth of cloud computing. Companies no longer needed to invest in expensive hardware to store data. Instead, cloud services like Amazon Web Services (AWS) and Microsoft Azure allowed businesses to store and process data remotely.'),\n Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century', 'Header 2': 'The Rise of the Internet and Mobile Technology', 'Header 3': 'Automation and its Challenges'}, page_content='Automation is another area that has seen rapid growth. Robotics and AI have been integrated into manufacturing, agriculture, and even healthcare.  \\nHowever, this rapid advancement has not come without challenges, such as job displacement and privacy concerns.'),\n Document(metadata={'Header 1': 'The Evolution of Technology in the 21st Century', 'Header 2': 'Conclusion'}, page_content='In conclusion, the 21st century has been marked by rapid technological advancements that have reshaped society in countless ways. Balancing innovation with ethical considerations will be key to ensuring a future where technology benefits all of humanity.')]</pre> In\u00a0[6]: Copied! <pre>from langchain_experimental.text_splitter import SemanticChunker\nfrom langchain_openai.embeddings import OpenAIEmbeddings\nfrom dotenv import load_dotenv\n\nload_dotenv()\n\nwith open(\"./sample.txt\", \"r\") as f:\n    text = f.read()\n\ntext_splitter = SemanticChunker(OpenAIEmbeddings())\nchunks = text_splitter.split_text(text)\nchunks\n</pre> from langchain_experimental.text_splitter import SemanticChunker from langchain_openai.embeddings import OpenAIEmbeddings from dotenv import load_dotenv  load_dotenv()  with open(\"./sample.txt\", \"r\") as f:     text = f.read()  text_splitter = SemanticChunker(OpenAIEmbeddings()) chunks = text_splitter.split_text(text) chunks Out[6]: <pre>['Technology has grown at an unprecedented rate in the 21st century, transforming every facet of human life. From the ways we communicate to how we work, learn, and entertain ourselves, technological advancements have redefined the modern world. This rapid growth, driven by the convergence of the internet, artificial intelligence (AI), and automation, has opened up new possibilities and challenges alike. The early 2000s witnessed the rise of personal computers and the internet, which revolutionized the way people accessed information. Before this period, gathering information meant visiting libraries, reading books, or consulting experts in person. The internet democratized knowledge by making it accessible to anyone with a connection. Search engines, such as Google, became essential tools for finding information instantly. As internet infrastructure improved, mobile technology followed. The introduction of smartphones in the late 2000s and early 2010s, particularly with the release of the iPhone in 2007, marked a turning point. Smartphones brought the internet into everyone\u2019s pocket, allowing for constant connectivity. Apps like Facebook, Instagram, and WhatsApp further expanded the digital landscape, making social media a central part of modern life. People now had the ability to stay connected with friends and family across the globe, share their experiences, and consume content on the go. One of the most significant advancements of this era has been the growth of cloud computing. Companies no longer needed to invest in expensive hardware to store data. Instead, cloud services like Amazon Web Services (AWS) and Microsoft Azure allowed businesses to store and process data remotely, enabling flexibility and scalability. The shift to the cloud has also supported the rise of AI and machine learning. With access to large datasets stored in the cloud, AI systems can be trained to perform tasks that were once thought to be exclusive to humans, such as recognizing patterns in images or making decisions based on data. Automation is another area that has seen rapid growth. Robotics and AI have been integrated into manufacturing, agriculture, and even healthcare. Factories are increasingly automated, reducing the need for manual labor. In agriculture, drones are being used to monitor crops and automate irrigation systems. Meanwhile, in healthcare, AI-driven diagnostic tools help doctors identify diseases more accurately. However, this rapid advancement has not come without challenges.',\n 'One major concern is the impact on jobs. As machines take over routine tasks, there are fears that many jobs will become obsolete. Workers in industries such as manufacturing and customer service may face significant changes. Governments and organizations are now focusing on reskilling and upskilling workers to adapt to this new reality. Privacy is another growing concern. As people become more connected, personal data is increasingly being shared online. Social media platforms and tech companies collect vast amounts of information on user behavior, leading to concerns about how this data is used. Regulations such as the General Data Protection Regulation (GDPR) in Europe have been introduced to give people more control over their data, but the debate over privacy is far from settled. Looking ahead, the pace of technological development shows no signs of slowing down.',\n 'Quantum computing, 5G networks, and advancements in renewable energy technologies are just some of the innovations on the horizon. These technologies have the potential to further transform industries and create new opportunities. In conclusion, the 21st century has been marked by rapid technological advancements that have reshaped society in countless ways. While these advancements have brought about unprecedented opportunities, they also come with significant challenges. As we move forward, balancing innovation with ethical considerations will be key to ensuring a future where technology benefits all of humanity. ']</pre> In\u00a0[10]: Copied! <pre>text_splitter = SemanticChunker(\n    OpenAIEmbeddings(), \n    breakpoint_threshold_type=\"percentile\",\n    breakpoint_threshold_amount=75 \n)\n\nchunks = text_splitter.split_text(text)\nchunks\n</pre> text_splitter = SemanticChunker(     OpenAIEmbeddings(),      breakpoint_threshold_type=\"percentile\",     breakpoint_threshold_amount=75  )  chunks = text_splitter.split_text(text) chunks Out[10]: <pre>['Technology has grown at an unprecedented rate in the 21st century, transforming every facet of human life. From the ways we communicate to how we work, learn, and entertain ourselves, technological advancements have redefined the modern world. This rapid growth, driven by the convergence of the internet, artificial intelligence (AI), and automation, has opened up new possibilities and challenges alike. The early 2000s witnessed the rise of personal computers and the internet, which revolutionized the way people accessed information. Before this period, gathering information meant visiting libraries, reading books, or consulting experts in person. The internet democratized knowledge by making it accessible to anyone with a connection. Search engines, such as Google, became essential tools for finding information instantly.',\n 'As internet infrastructure improved, mobile technology followed. The introduction of smartphones in the late 2000s and early 2010s, particularly with the release of the iPhone in 2007, marked a turning point. Smartphones brought the internet into everyone\u2019s pocket, allowing for constant connectivity. Apps like Facebook, Instagram, and WhatsApp further expanded the digital landscape, making social media a central part of modern life. People now had the ability to stay connected with friends and family across the globe, share their experiences, and consume content on the go. One of the most significant advancements of this era has been the growth of cloud computing.',\n 'Companies no longer needed to invest in expensive hardware to store data. Instead, cloud services like Amazon Web Services (AWS) and Microsoft Azure allowed businesses to store and process data remotely, enabling flexibility and scalability. The shift to the cloud has also supported the rise of AI and machine learning. With access to large datasets stored in the cloud, AI systems can be trained to perform tasks that were once thought to be exclusive to humans, such as recognizing patterns in images or making decisions based on data. Automation is another area that has seen rapid growth.',\n 'Robotics and AI have been integrated into manufacturing, agriculture, and even healthcare.',\n 'Factories are increasingly automated, reducing the need for manual labor. In agriculture, drones are being used to monitor crops and automate irrigation systems. Meanwhile, in healthcare, AI-driven diagnostic tools help doctors identify diseases more accurately.',\n 'However, this rapid advancement has not come without challenges.',\n 'One major concern is the impact on jobs. As machines take over routine tasks, there are fears that many jobs will become obsolete.',\n 'Workers in industries such as manufacturing and customer service may face significant changes. Governments and organizations are now focusing on reskilling and upskilling workers to adapt to this new reality. Privacy is another growing concern.',\n 'As people become more connected, personal data is increasingly being shared online. Social media platforms and tech companies collect vast amounts of information on user behavior, leading to concerns about how this data is used. Regulations such as the General Data Protection Regulation (GDPR) in Europe have been introduced to give people more control over their data, but the debate over privacy is far from settled. Looking ahead, the pace of technological development shows no signs of slowing down.',\n 'Quantum computing, 5G networks, and advancements in renewable energy technologies are just some of the innovations on the horizon. These technologies have the potential to further transform industries and create new opportunities. In conclusion, the 21st century has been marked by rapid technological advancements that have reshaped society in countless ways. While these advancements have brought about unprecedented opportunities, they also come with significant challenges. As we move forward, balancing innovation with ethical considerations will be key to ensuring a future where technology benefits all of humanity. ']</pre>"},{"location":"module-3/chunking_strategies/#chunking-strategies","title":"Chunking Strategies\u00b6","text":"<p>It is important to chunk the text data into smaller parts before converting them into vector embeddings and storing it in a vector database. It allows us to retrieve the exact content that is relevant to the query, as having irrelevant content in the context leads to unnecessary of tokens and generation of irrelevant response.</p> <p>In order to chunk our text we will be using the langchain text splitters library. This library provides a variety of text splitters that can be used to split the text into smaller chunks.</p>"},{"location":"module-3/chunking_strategies/#recursive-chunking","title":"Recursive chunking\u00b6","text":"<p>Here, the text is splitted on <code>[\"\\n\\n\", \"\\n\", \" \", \"\"]</code> characters until the chunk size is small enough.</p> <p>Parameters:</p> <ol> <li><code>seperators</code>: List of characters to split the text on. The default is <code>[\"\\n\\n\", \"\\n\", \" \", \"\"]</code>.</li> <li><code>chunk_size</code>: the max size of the chunk.</li> <li><code>chunk_overlap</code>: length of the overlapping text between the chunks.</li> </ol>"},{"location":"module-3/chunking_strategies/#html-based-chunking","title":"HTML based chunking\u00b6","text":"<p>While recursive chunking might be good enough for generic cases, it might not be good enough for cases where the text data does has a semantic structure to it. With the use of recursive chunking there is no guarantee that each chunk is \"context aware and not split in between a piec of information. HTML based chunking makes sure that no chunk has no incomplete information by using the HTML tags as the seperators rather than using escape sequences.</p>"},{"location":"module-3/chunking_strategies/#character-based-chunking","title":"Character Based Chunking\u00b6","text":"<p>This is a very simple technique where the chunks are created based on a seperator or the <code>chunk_size</code> given.</p>"},{"location":"module-3/chunking_strategies/#markdown-chunking","title":"Markdown Chunking\u00b6","text":"<p>This is ver similar to HTML chunking except that is for markdown content. IT uses markdown heading tags split the text into chunks.</p>"},{"location":"module-3/chunking_strategies/#semantic-chunking","title":"Semantic Chunking\u00b6","text":"<p>HTML and markdown based chunking are typically enough in most cases. However, this kind of chunking is done based on the assumption that the text within each heading has it's own context and semantic meaning. This may not be the case always. In such cases, we can use semantic chunking to split the text into chunks based on the semantic meaning of the text.</p> <p>Here's how it works:</p> <ol> <li>The text is broken down into groups of 3 sentences.</li> <li>if two groups are similar (based on vector embeddings similarity), they are merged together.</li> </ol>"},{"location":"module-3/chunking_strategies/#breakpoints","title":"Breakpoints\u00b6","text":"<p>We can decide the when the text should split based on a breakpoint set. First we need to set the <code>breakpoint_threshold_type</code> to <code>percentile</code>, <code>standard_deviation</code>, <code>interquartile</code> or <code>gradient</code>. The we can set the <code>breakpoint_threshold_amount</code> to the desired value. If the difference between two sentences is greater than the threshold(<code>breakpoint_threshold_amount</code>), then the text is split.</p>"},{"location":"module-3/post_retrieval_strategies/","title":"Post Retrieval Strategies","text":"In\u00a0[1]: Copied! <pre>import os\n\nos.getenv(\"OPENAI_API_KEY\")\n</pre> import os  os.getenv(\"OPENAI_API_KEY\") In\u00a0[2]: Copied! <pre>import weaviate \nfrom dotenv import load_dotenv\nimport os\nfrom weaviate.embedded import EmbeddedOptions\n\n\nload_dotenv(\"./../.env\")\n\nclient = weaviate.WeaviateClient(\n    embedded_options=EmbeddedOptions(\n        additional_env_vars={\n            \"ENABLE_MODULES\": \"backup-filesystem,text2vec-openai,text2vec-cohere,text2vec-huggingface,ref2vec-centroid,generative-openai,qna-openai\",\n            \"BACKUP_FILESYSTEM_PATH\": \"/tmp/backups\",\n            \"DEFAULT_VECTORIZER_MODULE\": \"text2vec-openai\"\n        }\n    ),\n    additional_headers={\n        \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_API_KEY\")\n    }\n)\n\nclient.connect()\n</pre> import weaviate  from dotenv import load_dotenv import os from weaviate.embedded import EmbeddedOptions   load_dotenv(\"./../.env\")  client = weaviate.WeaviateClient(     embedded_options=EmbeddedOptions(         additional_env_vars={             \"ENABLE_MODULES\": \"backup-filesystem,text2vec-openai,text2vec-cohere,text2vec-huggingface,ref2vec-centroid,generative-openai,qna-openai\",             \"BACKUP_FILESYSTEM_PATH\": \"/tmp/backups\",             \"DEFAULT_VECTORIZER_MODULE\": \"text2vec-openai\"         }     ),     additional_headers={         \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_API_KEY\")     } )  client.connect() <pre>{\"action\":\"startup\",\"default_vectorizer_module\":\"text2vec-openai\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"text2vec-openai\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-09-29T22:58:41+05:30\"}\n{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-09-29T22:58:41+05:30\"}\n{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-09-29T22:58:41+05:30\"}\n{\"level\":\"info\",\"msg\":\"module offload-s3 is enabled\",\"time\":\"2024-09-29T22:58:41+05:30\"}\n{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-09-29T22:58:41+05:30\"}\n{\"level\":\"info\",\"msg\":\"open cluster service\",\"servers\":{\"Embedded_at_8079\":51164},\"time\":\"2024-09-29T22:58:41+05:30\"}\n{\"address\":\"192.168.69.215:51165\",\"level\":\"info\",\"msg\":\"starting cloud rpc server ...\",\"time\":\"2024-09-29T22:58:41+05:30\"}\n{\"level\":\"info\",\"msg\":\"starting raft sub-system ...\",\"time\":\"2024-09-29T22:58:41+05:30\"}\n{\"address\":\"192.168.69.215:51164\",\"level\":\"info\",\"msg\":\"tcp transport\",\"tcpMaxPool\":3,\"tcpTimeout\":10000000000,\"time\":\"2024-09-29T22:58:41+05:30\"}\n{\"level\":\"info\",\"msg\":\"loading local db\",\"time\":\"2024-09-29T22:58:41+05:30\"}\n{\"level\":\"info\",\"msg\":\"local DB successfully loaded\",\"time\":\"2024-09-29T22:58:41+05:30\"}\n{\"level\":\"info\",\"msg\":\"schema manager loaded\",\"n\":0,\"time\":\"2024-09-29T22:58:41+05:30\"}\n{\"level\":\"info\",\"metadata_only_voters\":false,\"msg\":\"construct a new raft node\",\"name\":\"Embedded_at_8079\",\"time\":\"2024-09-29T22:58:41+05:30\"}\n{\"id\":\"2-3-1726727697440\",\"last-index\":3,\"last-term\":2,\"level\":\"info\",\"msg\":\"starting restore from snapshot\",\"size-in-bytes\":21578,\"time\":\"2024-09-29T22:58:41+05:30\"}\n{\"level\":\"info\",\"msg\":\"restoring schema from snapshot\",\"time\":\"2024-09-29T22:58:41+05:30\"}\n{\"level\":\"info\",\"msg\":\"successfully restored schema from snapshot\",\"time\":\"2024-09-29T22:58:41+05:30\"}\n{\"last_applied_index\":0,\"last_snapshot_index\":3,\"last_store_log_applied_index\":114,\"level\":\"info\",\"msg\":\"load local db from snapshot\",\"time\":\"2024-09-29T22:58:41+05:30\"}\n{\"action\":\"\",\"id\":\"2-3-1726727697440\",\"last-index\":3,\"last-term\":2,\"level\":\"info\",\"msg\":\"snapshot restore progress\",\"percent-complete\":\"[100.00]%\",\"read-bytes\":21578,\"size-in-bytes\":21578,\"time\":\"2024-09-29T22:58:41+05:30\"}\n{\"id\":\"2-3-1726727697440\",\"last-index\":3,\"last-term\":2,\"level\":\"info\",\"msg\":\"restored from snapshot\",\"size-in-bytes\":21578,\"time\":\"2024-09-29T22:58:41+05:30\"}\n{\"action\":\"raft\",\"index\":112,\"level\":\"info\",\"msg\":\"raft initial configuration\",\"servers\":\"[[{Suffrage:Voter ID:Embedded_at_8079 Address:192.168.69.215:51042}]]\",\"time\":\"2024-09-29T22:58:41+05:30\"}\n{\"action\":\"raft\",\"follower\":{},\"leader-address\":\"\",\"leader-id\":\"\",\"level\":\"info\",\"msg\":\"raft entering follower state\",\"time\":\"2024-09-29T22:58:41+05:30\"}\n{\"last_snapshot_index\":3,\"last_store_applied_index\":3,\"last_store_log_applied_index\":114,\"level\":\"info\",\"msg\":\"raft node constructed\",\"raft_applied_index\":3,\"raft_last_index\":114,\"time\":\"2024-09-29T22:58:41+05:30\"}\n{\"action\":\"bootstrap\",\"error\":\"could not join a cluster from [192.168.69.215:51164]\",\"level\":\"warning\",\"msg\":\"failed to join cluster, will notify next if voter\",\"servers\":[\"192.168.69.215:51164\"],\"time\":\"2024-09-29T22:58:42+05:30\",\"voter\":true}\n{\"action\":\"bootstrap\",\"candidates\":[{\"Suffrage\":0,\"ID\":\"Embedded_at_8079\",\"Address\":\"192.168.69.215:51164\"}],\"level\":\"info\",\"msg\":\"starting cluster bootstrapping\",\"time\":\"2024-09-29T22:58:42+05:30\"}\n{\"action\":\"bootstrap\",\"error\":\"bootstrap only works on new clusters\",\"level\":\"error\",\"msg\":\"could not bootstrapping cluster\",\"time\":\"2024-09-29T22:58:42+05:30\"}\n{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"notified peers this node is ready to join as voter\",\"servers\":[\"192.168.69.215:51164\"],\"time\":\"2024-09-29T22:58:42+05:30\"}\n{\"action\":\"raft\",\"last-leader-addr\":\"\",\"last-leader-id\":\"\",\"level\":\"warning\",\"msg\":\"raft heartbeat timeout reached, starting election\",\"time\":\"2024-09-29T22:58:42+05:30\"}\n{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft entering candidate state\",\"node\":{},\"term\":38,\"time\":\"2024-09-29T22:58:42+05:30\"}\n{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft election won\",\"tally\":1,\"term\":38,\"time\":\"2024-09-29T22:58:43+05:30\"}\n{\"action\":\"raft\",\"leader\":{},\"level\":\"info\",\"msg\":\"raft entering leader state\",\"time\":\"2024-09-29T22:58:43+05:30\"}\n{\"level\":\"info\",\"msg\":\"reload local db: update schema ...\",\"time\":\"2024-09-29T22:58:43+05:30\"}\n{\"index\":\"LlamaIndex\",\"level\":\"info\",\"msg\":\"reload local index\",\"time\":\"2024-09-29T22:58:43+05:30\"}\n{\"index\":\"Article\",\"level\":\"info\",\"msg\":\"reload local index\",\"time\":\"2024-09-29T22:58:43+05:30\"}\n{\"docker_image_tag\":\"unknown\",\"level\":\"info\",\"msg\":\"configured versions\",\"server_version\":\"1.26.1\",\"time\":\"2024-09-29T22:58:43+05:30\"}\n{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50060\",\"time\":\"2024-09-29T22:58:43+05:30\"}\n{\"address\":\"192.168.69.215:51164\",\"level\":\"info\",\"msg\":\"current Leader\",\"time\":\"2024-09-29T22:58:43+05:30\"}\n{\"action\":\"restapi_management\",\"docker_image_tag\":\"unknown\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-09-29T22:58:43+05:30\"}\n{\"action\":\"raft\",\"command\":0,\"level\":\"info\",\"msg\":\"raft updating configuration\",\"server-addr\":\"192.168.69.215:51164\",\"server-id\":\"Embedded_at_8079\",\"servers\":\"[[{Suffrage:Voter ID:Embedded_at_8079 Address:192.168.69.215:51164}]]\",\"time\":\"2024-09-29T22:58:43+05:30\"}\n{\"index\":\"Health\",\"level\":\"info\",\"msg\":\"reload local index\",\"time\":\"2024-09-29T22:58:43+05:30\"}\n{\"action\":\"bootstrap\",\"leader\":\"192.168.69.215:51164\",\"level\":\"info\",\"msg\":\"successfully joined cluster\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry started\",\"payload\":\"\\u0026{MachineID:71fc7443-268d-43f9-9396-ba08c2445d45 Type:INIT Version:1.26.1 NumObjects:0 OS:darwin Arch:arm64 UsedModules:[text2vec-openai]}\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/objects/segment-1727247286715350000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/objects/segment-1727428171202975000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/objects/segment-1727428870328292000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/objects/segment-1727532599198310000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/objects/segment-1727623672402738000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/objects/segment-1727623788225585000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/objects/segment-1727623862795796000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/objects/segment-1727624181609895000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/objects/segment-1727624323963330000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/objects/segment-1727627647701473000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/objects/segment-1727627700986716000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/objects/segment-1727628431651387000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/objects/segment-1727628540142838000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/objects/segment-1727629385302155000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/objects/segment-1727630743680481000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title/segment-1727247286725435000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title/segment-1727428171210014000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title/segment-1727428870335316000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title/segment-1727532599204235000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title/segment-1727623672426756000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title/segment-1727623788246618000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title/segment-1727623862801062000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title/segment-1727624181655071000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title/segment-1727624323975363000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title/segment-1727627647710308000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title/segment-1727627700992659000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title/segment-1727628431660344000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title/segment-1727628540150615000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title/segment-1727629385315094000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title/segment-1727630743689459000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title_searchable/segment-1727247286730296000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title_searchable/segment-1727428171214951000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title_searchable/segment-1727428870340239000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title_searchable/segment-1727532599209214000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title_searchable/segment-1727623672447989000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title_searchable/segment-1727623788252615000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title_searchable/segment-1727623862807031000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title_searchable/segment-1727624181696017000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title_searchable/segment-1727624323980227000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title_searchable/segment-1727627647717298000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title_searchable/segment-1727627700996559000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title_searchable/segment-1727628431665399000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title_searchable/segment-1727628540156546000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title_searchable/segment-1727629385320090000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title_searchable/segment-1727630743694557000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body/segment-1727247286738950000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body/segment-1727428171219960000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body/segment-1727428870345253000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body/segment-1727532599213209000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body/segment-1727623672475791000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body/segment-1727623788258574000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body/segment-1727623862811784000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body/segment-1727624181737851000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body/segment-1727624324010304000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body/segment-1727627647722313000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body/segment-1727627701001497000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body/segment-1727628431670448000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body/segment-1727628540162554000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body/segment-1727629385326232000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body/segment-1727630743700482000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body_searchable/segment-1727247286745766000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body_searchable/segment-1727428171224967000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body_searchable/segment-1727428870350303000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body_searchable/segment-1727532599218188000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body_searchable/segment-1727623672496712000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body_searchable/segment-1727623788263596000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body_searchable/segment-1727623862816765000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body_searchable/segment-1727624181778908000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body_searchable/segment-1727624324017375000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body_searchable/segment-1727627647727370000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body_searchable/segment-1727627701005507000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body_searchable/segment-1727628431684357000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body_searchable/segment-1727628540171595000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body_searchable/segment-1727629385331116000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body_searchable/segment-1727630743706432000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_date/segment-1727247286751278000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_date/segment-1727428171229916000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_date/segment-1727428870355276000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_date/segment-1727532599223165000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_date/segment-1727623672540835000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_date/segment-1727623788268585000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_date/segment-1727623862820769000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_date/segment-1727624181820240000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_date/segment-1727624324046331000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_date/segment-1727627647732316000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_date/segment-1727627701009666000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_date/segment-1727628431688302000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_date/segment-1727628540177573000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_date/segment-1727629385336061000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_date/segment-1727630743712469000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category/segment-1727247286756665000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category/segment-1727428171234938000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category/segment-1727428870359223000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category/segment-1727532599227219000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category/segment-1727623672559184000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category/segment-1727623788273595000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category/segment-1727623862825811000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category/segment-1727624181860937000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category/segment-1727624324052083000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category/segment-1727627647737265000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category/segment-1727627701014521000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category/segment-1727628431692299000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category/segment-1727628540182669000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category/segment-1727629385341104000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category/segment-1727630743718425000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category_searchable/segment-1727247286760489000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category_searchable/segment-1727428171239022000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category_searchable/segment-1727428870363271000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category_searchable/segment-1727532599232198000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category_searchable/segment-1727623672603712000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category_searchable/segment-1727623788278612000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category_searchable/segment-1727623862830771000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category_searchable/segment-1727624181903861000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category_searchable/segment-1727624324062538000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category_searchable/segment-1727627647741324000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category_searchable/segment-1727627701019511000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category_searchable/segment-1727628431696259000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category_searchable/segment-1727628540187659000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category_searchable/segment-1727629385346060000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category_searchable/segment-1727630743723516000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author/segment-1727247286766230000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author/segment-1727428171242971000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author/segment-1727428870366217000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author/segment-1727532599236190000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author/segment-1727623672624034000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author/segment-1727623788284574000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author/segment-1727623862835789000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author/segment-1727624181942898000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author/segment-1727624324069709000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author/segment-1727627647746328000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author/segment-1727627701023544000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author/segment-1727628431703252000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author/segment-1727628540193585000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author/segment-1727629385350137000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author/segment-1727630743729469000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author_searchable/segment-1727247286771449000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author_searchable/segment-1727428171247943000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author_searchable/segment-1727428870369541000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author_searchable/segment-1727532599240187000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author_searchable/segment-1727623672646094000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author_searchable/segment-1727623788305679000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author_searchable/segment-1727623862840772000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author_searchable/segment-1727624181985245000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author_searchable/segment-1727624324104380000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author_searchable/segment-1727627647749231000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author_searchable/segment-1727627701027471000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author_searchable/segment-1727628431707309000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author_searchable/segment-1727628540199615000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author_searchable/segment-1727629385354163000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author_searchable/segment-1727630743735478000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property__id/segment-1727247286776551000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property__id/segment-1727428171252929000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property__id/segment-1727428870374237000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property__id/segment-1727532599244219000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property__id/segment-1727623672662772000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property__id/segment-1727623788310562000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property__id/segment-1727623862845765000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property__id/segment-1727624182027882000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property__id/segment-1727624324123220000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property__id/segment-1727627647753377000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property__id/segment-1727627701031542000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property__id/segment-1727628431708893000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property__id/segment-1727628540205599000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property__id/segment-1727629385356748000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property__id/segment-1727630743741420000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-09-29T22:58:44+05:30\",\"wait_for_cache_prefill\":false}\n{\"level\":\"info\",\"msg\":\"Completed loading shard article_PHiJNusYv2bT in 57.87225ms\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-09-29T22:58:44+05:30\",\"took\":229291}\n</pre> In\u00a0[3]: Copied! <pre>from weaviate.classes.config import Property, DataType, Configure\nimport json\n\nif client.collections.exists(\"Health\"):\n    client.collections.delete(\"Health\")\nelse:\n    client.collections.create(\n        \"Health\",\n        properties=[\n            Property(name=\"title\", data_type=DataType.TEXT),\n            Property(name=\"body\", data_type=DataType.TEXT),\n        ]\n    )\n\nwith open(\"./health.json\", \"r\") as f:\n    health_json = json.load(f)\n\nhealth = client.collections.get(\"Health\")\n\nwith health.batch.dynamic() as batch:\n    for h in health_json:\n        batch.add_object(h)\n</pre> from weaviate.classes.config import Property, DataType, Configure import json  if client.collections.exists(\"Health\"):     client.collections.delete(\"Health\") else:     client.collections.create(         \"Health\",         properties=[             Property(name=\"title\", data_type=DataType.TEXT),             Property(name=\"body\", data_type=DataType.TEXT),         ]     )  with open(\"./health.json\", \"r\") as f:     health_json = json.load(f)  health = client.collections.get(\"Health\")  with health.batch.dynamic() as batch:     for h in health_json:         batch.add_object(h)  <pre>{\"action\":\"load_all_shards\",\"level\":\"error\",\"msg\":\"failed to load all shards: context canceled\",\"time\":\"2024-09-29T22:58:44+05:30\"}\n{\"level\":\"warning\",\"msg\":\"prop len tracker file /Users/vishwasgowda/.local/share/weaviate/health/VeXaKjf2h4Vs/proplengths does not exist, creating new tracker\",\"time\":\"2024-09-29T22:58:45+05:30\"}\n{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-09-29T22:58:45+05:30\",\"wait_for_cache_prefill\":false}\n{\"level\":\"info\",\"msg\":\"Created shard health_VeXaKjf2h4Vs in 3.00275ms\",\"time\":\"2024-09-29T22:58:45+05:30\"}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-09-29T22:58:45+05:30\",\"took\":99208}\n</pre> In\u00a0[4]: Copied! <pre>import textwrap\n\ndef print_objects(objects):\n    \"\"\"\n        a function to print the retrieved objects\n    \"\"\"\n    for obj in objects:\n        print(f\"ID: {obj.uuid.int}\")\n        metadata = [{k: round(v, 2) if isinstance(v, float) else v} for k, v in obj.metadata.__dict__.items() if v is not None]\n        print(f\"Metadata: {metadata}\")\n        print(f\"Title: {obj.properties['title']}\")\n        print(f\"Body: {textwrap.shorten(obj.properties['body'], width=100)}\")\n        print()\n</pre> import textwrap  def print_objects(objects):     \"\"\"         a function to print the retrieved objects     \"\"\"     for obj in objects:         print(f\"ID: {obj.uuid.int}\")         metadata = [{k: round(v, 2) if isinstance(v, float) else v} for k, v in obj.metadata.__dict__.items() if v is not None]         print(f\"Metadata: {metadata}\")         print(f\"Title: {obj.properties['title']}\")         print(f\"Body: {textwrap.shorten(obj.properties['body'], width=100)}\")         print() In\u00a0[5]: Copied! <pre>from weaviate.classes.query import MetadataQuery\n\nqueries = [\n    \"How does diet affect muscle recovery after exercise?\",\n    \"Can intermittent fasting and weight training improve both heart health and muscle growth?\",\n    \"How can yoga and mindfulness help reduce stress and improve digestion?\",\n    \"What role do hydration and nutrition play in speeding up muscle recovery?\",\n    \"What's the best way to combine intermittent fasting and HIIT to improve cardio?\"\n]\n\n\nquery = queries[4]\n\nchunks = health.query.near_text(\n    query=query,\n    limit=10,\n    return_metadata=MetadataQuery(distance=True, certainty=True)\n)\n\nprint_objects(chunks.objects)\n</pre> from weaviate.classes.query import MetadataQuery  queries = [     \"How does diet affect muscle recovery after exercise?\",     \"Can intermittent fasting and weight training improve both heart health and muscle growth?\",     \"How can yoga and mindfulness help reduce stress and improve digestion?\",     \"What role do hydration and nutrition play in speeding up muscle recovery?\",     \"What's the best way to combine intermittent fasting and HIIT to improve cardio?\" ]   query = queries[4]  chunks = health.query.near_text(     query=query,     limit=10,     return_metadata=MetadataQuery(distance=True, certainty=True) )  print_objects(chunks.objects) <pre>ID: 79750210735445999554422007586051561295\nMetadata: [{'distance': 0.13}, {'certainty': 0.93}]\nTitle: Benefits of HIIT Workouts\nBody: High-intensity interval training (HIIT) is an efficient way to burn fat and improve [...]\n\nID: 110722175561862500784486769915905468074\nMetadata: [{'distance': 0.16}, {'certainty': 0.92}]\nTitle: Intermittent Fasting and Cardiovascular Health\nBody: Research suggests that intermittent fasting may improve cardiovascular health by reducing [...]\n\nID: 311091617027233937846831049884227850741\nMetadata: [{'distance': 0.19}, {'certainty': 0.91}]\nTitle: Intermittent Fasting for Muscle Gain\nBody: Although intermittent fasting is often associated with weight loss, it can also be used to [...]\n\nID: 161858462270752632728592141290163058648\nMetadata: [{'distance': 0.19}, {'certainty': 0.9}]\nTitle: Intermittent Fasting for Weight Loss\nBody: Intermittent fasting has become popular for its potential to aid in weight loss. By [...]\n\nID: 201600014844846141563473870326332371185\nMetadata: [{'distance': 0.22}, {'certainty': 0.89}]\nTitle: Cardio Exercises for Heart Health\nBody: Cardiovascular exercises, such as running, cycling, and swimming, are crucial for maintaining [...]\n\nID: 256375938163050498204716898560826021157\nMetadata: [{'distance': 0.24}, {'certainty': 0.88}]\nTitle: Strength Training and Muscle Growth\nBody: Strength training is essential for building muscle and increasing strength. Regular resistance [...]\n\nID: 55460105393633533740082431678917851971\nMetadata: [{'distance': 0.24}, {'certainty': 0.88}]\nTitle: Effects of Caffeine on Athletic Performance\nBody: Caffeine is a popular pre-workout stimulant that can enhance physical performance. Studies [...]\n\nID: 147016491609408134115755187053551869270\nMetadata: [{'distance': 0.25}, {'certainty': 0.88}]\nTitle: Understanding Metabolism and Weight Loss\nBody: Metabolism plays a key role in how your body uses energy. A faster metabolism can help you [...]\n\nID: 181738845934224674309355573454392853110\nMetadata: [{'distance': 0.25}, {'certainty': 0.88}]\nTitle: Best Foods for Long-Lasting Energy\nBody: Foods like oats, sweet potatoes, and nuts provide sustained energy throughout the day. These [...]\n\nID: 174062307180986013243815971954302189093\nMetadata: [{'distance': 0.26}, {'certainty': 0.87}]\nTitle: Yoga for Stress Relief\nBody: Yoga is widely regarded as one of the best activities for managing stress. By combining [...]\n\n</pre> In\u00a0[6]: Copied! <pre>def convert_chunks_to_dict(chunks):\n    chunks_dict = []\n    for chunk in chunks:\n        chunk_dict = {\n            \"id\": chunk.uuid.int,\n            \"title\": chunk.properties[\"title\"],\n            \"body\": chunk.properties[\"body\"],\n            \"metadata\": chunk.metadata.__dict__\n        }\n        chunks_dict.append(chunk_dict)\n    return chunks_dict\n</pre> def convert_chunks_to_dict(chunks):     chunks_dict = []     for chunk in chunks:         chunk_dict = {             \"id\": chunk.uuid.int,             \"title\": chunk.properties[\"title\"],             \"body\": chunk.properties[\"body\"],             \"metadata\": chunk.metadata.__dict__         }         chunks_dict.append(chunk_dict)     return chunks_dict In\u00a0[7]: Copied! <pre>import cohere\n\nco = cohere.Client(api_key=os.getenv(\"COHERE_API_KEY\"))\n\nchunks_dict = convert_chunks_to_dict(chunks.objects)\n\nreranked_chunks = co.rerank(\n    model=\"rerank-english-v3.0\", \n    query=query, \n    documents=chunks_dict,\n    rank_fields=[\"title\", \"body\"], # fields in the docs list to consider for ranking\n    top_n=5, \n    return_documents=True\n)\n\n[print(chunk) for chunk in reranked_chunks.results]\n</pre> import cohere  co = cohere.Client(api_key=os.getenv(\"COHERE_API_KEY\"))  chunks_dict = convert_chunks_to_dict(chunks.objects)  reranked_chunks = co.rerank(     model=\"rerank-english-v3.0\",      query=query,      documents=chunks_dict,     rank_fields=[\"title\", \"body\"], # fields in the docs list to consider for ranking     top_n=5,      return_documents=True )  [print(chunk) for chunk in reranked_chunks.results] <pre>/Users/vishwasgowda/code/ai-course/.venv/lib/python3.11/site-packages/pydantic/_internal/_generate_schema.py:312: PydanticDeprecatedSince20: `json_encoders` is deprecated. See https://docs.pydantic.dev/2.9/concepts/serialization/#custom-serializers for alternatives. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.9/migration/\n  warnings.warn(\n</pre> <pre>document=RerankResponseResultsItemDocument(text=None, body='Research suggests that intermittent fasting may improve cardiovascular health by reducing blood pressure, cholesterol levels, and inflammation. However, it is essential to balance fasting with nutrient-rich foods to ensure overall health.', id=1.107221755618625e+38, metadata={'certainty': 0.9217401146888733, 'creation_time': None, 'distance': 0.15651977062225342, 'explain_score': None, 'is_consistent': None, 'last_update_time': None, 'rerank_score': None, 'score': None}, title='Intermittent Fasting and Cardiovascular Health') index=1 relevance_score=0.70181525\ndocument=RerankResponseResultsItemDocument(text=None, body='High-intensity interval training (HIIT) is an efficient way to burn fat and improve cardiovascular fitness. HIIT involves short bursts of intense exercise followed by rest or low-intensity periods. This type of workout can also boost metabolism.', id=7.9750210735446e+37, metadata={'certainty': 0.9332375526428223, 'creation_time': None, 'distance': 0.13352489471435547, 'explain_score': None, 'is_consistent': None, 'last_update_time': None, 'rerank_score': None, 'score': None}, title='Benefits of HIIT Workouts') index=0 relevance_score=0.1133831\ndocument=RerankResponseResultsItemDocument(text=None, body='Although intermittent fasting is often associated with weight loss, it can also be used to build muscle. By carefully timing meals and focusing on nutrient-dense foods, intermittent fasters can gain lean muscle mass while reducing body fat.', id=3.1109161702723392e+38, metadata={'certainty': 0.9072262048721313, 'creation_time': None, 'distance': 0.18554764986038208, 'explain_score': None, 'is_consistent': None, 'last_update_time': None, 'rerank_score': None, 'score': None}, title='Intermittent Fasting for Muscle Gain') index=2 relevance_score=0.005159623\ndocument=RerankResponseResultsItemDocument(text=None, body='Intermittent fasting has become popular for its potential to aid in weight loss. By restricting eating to certain windows, people may consume fewer calories overall, leading to fat loss. However, intermittent fasting should be practiced carefully, as it may not be suitable for everyone.', id=1.6185846227075263e+38, metadata={'certainty': 0.902607262134552, 'creation_time': None, 'distance': 0.194785475730896, 'explain_score': None, 'is_consistent': None, 'last_update_time': None, 'rerank_score': None, 'score': None}, title='Intermittent Fasting for Weight Loss') index=3 relevance_score=0.0037217087\ndocument=RerankResponseResultsItemDocument(text=None, body='Cardiovascular exercises, such as running, cycling, and swimming, are crucial for maintaining heart health. These activities strengthen the heart muscle, improve blood circulation, and reduce the risk of heart disease.', id=2.0160001484484615e+38, metadata={'certainty': 0.8883228302001953, 'creation_time': None, 'distance': 0.22335433959960938, 'explain_score': None, 'is_consistent': None, 'last_update_time': None, 'rerank_score': None, 'score': None}, title='Cardio Exercises for Heart Health') index=4 relevance_score=0.00038899208\n</pre> Out[7]: <pre>[None, None, None, None, None]</pre> In\u00a0[8]: Copied! <pre># create a pandas df comparing the sequence of the original chunks and the reranked chunks using the titles\nimport pandas as pd\n\ndf = pd.DataFrame({\n    \"original\": [chunk.properties[\"title\"] for chunk in chunks.objects[:5]],\n    \"similarity\": [chunk.metadata.certainty for chunk in chunks.objects[:5]],\n    \"reranked\": [chunk[\"document\"][\"title\"] for chunk in reranked_chunks.dict()[\"results\"]],\n    \"relevance score\": [chunk[\"relevance_score\"] for chunk in reranked_chunks.dict()[\"results\"]]\n})\n\ndf\n</pre> # create a pandas df comparing the sequence of the original chunks and the reranked chunks using the titles import pandas as pd  df = pd.DataFrame({     \"original\": [chunk.properties[\"title\"] for chunk in chunks.objects[:5]],     \"similarity\": [chunk.metadata.certainty for chunk in chunks.objects[:5]],     \"reranked\": [chunk[\"document\"][\"title\"] for chunk in reranked_chunks.dict()[\"results\"]],     \"relevance score\": [chunk[\"relevance_score\"] for chunk in reranked_chunks.dict()[\"results\"]] })  df <pre>/Users/vishwasgowda/code/ai-course/.venv/lib/python3.11/site-packages/pydantic/main.py:1097: PydanticDeprecatedSince20: The `__fields_set__` attribute is deprecated, use `model_fields_set` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.9/migration/\n  warnings.warn(\n</pre> Out[8]: original similarity reranked relevance score 0 Benefits of HIIT Workouts 0.933238 Intermittent Fasting and Cardiovascular Health 0.701815 1 Intermittent Fasting and Cardiovascular Health 0.921740 Benefits of HIIT Workouts 0.113383 2 Intermittent Fasting for Muscle Gain 0.907226 Intermittent Fasting for Muscle Gain 0.005160 3 Intermittent Fasting for Weight Loss 0.902607 Intermittent Fasting for Weight Loss 0.003722 4 Cardio Exercises for Heart Health 0.888323 Cardio Exercises for Heart Health 0.000389 In\u00a0[9]: Copied! <pre>from openai import OpenAI\nimport json\nfrom IPython.display import Markdown, display\n\n\nclient = OpenAI()\n\nPROMPT_TEMPLATE = \"\"\"\n    You are a health expert and you will be provided with a question and related context on which needs to provide a well constructed and structured answer.\n\n    ## Instructions:\n    - Avoid fluff and clich\u00e9s: Generate a concise answers and avoid words, phrases, and sentences that do not add any substantial value to the response.\n    - Tone: needs to be conversational, spartan, use less corporate jargon.\n    - The answers should have a natural flow and should be easy to understand.\n    - Assume that the reader has a {level} level of understanding of the topic, so generate response and use terminology accordingly.\n    \n    ## Question:\n    {question}\n\n    ## Context:\n    The context provided below is order from most relevant to least relevant to the question. So use the context to accordingly to structure your response.\n    {context}\n\n    ## Response Format:\n    {{\"response\": \"provide the response using proper markdown formatting.\"}}\n\n    ## Response:\n\"\"\"\n\ndef generate_response(question, context, level=\"beginner\"):\n\n    formatted_context = \"\\n\".join([f\"---\\n{chunk['document']['title']}\\n{chunk['document']['body']}\" for chunk in context])\n\n    prompt = PROMPT_TEMPLATE.format(question=question, context=formatted_context, level=level)\n    response = client.chat.completions.create(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": \"you are an assistant who responds in json format\"},\n            {\"role\": \"user\", \"content\": prompt}\n        ],\n        response_format={\"type\": \"json_object\"}\n    )\n\n    return json.loads(response.choices[0].message.content)[\"response\"]\n\n\nresponse = generate_response(\n    question=query, \n    context=reranked_chunks.dict()[\"results\"],\n    level=\"advanced\"\n)\n\ndisplay(Markdown(response))\n</pre> from openai import OpenAI import json from IPython.display import Markdown, display   client = OpenAI()  PROMPT_TEMPLATE = \"\"\"     You are a health expert and you will be provided with a question and related context on which needs to provide a well constructed and structured answer.      ## Instructions:     - Avoid fluff and clich\u00e9s: Generate a concise answers and avoid words, phrases, and sentences that do not add any substantial value to the response.     - Tone: needs to be conversational, spartan, use less corporate jargon.     - The answers should have a natural flow and should be easy to understand.     - Assume that the reader has a {level} level of understanding of the topic, so generate response and use terminology accordingly.          ## Question:     {question}      ## Context:     The context provided below is order from most relevant to least relevant to the question. So use the context to accordingly to structure your response.     {context}      ## Response Format:     {{\"response\": \"provide the response using proper markdown formatting.\"}}      ## Response: \"\"\"  def generate_response(question, context, level=\"beginner\"):      formatted_context = \"\\n\".join([f\"---\\n{chunk['document']['title']}\\n{chunk['document']['body']}\" for chunk in context])      prompt = PROMPT_TEMPLATE.format(question=question, context=formatted_context, level=level)     response = client.chat.completions.create(         model=\"gpt-4o-mini\",         messages=[             {\"role\": \"system\", \"content\": \"you are an assistant who responds in json format\"},             {\"role\": \"user\", \"content\": prompt}         ],         response_format={\"type\": \"json_object\"}     )      return json.loads(response.choices[0].message.content)[\"response\"]   response = generate_response(     question=query,      context=reranked_chunks.dict()[\"results\"],     level=\"advanced\" )  display(Markdown(response)) <pre>/Users/vishwasgowda/code/ai-course/.venv/lib/python3.11/site-packages/pydantic/main.py:1097: PydanticDeprecatedSince20: The `__fields_set__` attribute is deprecated, use `model_fields_set` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.9/migration/\n  warnings.warn(\n</pre> <p>To effectively combine intermittent fasting (IF) with high-intensity interval training (HIIT) for improved cardio, follow these guidelines:</p> <ol> <li><p>Timing Your Workouts: Schedule HIIT sessions towards the end of your fasting window. This ensures that you have higher energy levels for intense workouts while still benefiting from the metabolic advantages of fasting.</p> </li> <li><p>Post-Workout Nutrition: After your HIIT workout, break your fast with nutrient-dense foods. Focus on a balance of protein, healthy fats, and carbohydrates to replenish glycogen and support muscle recovery. This strategy promotes muscle gain and enhances cardiovascular health.</p> </li> <li><p>Hydration: Stay well-hydrated. Proper hydration optimizes performance during HIIT and aids recovery afterwards. Make sure to drink water during fasting periods as well.</p> </li> <li><p>Listen to Your Body: Monitor your energy levels and overall well-being. If you experience excessive fatigue or decreased performance, consider adjusting your fasting schedule or the intensity of your HIIT sessions.</p> </li> <li><p>Consistency: Maintain a consistent routine. Results from both intermittent fasting and HIIT build over time, so sticking to a regular schedule is vital for maximizing cardiovascular benefits.</p> </li> </ol> <p>By integrating these strategies, you can leverage the advantages of both intermittent fasting and HIIT to enhance your cardiovascular fitness.</p>"},{"location":"module-3/post_retrieval_strategies/#post-retrieval-strategies","title":"Post Retrieval Strategies\u00b6","text":""},{"location":"module-3/post_retrieval_strategies/#reranking-retrieved-chunks","title":"Reranking Retrieved Chunks\u00b6","text":""},{"location":"module-3/post_retrieval_strategies/#what-is-a-reranker","title":"What is a Reranker?\u00b6","text":"<p>A reranker is a type of machine learning model used in search systems to reorder a set of retrieved documents by relevance to a user query. Imagine you search for something, and the system pulls a bunch of documents. Not all of them are equally useful, though. The reranker steps in after the initial search to figure out which of those documents are most relevant to what you\u2019re asking.</p> <p>At its core, a reranker is typically built using a \"cross-encoder\" model. Unlike traditional search methods, which compress each document and query separately into vectors, a reranker considers the relationship between the query and each document individually. This allows it to provide a more accurate score for how closely a document matches a query, improving the relevance of the results presented to the user.</p>"},{"location":"module-3/post_retrieval_strategies/#why-a-reranker-is-needed","title":"Why a Reranker is Needed\u00b6","text":""},{"location":"module-3/post_retrieval_strategies/#inadequacy-of-vectorkeyword-search","title":"Inadequacy of Vector/Keyword Search\u00b6","text":"<p>Let\u2019s start with the basic problem: vector search, or even traditional keyword search, has limitations. In a typical retrieval-augmented generation (RAG) setup, you\u2019re dealing with a lot of documents\u2014sometimes tens of thousands, other times millions. The first step in a RAG pipeline is usually vector search. Here, documents are turned into numerical representations, or \"vectors,\" and stored in a large vector database. When a user submits a query, it\u2019s also turned into a vector, and the system retrieves documents that are mathematically closest to this query vector.</p> <p>While this sounds straightforward, there\u2019s a catch. Vector search involves compressing the \"meaning\" of a document into a fixed-length vector, typically 768 or 1536 dimensions. This compression inevitably leads to information loss. When we\u2019re crunching documents into smaller vectors, there\u2019s no guarantee that every subtle detail of the document's meaning will be preserved. As a result, highly relevant information might be hidden in documents that don\u2019t make it to the top results of the vector search. You might end up retrieving documents that are good but not great, missing key information that could answer the user\u2019s query better.</p> <p>This problem becomes even more apparent with large datasets. Vector search is good for finding \u201cclose enough\u201d documents fast, but it\u2019s often too blunt for identifying nuanced, highly relevant documents. It doesn\u2019t always account for context either. That\u2019s because the vector embeddings are created before the user query even arrives, meaning the search system doesn\u2019t have a chance to fine-tune those embeddings based on the specific question asked.</p>"},{"location":"module-3/post_retrieval_strategies/#how-a-reranker-overcomes-this","title":"How a Reranker Overcomes This\u00b6","text":"<p>This is where rerankers shine. A reranker takes the top documents retrieved by the vector search and refines their order based on a deeper understanding of both the query and each document. Instead of treating the query and document separately, as vector searches do, a reranker looks at them together. It applies a large transformer model (like BERT) to both the query and the retrieved document, allowing it to understand the relationship between the two in much greater detail.</p> <p>Here\u2019s how it works: after the vector search pulls a set of documents, the reranker model pairs the query with each document, feeds them both into the transformer model, and then calculates a similarity score. This score is based on how well the document answers the specific query. In short, the reranker makes decisions based on the exact words in both the query and the document rather than just their vectorized representations.</p> <p>For example, if the query is \u201cHow do rerankers improve RAG pipelines?\u201d a reranker would look at every document retrieved and determine which ones specifically talk about how rerankers improve RAG pipelines\u2014not just documents that vaguely match the topic. This precision comes at a cost: rerankers are slower because they perform a full transformer computation for each query-document pair. But the accuracy boost makes it worth it in many cases.</p>"},{"location":"module-3/post_retrieval_strategies/#tradeoffs-of-using-a-reranker","title":"Tradeoffs of Using a Reranker\u00b6","text":"<p>While rerankers improve the accuracy of search results, they come with tradeoffs, primarily in terms of speed and computational cost. Rerankers, especially those based on large transformer models, require significant processing power because they perform a full transformer inference for each query-document pair. This makes them much slower than vector search, which only needs to compute a single query vector and compare it with pre-stored document vectors. For real-time systems with high user traffic, this added latency can be a bottleneck.</p> <p>Additionally, the computational cost of reranking increases with the number of documents being reranked. As a result, rerankers are typically used only after an initial retrieval step has reduced the candidate set, balancing the need for accuracy with the need for performance.</p>"},{"location":"module-3/post_retrieval_strategies/#how-rerankers-are-used-in-a-rag-pipeline","title":"How Rerankers Are Used In A RAG Pipeline\u00b6","text":"<p>In a typical RAG pipeline, rerankers are used as part of a two-stage retrieval system. The first stage involves the fast retrieval of documents using vector or keyword search. This stage is designed for speed because we want to narrow down millions of documents to just a handful as quickly as possible.</p> <p>Once the vector search has pulled the top documents (say, the top 25), the reranker steps in. The reranker takes this smaller set of documents and reorders them based on how well they match the user\u2019s query, using its deeper understanding of the content. This ensures that the top results shown to the user are not just \u201cclose enough\u201d but are actually the most relevant documents available.</p> <p>This combination of vector search for speed and reranking for accuracy strikes a balance between performance and relevance. By using vector search as a first pass to trim down the number of documents and then applying rerankers for fine-tuning, the RAG pipeline can deliver better, more precise results to the LLM, improving the quality of the final output.</p>"},{"location":"module-3/post_retrieval_strategies/#implementation","title":"Implementation\u00b6","text":"<p>We are going to use Cohere Reranker for this task. It is one of the best rerankers out there.</p>"},{"location":"module-3/post_retrieval_strategies/#comparing-retrieved-chunks-with-reranked-chunks","title":"Comparing retrieved chunks with reranked chunks\u00b6","text":""},{"location":"module-3/post_retrieval_strategies/#response-generation","title":"Response Generation\u00b6","text":"<p>Response Generation is basically the last step in the RAG pipeline. It is the process of generating a response based on the retrieved and reranked chunks. This is basically done by prompting the model with the query, context (retrieved chunks), instructions/guidelines on generating the response, and any other relevant information. The model then generates a response based on this information. These instructions and other relvant information is highly specific to the domain and the task at hand.</p>"},{"location":"module-3/pre_retrieval_strategies/","title":"Pre Retrieval Strategies","text":"In\u00a0[1]: Copied! <pre>import json\n\nwith open(\"./articles.json\", \"r\") as f:\n    articles = json.load(f)\n\narticle_categories = []\nauthors = []\nfor article in articles:\n    article_categories.append(article[\"category\"])\n    authors.append(article[\"author\"])\n\n# set(article_categories)\nlist(set(authors))\n</pre> import json  with open(\"./articles.json\", \"r\") as f:     articles = json.load(f)  article_categories = [] authors = [] for article in articles:     article_categories.append(article[\"category\"])     authors.append(article[\"author\"])  # set(article_categories) list(set(authors)) Out[1]: <pre>['TechCrunch',\n 'MDN Web Docs',\n 'Towards Data Science',\n 'Smashing Magazine',\n 'Krebs on Security',\n 'Codecademy',\n 'GeeksForGeeks',\n 'KDnuggets']</pre> In\u00a0[2]: Copied! <pre>from enum import Enum\n\n# List of categories and authors\narticle_categories = ['Cybersecurity', 'Data Science', 'ML', 'Programming', 'Web Development']\nauthors = ['Towards Data Science', 'Smashing Magazine', 'Codecademy', 'MDN Web Docs', \n           'Krebs on Security', 'GeeksForGeeks', 'Analytics Vidhya', 'KDnuggets', 'TechCrunch']\n\n# Dynamically create Enum classes\nArticleCategory = Enum('ArticleCategory', {category.replace(' ', '_').upper(): category for category in article_categories})\nAuthor = Enum('Author', {author.replace(' ', '_').upper(): author for author in authors})\n</pre> from enum import Enum  # List of categories and authors article_categories = ['Cybersecurity', 'Data Science', 'ML', 'Programming', 'Web Development'] authors = ['Towards Data Science', 'Smashing Magazine', 'Codecademy', 'MDN Web Docs',             'Krebs on Security', 'GeeksForGeeks', 'Analytics Vidhya', 'KDnuggets', 'TechCrunch']  # Dynamically create Enum classes ArticleCategory = Enum('ArticleCategory', {category.replace(' ', '_').upper(): category for category in article_categories}) Author = Enum('Author', {author.replace(' ', '_').upper(): author for author in authors})  In\u00a0[3]: Copied! <pre>from pydantic import BaseModel\nfrom typing import Optional\n\nPROMPT = \"\"\" \n    Your task is to transform a given query into a schema/structure given.\n    This schema will be used to filter articles based on the given query.\n\n    Here is a description of the parameters:\n    - rewritten_query: rewrite query that is more keyword based like it is for a search engine.\n    - author: Only if any particular author of the article mentioned in the query.\n    - category: Only if any particular category of the article mentioned in the query\n    - date_range: Create a date range if there is any mention of time period/date in the query. like a year or month.\n\"\"\"\n\nclass DateRange(BaseModel):\n    start_date: str\n    end: str\n\nclass ArticleQuery(BaseModel):\n    rewritten_query: str\n    author: Optional[Author]\n    category: Optional[ArticleCategory]\n    date_range: DateRange\n</pre> from pydantic import BaseModel from typing import Optional  PROMPT = \"\"\"      Your task is to transform a given query into a schema/structure given.     This schema will be used to filter articles based on the given query.      Here is a description of the parameters:     - rewritten_query: rewrite query that is more keyword based like it is for a search engine.     - author: Only if any particular author of the article mentioned in the query.     - category: Only if any particular category of the article mentioned in the query     - date_range: Create a date range if there is any mention of time period/date in the query. like a year or month. \"\"\"  class DateRange(BaseModel):     start_date: str     end: str  class ArticleQuery(BaseModel):     rewritten_query: str     author: Optional[Author]     category: Optional[ArticleCategory]     date_range: DateRange  In\u00a0[4]: Copied! <pre>from openai import OpenAI\nfrom dotenv import load_dotenv\n\nload_dotenv(\"./../.env\")\n\ndef breakdown_query(query, system_prompt, response_format):\n    client = OpenAI()\n    response = client.beta.chat.completions.parse(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": system_prompt},\n            {\"role\": \"user\", \"content\": query}\n        ],\n        response_format=response_format\n    )\n\n    return response.choices[0].message.parsed\n\n\nresponse1 = breakdown_query(\"what is machine learning?\", PROMPT, ArticleQuery)\nprint(response1)\n</pre> from openai import OpenAI from dotenv import load_dotenv  load_dotenv(\"./../.env\")  def breakdown_query(query, system_prompt, response_format):     client = OpenAI()     response = client.beta.chat.completions.parse(         model=\"gpt-4o-mini\",         messages=[             {\"role\": \"system\", \"content\": system_prompt},             {\"role\": \"user\", \"content\": query}         ],         response_format=response_format     )      return response.choices[0].message.parsed   response1 = breakdown_query(\"what is machine learning?\", PROMPT, ArticleQuery) print(response1) <pre>rewritten_query='definition of machine learning' author=None category=&lt;ArticleCategory.ML: 'ML'&gt; date_range=DateRange(start_date='', end='')\n</pre> In\u00a0[5]: Copied! <pre>query = \"cyber security in 2022\"\nresponse2 = breakdown_query(query, PROMPT, ArticleQuery)\nresponse2\n</pre> query = \"cyber security in 2022\" response2 = breakdown_query(query, PROMPT, ArticleQuery) response2 Out[5]: <pre>ArticleQuery(rewritten_query='cybersecurity 2022', author=None, category=&lt;ArticleCategory.CYBERSECURITY: 'Cybersecurity'&gt;, date_range=DateRange(start_date='2022-01-01', end='2022-12-31'))</pre> In\u00a0[6]: Copied! <pre>query = \"what are articles from Towards Data Science in 2022\"\nresponse3 = breakdown_query(query, PROMPT, ArticleQuery)\nresponse3\n</pre> query = \"what are articles from Towards Data Science in 2022\" response3 = breakdown_query(query, PROMPT, ArticleQuery) response3 Out[6]: <pre>ArticleQuery(rewritten_query='articles from Towards Data Science in 2022', author=&lt;Author.TOWARDS_DATA_SCIENCE: 'Towards Data Science'&gt;, category=None, date_range=DateRange(start_date='2022-01-01', end='2022-12-31'))</pre> <p>Run command <code>kill -9 $(lsof -t -i :8079)</code> in terminal if you want to reconnect to client</p> In\u00a0[7]: Copied! <pre>import weaviate\nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv(\"./../.env\")\n\nclient = weaviate.connect_to_embedded(\n    headers={\n        \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_API_KEY\")\n    }\n)\narticle = client.collections.get(\"Article\")\n</pre> import weaviate from dotenv import load_dotenv import os  load_dotenv(\"./../.env\")  client = weaviate.connect_to_embedded(     headers={         \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_API_KEY\")     } ) article = client.collections.get(\"Article\")  <pre>{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-09-25T12:24:43+05:30\"}\n{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-09-25T12:24:43+05:30\"}\n{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-09-25T12:24:43+05:30\"}\n{\"level\":\"info\",\"msg\":\"module offload-s3 is enabled\",\"time\":\"2024-09-25T12:24:43+05:30\"}\n{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-09-25T12:24:43+05:30\"}\n{\"level\":\"info\",\"msg\":\"open cluster service\",\"servers\":{\"Embedded_at_8079\":53536},\"time\":\"2024-09-25T12:24:43+05:30\"}\n{\"address\":\"172.22.13.215:53537\",\"level\":\"info\",\"msg\":\"starting cloud rpc server ...\",\"time\":\"2024-09-25T12:24:43+05:30\"}\n{\"level\":\"info\",\"msg\":\"starting raft sub-system ...\",\"time\":\"2024-09-25T12:24:43+05:30\"}\n{\"address\":\"172.22.13.215:53536\",\"level\":\"info\",\"msg\":\"tcp transport\",\"tcpMaxPool\":3,\"tcpTimeout\":10000000000,\"time\":\"2024-09-25T12:24:43+05:30\"}\n{\"level\":\"info\",\"msg\":\"loading local db\",\"time\":\"2024-09-25T12:24:43+05:30\"}\n{\"level\":\"info\",\"msg\":\"local DB successfully loaded\",\"time\":\"2024-09-25T12:24:43+05:30\"}\n{\"level\":\"info\",\"msg\":\"schema manager loaded\",\"n\":0,\"time\":\"2024-09-25T12:24:43+05:30\"}\n{\"level\":\"info\",\"metadata_only_voters\":false,\"msg\":\"construct a new raft node\",\"name\":\"Embedded_at_8079\",\"time\":\"2024-09-25T12:24:43+05:30\"}\n{\"id\":\"2-3-1726727697440\",\"last-index\":3,\"last-term\":2,\"level\":\"info\",\"msg\":\"starting restore from snapshot\",\"size-in-bytes\":21578,\"time\":\"2024-09-25T12:24:43+05:30\"}\n{\"level\":\"info\",\"msg\":\"restoring schema from snapshot\",\"time\":\"2024-09-25T12:24:43+05:30\"}\n{\"level\":\"info\",\"msg\":\"successfully restored schema from snapshot\",\"time\":\"2024-09-25T12:24:43+05:30\"}\n{\"last_applied_index\":0,\"last_snapshot_index\":3,\"last_store_log_applied_index\":60,\"level\":\"info\",\"msg\":\"load local db from snapshot\",\"time\":\"2024-09-25T12:24:43+05:30\"}\n{\"action\":\"\",\"id\":\"2-3-1726727697440\",\"last-index\":3,\"last-term\":2,\"level\":\"info\",\"msg\":\"snapshot restore progress\",\"percent-complete\":\"[100.00]%\",\"read-bytes\":21578,\"size-in-bytes\":21578,\"time\":\"2024-09-25T12:24:43+05:30\"}\n{\"id\":\"2-3-1726727697440\",\"last-index\":3,\"last-term\":2,\"level\":\"info\",\"msg\":\"restored from snapshot\",\"size-in-bytes\":21578,\"time\":\"2024-09-25T12:24:43+05:30\"}\n{\"action\":\"raft\",\"index\":57,\"level\":\"info\",\"msg\":\"raft initial configuration\",\"servers\":\"[[{Suffrage:Voter ID:Embedded_at_8079 Address:172.22.13.215:53421}]]\",\"time\":\"2024-09-25T12:24:43+05:30\"}\n{\"action\":\"raft\",\"follower\":{},\"leader-address\":\"\",\"leader-id\":\"\",\"level\":\"info\",\"msg\":\"raft entering follower state\",\"time\":\"2024-09-25T12:24:43+05:30\"}\n{\"last_snapshot_index\":3,\"last_store_applied_index\":3,\"last_store_log_applied_index\":60,\"level\":\"info\",\"msg\":\"raft node constructed\",\"raft_applied_index\":3,\"raft_last_index\":60,\"time\":\"2024-09-25T12:24:43+05:30\"}\n{\"action\":\"raft\",\"last-leader-addr\":\"\",\"last-leader-id\":\"\",\"level\":\"warning\",\"msg\":\"raft heartbeat timeout reached, starting election\",\"time\":\"2024-09-25T12:24:44+05:30\"}\n{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft entering candidate state\",\"node\":{},\"term\":23,\"time\":\"2024-09-25T12:24:44+05:30\"}\n{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft election won\",\"tally\":1,\"term\":23,\"time\":\"2024-09-25T12:24:45+05:30\"}\n{\"action\":\"raft\",\"leader\":{},\"level\":\"info\",\"msg\":\"raft entering leader state\",\"time\":\"2024-09-25T12:24:45+05:30\"}\n{\"level\":\"info\",\"msg\":\"reload local db: update schema ...\",\"time\":\"2024-09-25T12:24:45+05:30\"}\n{\"index\":\"LlamaIndex\",\"level\":\"info\",\"msg\":\"reload local index\",\"time\":\"2024-09-25T12:24:45+05:30\"}\n{\"index\":\"Article\",\"level\":\"info\",\"msg\":\"reload local index\",\"time\":\"2024-09-25T12:24:45+05:30\"}\n{\"action\":\"bootstrap\",\"level\":\"info\",\"msg\":\"node reporting ready, node has probably recovered cluster from raft config. Exiting bootstrap process\",\"time\":\"2024-09-25T12:24:45+05:30\"}\n{\"docker_image_tag\":\"unknown\",\"level\":\"info\",\"msg\":\"configured versions\",\"server_version\":\"1.26.1\",\"time\":\"2024-09-25T12:24:45+05:30\"}\n{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50050\",\"time\":\"2024-09-25T12:24:45+05:30\"}\n{\"address\":\"172.22.13.215:53536\",\"level\":\"info\",\"msg\":\"current Leader\",\"time\":\"2024-09-25T12:24:45+05:30\"}\n{\"action\":\"restapi_management\",\"docker_image_tag\":\"unknown\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-09-25T12:24:45+05:30\"}\n</pre> In\u00a0[8]: Copied! <pre>import textwrap\n\ndef print_objects(objects):\n    \"\"\"\n        a function to print the retrieved objects\n    \"\"\"\n    for obj in objects:\n        print(f\"ID: {obj.uuid.int}\")\n        metadata = [{k: round(v, 2) if isinstance(v, float) else v} for k, v in obj.metadata.__dict__.items() if v is not None]\n        print(f\"Metadata: {metadata}\")\n        print(f\"Title: {obj.properties['title']}\")\n        print(f\"Date: {obj.properties['date']}\")\n        print(f\"Category: {obj.properties['category']}\")\n        print(f\"Author: {obj.properties['author']}\")\n        print(f\"Body: {textwrap.shorten(obj.properties['body'], width=100)}\")\n        print()\n</pre> import textwrap  def print_objects(objects):     \"\"\"         a function to print the retrieved objects     \"\"\"     for obj in objects:         print(f\"ID: {obj.uuid.int}\")         metadata = [{k: round(v, 2) if isinstance(v, float) else v} for k, v in obj.metadata.__dict__.items() if v is not None]         print(f\"Metadata: {metadata}\")         print(f\"Title: {obj.properties['title']}\")         print(f\"Date: {obj.properties['date']}\")         print(f\"Category: {obj.properties['category']}\")         print(f\"Author: {obj.properties['author']}\")         print(f\"Body: {textwrap.shorten(obj.properties['body'], width=100)}\")         print() In\u00a0[9]: Copied! <pre>from weaviate.classes.query import Filter\nfrom datetime import datetime, timezone\nfrom weaviate.classes.query import MetadataQuery\n\ndef retrieve(params: ArticleQuery):\n    start_date = datetime.strptime(params.date_range.start_date, \"%Y-%m-%d\").replace(tzinfo=timezone.utc) if params.date_range.start_date else None\n    end_date = datetime.strptime(params.date_range.end, \"%Y-%m-%d\").replace(tzinfo=timezone.utc) if params.date_range.end else None\n\n    # Collect filters in a list\n    filters_list = []\n    if params.author:\n        filters_list.append(Filter.by_property(\"author\").equal(params.author.value))\n    if params.category:\n        filters_list.append(Filter.by_property(\"category\").equal(params.category.value))\n    if start_date:\n        filters_list.append(Filter.by_property(\"date\").greater_than(start_date))\n    if end_date:\n        filters_list.append(Filter.by_property(\"date\").less_than(end_date))\n\n    # Combine all filters using the AND (&amp;) operator, if any filters exist\n    filters = None\n    if filters_list:\n        filters = filters_list[0]\n        for f in filters_list[1:]:\n            filters = filters &amp; f\n            \n    chunks = article.query.near_text(\n        query=params.rewritten_query,\n        filters=filters if filters else None,\n        return_metadata=MetadataQuery(distance=True, certainty=True),\n        limit=3\n    )\n\n    return chunks.objects\n\nprint(f\"Query: {response1}\\n\")\nchunks = retrieve(response1)\nprint_objects(chunks)\n</pre> from weaviate.classes.query import Filter from datetime import datetime, timezone from weaviate.classes.query import MetadataQuery  def retrieve(params: ArticleQuery):     start_date = datetime.strptime(params.date_range.start_date, \"%Y-%m-%d\").replace(tzinfo=timezone.utc) if params.date_range.start_date else None     end_date = datetime.strptime(params.date_range.end, \"%Y-%m-%d\").replace(tzinfo=timezone.utc) if params.date_range.end else None      # Collect filters in a list     filters_list = []     if params.author:         filters_list.append(Filter.by_property(\"author\").equal(params.author.value))     if params.category:         filters_list.append(Filter.by_property(\"category\").equal(params.category.value))     if start_date:         filters_list.append(Filter.by_property(\"date\").greater_than(start_date))     if end_date:         filters_list.append(Filter.by_property(\"date\").less_than(end_date))      # Combine all filters using the AND (&amp;) operator, if any filters exist     filters = None     if filters_list:         filters = filters_list[0]         for f in filters_list[1:]:             filters = filters &amp; f                  chunks = article.query.near_text(         query=params.rewritten_query,         filters=filters if filters else None,         return_metadata=MetadataQuery(distance=True, certainty=True),         limit=3     )      return chunks.objects  print(f\"Query: {response1}\\n\") chunks = retrieve(response1) print_objects(chunks)  <pre>Query: rewritten_query='definition of machine learning' author=None category=&lt;ArticleCategory.ML: 'ML'&gt; date_range=DateRange(start_date='', end='')\n\n</pre> <pre>{\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry started\",\"payload\":\"\\u0026{MachineID:d52e011e-8305-416e-8f39-2e6299413b63 Type:INIT Version:1.26.1 NumObjects:0 OS:darwin Arch:arm64 UsedModules:[text2vec-openai]}\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Trying to recover...\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/objects/segment-1727247230532865000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/objects/segment-1727247230532865000.wal\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Trying to recover...\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title/segment-1727247230533512000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title/segment-1727247230533512000.wal\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Trying to recover...\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title_searchable/segment-1727247230533664000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_title_searchable/segment-1727247230533664000.wal\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Trying to recover...\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body/segment-1727247230533828000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body/segment-1727247230533828000.wal\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Trying to recover...\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body_searchable/segment-1727247230533980000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_body_searchable/segment-1727247230533980000.wal\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Trying to recover...\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_date/segment-1727247230534124000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_date/segment-1727247230534124000.wal\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Trying to recover...\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category/segment-1727247230534291000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category/segment-1727247230534291000.wal\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Trying to recover...\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category_searchable/segment-1727247230534438000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_category_searchable/segment-1727247230534438000.wal\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Trying to recover...\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author/segment-1727247230534981000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author/segment-1727247230534981000.wal\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Trying to recover...\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author_searchable/segment-1727247230535123000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property_author_searchable/segment-1727247230535123000.wal\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"active write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Trying to recover...\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property__id/segment-1727247230534599000\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal_success\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"info\",\"msg\":\"successfully recovered from write-ahead-log\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/lsm/property__id/segment-1727247230534599000.wal\",\"shard\":\"PHiJNusYv2bT\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-09-25T12:24:46+05:30\",\"wait_for_cache_prefill\":false}\n{\"level\":\"info\",\"msg\":\"Completed loading shard article_PHiJNusYv2bT in 74.413083ms\",\"time\":\"2024-09-25T12:24:46+05:30\"}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-09-25T12:24:46+05:30\",\"took\":726833}\n</pre> <pre>ID: 235959584379154997552071134050082173029\nMetadata: [{'distance': 0.34}, {'certainty': 0.83}]\nTitle: Machine Learning Basics\nDate: 2023-03-05 00:00:00+00:00\nCategory: ML\nAuthor: TechCrunch\nBody: Machine learning is a branch of artificial intelligence that focuses on building systems that [...]\n\nID: 66177066615778596449200477828369435490\nMetadata: [{'distance': 0.36}, {'certainty': 0.82}]\nTitle: Machine Learning\nDate: 2021-10-01 00:00:00+00:00\nCategory: ML\nAuthor: Towards Data Science\nBody: Machine learning is a subset of artificial intelligence (AI) that provides systems the ability [...]\n\nID: 37499734945959922522607306974367251245\nMetadata: [{'distance': 0.48}, {'certainty': 0.76}]\nTitle: Introduction to Deep Learning\nDate: 2022-07-10 00:00:00+00:00\nCategory: ML\nAuthor: Towards Data Science\nBody: Deep learning is a subset of machine learning that uses neural networks with many layers to [...]\n\n</pre> In\u00a0[10]: Copied! <pre>print(f\"Query: {response2}\\n\")\nchunks = retrieve(response2)\nprint_objects(chunks)\n</pre> print(f\"Query: {response2}\\n\") chunks = retrieve(response2) print_objects(chunks) <pre>Query: rewritten_query='cybersecurity 2022' author=None category=&lt;ArticleCategory.CYBERSECURITY: 'Cybersecurity'&gt; date_range=DateRange(start_date='2022-01-01', end='2022-12-31')\n\nID: 111770961923860747703082376322890795880\nMetadata: [{'distance': 0.48}, {'certainty': 0.76}]\nTitle: The Importance of Cybersecurity\nDate: 2022-12-12 00:00:00+00:00\nCategory: Cybersecurity\nAuthor: Krebs on Security\nBody: Cybersecurity involves protecting computer systems and networks from information disclosure, [...]\n\nID: 9620050475437321785307488639092868804\nMetadata: [{'distance': 0.55}, {'certainty': 0.72}]\nTitle: Cryptography\nDate: 2022-08-25 00:00:00+00:00\nCategory: Cybersecurity\nAuthor: TechCrunch\nBody: Cryptography is the study and practice of securing communication and data from unauthorized [...]\n\n</pre> In\u00a0[11]: Copied! <pre>print(f\"Query: {response3}\\n\")\nchunks = retrieve(response3)\nprint_objects(chunks)\n</pre> print(f\"Query: {response3}\\n\") chunks = retrieve(response3) print_objects(chunks) <pre>Query: rewritten_query='articles from Towards Data Science in 2022' author=&lt;Author.TOWARDS_DATA_SCIENCE: 'Towards Data Science'&gt; category=None date_range=DateRange(start_date='2022-01-01', end='2022-12-31')\n\nID: 37499734945959922522607306974367251245\nMetadata: [{'distance': 0.55}, {'certainty': 0.73}]\nTitle: Introduction to Deep Learning\nDate: 2022-07-10 00:00:00+00:00\nCategory: ML\nAuthor: Towards Data Science\nBody: Deep learning is a subset of machine learning that uses neural networks with many layers to [...]\n\n</pre> In\u00a0[28]: Copied! <pre>from typing import List\nfrom openai import OpenAI\nfrom dotenv import load_dotenv\n\nclass SubQueries(BaseModel):\n    queries: List[ArticleQuery]\n\nload_dotenv(\"./../.env\")\n\nMULTI_STEP_PROMPT = \"\"\" \n    Your task is to break down a query into multiple sub queries which will be executed step by step and retrieve information for the subquery\n    Each step MUST follow the given schema/structure.\n    This schema will be used to filter articles based on the given query.\n\n    Use below example just as a reference:\n    Query: Compare 'A' and 'B' --&gt; query1: defn of 'A', query2: defn of 'B'\n\n    Here is a description of the parameters:\n    - rewritten_query: rewrite query that is more keyword based like it is for a search engine.\n    - author: Only if any particular author of the article mentioned in the query. DO NOT use unless it is obvious.\n    - category: Only if any particular category of the article mentioned in the query. DO NOT use unless it is obvious.\n    - date_range: Create a date range if there is any mention of time period/date in the query. like a year or month.\n\"\"\"\n\ndef breakdown_query(query, system_prompt, response_format):\n    client = OpenAI()\n    response = client.beta.chat.completions.parse(\n        model=\"gpt-4o-mini\",\n        messages=[\n            {\"role\": \"system\", \"content\": system_prompt},\n            {\"role\": \"user\", \"content\": query}\n        ],\n        response_format=response_format\n    )\n\n    return response.choices[0].message.parsed\n\nbreakdown = breakdown_query(\"What does Meta's financial health look like?\", MULTI_STEP_PROMPT, SubQueries)\nbreakdown\n</pre> from typing import List from openai import OpenAI from dotenv import load_dotenv  class SubQueries(BaseModel):     queries: List[ArticleQuery]  load_dotenv(\"./../.env\")  MULTI_STEP_PROMPT = \"\"\"      Your task is to break down a query into multiple sub queries which will be executed step by step and retrieve information for the subquery     Each step MUST follow the given schema/structure.     This schema will be used to filter articles based on the given query.      Use below example just as a reference:     Query: Compare 'A' and 'B' --&gt; query1: defn of 'A', query2: defn of 'B'      Here is a description of the parameters:     - rewritten_query: rewrite query that is more keyword based like it is for a search engine.     - author: Only if any particular author of the article mentioned in the query. DO NOT use unless it is obvious.     - category: Only if any particular category of the article mentioned in the query. DO NOT use unless it is obvious.     - date_range: Create a date range if there is any mention of time period/date in the query. like a year or month. \"\"\"  def breakdown_query(query, system_prompt, response_format):     client = OpenAI()     response = client.beta.chat.completions.parse(         model=\"gpt-4o-mini\",         messages=[             {\"role\": \"system\", \"content\": system_prompt},             {\"role\": \"user\", \"content\": query}         ],         response_format=response_format     )      return response.choices[0].message.parsed  breakdown = breakdown_query(\"What does Meta's financial health look like?\", MULTI_STEP_PROMPT, SubQueries) breakdown Out[28]: <pre>SubQueries(queries=[ArticleQuery(rewritten_query='Meta financial health overview', author=None, category=None, date_range=DateRange(start_date='2022-01-01', end='2023-10-31')), ArticleQuery(rewritten_query='Meta quarterly financial report', author=None, category=None, date_range=DateRange(start_date='2022-01-01', end='2023-10-31')), ArticleQuery(rewritten_query='Meta revenue and profit analysis', author=None, category=None, date_range=DateRange(start_date='2022-01-01', end='2023-10-31'))])</pre> In\u00a0[22]: Copied! <pre>breakdown = breakdown_query(\"what is Data structures and algorithms?\", MULTI_STEP_PROMPT, SubQueries)\nbreakdown\n</pre> breakdown = breakdown_query(\"what is Data structures and algorithms?\", MULTI_STEP_PROMPT, SubQueries) breakdown Out[22]: <pre>MultiStep(queries=[ArticleQuery(rewritten_query='What are data structures?', author=None, category=None, date_range=DateRange(start_date='.', end='.0')), ArticleQuery(rewritten_query='What are algorithms?', author=None, category=None, date_range=DateRange(start_date='.', end='.0'))])</pre>"},{"location":"module-3/pre_retrieval_strategies/#pre-retrieval-strategies","title":"Pre Retrieval Strategies\u00b6","text":""},{"location":"module-3/pre_retrieval_strategies/#query-transformation","title":"Query Transformation\u00b6","text":""},{"location":"module-3/pre_retrieval_strategies/#convert-to-multiple-sub-queries","title":"Convert To Multiple Sub Queries\u00b6","text":"<p>This technique is very similar to CoT promting, but instead of working with tools and dynamically generating the next sub queries, we are working with just one knowledge base and generating the sub-queries in parallel.</p> <p>Breaking down queries, is particularly useful for queries which requires retrieving a varied kinds of chunks, which can't be done with a simple vector search.</p> <p>for example: Query: What does Meta's financial health look like?</p> <p>A straightforward vector search or hybrid search would just find chunks that have words like 'financial health' , 'Meta' or other semantically similar words. This is sub-optimal.</p> <p>Let's say we breakdown the queries into multiple sub-queries:</p> <ul> <li>Meta finances overview</li> <li>Meta financial statements</li> <li>Meta stock trend</li> <li>Meta earnings call</li> </ul> <p>The combined chunks retrievd for all these queries would be much more relevant, and answer the user's query much more accurately.</p>"},{"location":"module-3/retrieval_strategies/","title":"Retrieval Strategies","text":"In\u00a0[2]: Copied! <pre>import weaviate\nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv(\"./../.env\")\n\nclient = weaviate.connect_to_embedded(\n    headers={\n        \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_API_KEY\")\n    }\n)\n</pre> import weaviate from dotenv import load_dotenv import os  load_dotenv(\"./../.env\")  client = weaviate.connect_to_embedded(     headers={         \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_API_KEY\")     } ) <pre>{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-09-25T12:23:46+05:30\"}\n{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-09-25T12:23:46+05:30\"}\n{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-09-25T12:23:46+05:30\"}\n{\"level\":\"info\",\"msg\":\"module offload-s3 is enabled\",\"time\":\"2024-09-25T12:23:46+05:30\"}\n{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-09-25T12:23:46+05:30\"}\n{\"level\":\"info\",\"msg\":\"open cluster service\",\"servers\":{\"Embedded_at_8079\":53421},\"time\":\"2024-09-25T12:23:46+05:30\"}\n{\"address\":\"172.22.13.215:53422\",\"level\":\"info\",\"msg\":\"starting cloud rpc server ...\",\"time\":\"2024-09-25T12:23:46+05:30\"}\n{\"level\":\"info\",\"msg\":\"starting raft sub-system ...\",\"time\":\"2024-09-25T12:23:46+05:30\"}\n{\"address\":\"172.22.13.215:53421\",\"level\":\"info\",\"msg\":\"tcp transport\",\"tcpMaxPool\":3,\"tcpTimeout\":10000000000,\"time\":\"2024-09-25T12:23:46+05:30\"}\n{\"level\":\"info\",\"msg\":\"loading local db\",\"time\":\"2024-09-25T12:23:46+05:30\"}\n{\"level\":\"info\",\"msg\":\"local DB successfully loaded\",\"time\":\"2024-09-25T12:23:46+05:30\"}\n{\"level\":\"info\",\"msg\":\"schema manager loaded\",\"n\":0,\"time\":\"2024-09-25T12:23:46+05:30\"}\n{\"level\":\"info\",\"metadata_only_voters\":false,\"msg\":\"construct a new raft node\",\"name\":\"Embedded_at_8079\",\"time\":\"2024-09-25T12:23:46+05:30\"}\n{\"id\":\"2-3-1726727697440\",\"last-index\":3,\"last-term\":2,\"level\":\"info\",\"msg\":\"starting restore from snapshot\",\"size-in-bytes\":21578,\"time\":\"2024-09-25T12:23:46+05:30\"}\n{\"level\":\"info\",\"msg\":\"restoring schema from snapshot\",\"time\":\"2024-09-25T12:23:46+05:30\"}\n{\"level\":\"info\",\"msg\":\"successfully restored schema from snapshot\",\"time\":\"2024-09-25T12:23:46+05:30\"}\n{\"last_applied_index\":0,\"last_snapshot_index\":3,\"last_store_log_applied_index\":52,\"level\":\"info\",\"msg\":\"load local db from snapshot\",\"time\":\"2024-09-25T12:23:46+05:30\"}\n{\"action\":\"\",\"id\":\"2-3-1726727697440\",\"last-index\":3,\"last-term\":2,\"level\":\"info\",\"msg\":\"snapshot restore progress\",\"percent-complete\":\"[100.00]%\",\"read-bytes\":21578,\"size-in-bytes\":21578,\"time\":\"2024-09-25T12:23:46+05:30\"}\n{\"id\":\"2-3-1726727697440\",\"last-index\":3,\"last-term\":2,\"level\":\"info\",\"msg\":\"restored from snapshot\",\"size-in-bytes\":21578,\"time\":\"2024-09-25T12:23:46+05:30\"}\n{\"action\":\"raft\",\"index\":55,\"level\":\"info\",\"msg\":\"raft initial configuration\",\"servers\":\"[[{Suffrage:Voter ID:Embedded_at_8079 Address:172.22.13.215:53281}]]\",\"time\":\"2024-09-25T12:23:46+05:30\"}\n{\"action\":\"raft\",\"follower\":{},\"leader-address\":\"\",\"leader-id\":\"\",\"level\":\"info\",\"msg\":\"raft entering follower state\",\"time\":\"2024-09-25T12:23:46+05:30\"}\n{\"last_snapshot_index\":3,\"last_store_applied_index\":3,\"last_store_log_applied_index\":52,\"level\":\"info\",\"msg\":\"raft node constructed\",\"raft_applied_index\":3,\"raft_last_index\":55,\"time\":\"2024-09-25T12:23:46+05:30\"}\n{\"action\":\"raft\",\"last-leader-addr\":\"\",\"last-leader-id\":\"\",\"level\":\"warning\",\"msg\":\"raft heartbeat timeout reached, starting election\",\"time\":\"2024-09-25T12:23:48+05:30\"}\n{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft entering candidate state\",\"node\":{},\"term\":22,\"time\":\"2024-09-25T12:23:48+05:30\"}\n{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft election won\",\"tally\":1,\"term\":22,\"time\":\"2024-09-25T12:23:48+05:30\"}\n{\"action\":\"raft\",\"leader\":{},\"level\":\"info\",\"msg\":\"raft entering leader state\",\"time\":\"2024-09-25T12:23:48+05:30\"}\n{\"level\":\"info\",\"msg\":\"reload local db: update schema ...\",\"time\":\"2024-09-25T12:23:48+05:30\"}\n{\"index\":\"Article\",\"level\":\"info\",\"msg\":\"reload local index\",\"time\":\"2024-09-25T12:23:48+05:30\"}\n{\"action\":\"raft\",\"command\":0,\"level\":\"info\",\"msg\":\"raft updating configuration\",\"server-addr\":\"172.22.13.215:53421\",\"server-id\":\"Embedded_at_8079\",\"servers\":\"[[{Suffrage:Voter ID:Embedded_at_8079 Address:172.22.13.215:53421}]]\",\"time\":\"2024-09-25T12:23:48+05:30\"}\n{\"index\":\"LlamaIndex\",\"level\":\"info\",\"msg\":\"reload local index\",\"time\":\"2024-09-25T12:23:48+05:30\"}\n{\"docker_image_tag\":\"unknown\",\"level\":\"info\",\"msg\":\"configured versions\",\"server_version\":\"1.26.1\",\"time\":\"2024-09-25T12:23:48+05:30\"}\n{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50050\",\"time\":\"2024-09-25T12:23:48+05:30\"}\n{\"address\":\"172.22.13.215:53421\",\"level\":\"info\",\"msg\":\"current Leader\",\"time\":\"2024-09-25T12:23:48+05:30\"}\n{\"action\":\"restapi_management\",\"docker_image_tag\":\"unknown\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-09-25T12:23:48+05:30\"}\n{\"action\":\"bootstrap\",\"leader\":\"172.22.13.215:53421\",\"level\":\"info\",\"msg\":\"successfully joined cluster\",\"time\":\"2024-09-25T12:23:48+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/objects/segment-1727246350642040000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/objects/segment-1727246694722802000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/objects/segment-1727247041218338000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_title/segment-1727246350655645000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_title/segment-1727246694729827000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_title/segment-1727247041224353000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_title_searchable/segment-1727246350664884000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_title_searchable/segment-1727246694734820000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_title_searchable/segment-1727247041229310000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_body/segment-1727246350675014000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_body/segment-1727246694739788000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_body/segment-1727247041234281000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_body_searchable/segment-1727246350686479000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_body_searchable/segment-1727246694743842000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_body_searchable/segment-1727247041239297000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_date/segment-1727246350697755000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_date/segment-1727246694748874000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_date/segment-1727247041244300000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_category/segment-1727246350707667000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_category/segment-1727246694752851000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_category/segment-1727247041249324000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_category_searchable/segment-1727246350717597000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_category_searchable/segment-1727246694757834000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_category_searchable/segment-1727247041253228000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_author/segment-1727246350733638000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_author/segment-1727246694761896000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_author/segment-1727247041258310000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_author_searchable/segment-1727246350740939000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_author_searchable/segment-1727246694767850000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property_author_searchable/segment-1727247041262289000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property__id/segment-1727246350725669000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property__id/segment-1727246694771873000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/pdErif1ChEOS/lsm/property__id/segment-1727247041265298000\",\"shard\":\"pdErif1ChEOS\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-09-25T12:23:49+05:30\",\"wait_for_cache_prefill\":false}\n{\"level\":\"info\",\"msg\":\"Completed loading shard article_pdErif1ChEOS in 48.481625ms\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-09-25T12:23:49+05:30\",\"took\":216458}\n{\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry started\",\"payload\":\"\\u0026{MachineID:0d97a51b-3352-4bf8-8ecc-542738ece1ae Type:INIT Version:1.26.1 NumObjects:0 OS:darwin Arch:arm64 UsedModules:[text2vec-openai]}\",\"time\":\"2024-09-25T12:23:49+05:30\"}\n</pre> In\u00a0[3]: Copied! <pre>from weaviate.classes.config import Property, DataType, Configure\n\nif client.collections.exists(\"Article\"):\n    client.collections.delete(\"Article\")\n\nclient.collections.create(\n    \"Article\",\n    properties=[\n        Property(name=\"title\", data_type=DataType.TEXT),\n        Property(name=\"body\", data_type=DataType.TEXT, vectorize_property_name=True),\n        Property(name=\"date\", data_type=DataType.DATE),\n        Property(name=\"category\", data_type=DataType.TEXT),\n    ],\n    vectorizer_config=Configure.Vectorizer.text2vec_openai(\n        model=\"text-embedding-3-small\"\n    )\n)\n</pre> from weaviate.classes.config import Property, DataType, Configure  if client.collections.exists(\"Article\"):     client.collections.delete(\"Article\")  client.collections.create(     \"Article\",     properties=[         Property(name=\"title\", data_type=DataType.TEXT),         Property(name=\"body\", data_type=DataType.TEXT, vectorize_property_name=True),         Property(name=\"date\", data_type=DataType.DATE),         Property(name=\"category\", data_type=DataType.TEXT),     ],     vectorizer_config=Configure.Vectorizer.text2vec_openai(         model=\"text-embedding-3-small\"     ) ) Out[3]: <pre>&lt;weaviate.collections.collection.sync.Collection at 0x109857d90&gt;</pre> In\u00a0[4]: Copied! <pre>import json\n\nwith open(\"./articles.json\", \"r\") as f:\n    articles_json = json.load(f)\n\narticle = client.collections.get('Article')\n\n\nwith article.batch.dynamic() as batch:  # inserting objects to collection in batch\n    for art in articles_json:\n        batch.add_object(art)\n</pre> import json  with open(\"./articles.json\", \"r\") as f:     articles_json = json.load(f)  article = client.collections.get('Article')   with article.batch.dynamic() as batch:  # inserting objects to collection in batch     for art in articles_json:         batch.add_object(art)  <pre>{\"level\":\"warning\",\"msg\":\"prop len tracker file /Users/vishwasgowda/.local/share/weaviate/article/PHiJNusYv2bT/proplengths does not exist, creating new tracker\",\"time\":\"2024-09-25T12:23:50+05:30\"}\n{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-09-25T12:23:50+05:30\",\"wait_for_cache_prefill\":false}\n{\"level\":\"info\",\"msg\":\"Created shard article_PHiJNusYv2bT in 2.400917ms\",\"time\":\"2024-09-25T12:23:50+05:30\"}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-09-25T12:23:50+05:30\",\"took\":55625}\n</pre> In\u00a0[5]: Copied! <pre>item_count = 0\nfor item in article.iterator():\n    item_count += 1\nitem_count\n</pre> item_count = 0 for item in article.iterator():     item_count += 1 item_count Out[5]: <pre>13</pre> In\u00a0[6]: Copied! <pre>import textwrap\n\ndef print_objects(objects):\n    \"\"\"\n        a function to print the retrieved objects\n    \"\"\"\n    for obj in objects:\n        print(f\"ID: {obj.uuid.int}\")\n        metadata = [{k: round(v, 2) if isinstance(v, float) else v} for k, v in obj.metadata.__dict__.items() if v is not None]\n        print(f\"Metadata: {metadata}\")\n        print(f\"Title: {obj.properties['title']}\")\n        print(f\"Date: {obj.properties['date']}\")\n        print(f\"Category: {obj.properties['category']}\")\n        print(f\"Author: {obj.properties['author']}\")\n        print(f\"Body: {textwrap.shorten(obj.properties['body'], width=100)}\")\n        print()\n</pre> import textwrap  def print_objects(objects):     \"\"\"         a function to print the retrieved objects     \"\"\"     for obj in objects:         print(f\"ID: {obj.uuid.int}\")         metadata = [{k: round(v, 2) if isinstance(v, float) else v} for k, v in obj.metadata.__dict__.items() if v is not None]         print(f\"Metadata: {metadata}\")         print(f\"Title: {obj.properties['title']}\")         print(f\"Date: {obj.properties['date']}\")         print(f\"Category: {obj.properties['category']}\")         print(f\"Author: {obj.properties['author']}\")         print(f\"Body: {textwrap.shorten(obj.properties['body'], width=100)}\")         print() In\u00a0[7]: Copied! <pre>from weaviate.classes.query import MetadataQuery\n\nresponse = article.query.near_text(\n    query = \"What is machine learning?\",\n    limit=3,    # max no of chunks to be returned\n    return_metadata=MetadataQuery(distance=True, certainty=True),\n    include_vector=True\n)\n\nprint_objects(response.objects)\n</pre> from weaviate.classes.query import MetadataQuery  response = article.query.near_text(     query = \"What is machine learning?\",     limit=3,    # max no of chunks to be returned     return_metadata=MetadataQuery(distance=True, certainty=True),     include_vector=True )  print_objects(response.objects) <pre>ID: 235959584379154997552071134050082173029\nMetadata: [{'distance': 0.37}, {'certainty': 0.82}]\nTitle: Machine Learning Basics\nDate: 2023-03-05 00:00:00+00:00\nCategory: ML\nAuthor: TechCrunch\nBody: Machine learning is a branch of artificial intelligence that focuses on building systems that [...]\n\nID: 66177066615778596449200477828369435490\nMetadata: [{'distance': 0.39}, {'certainty': 0.81}]\nTitle: Machine Learning\nDate: 2021-10-01 00:00:00+00:00\nCategory: ML\nAuthor: Towards Data Science\nBody: Machine learning is a subset of artificial intelligence (AI) that provides systems the ability [...]\n\nID: 37499734945959922522607306974367251245\nMetadata: [{'distance': 0.5}, {'certainty': 0.75}]\nTitle: Introduction to Deep Learning\nDate: 2022-07-10 00:00:00+00:00\nCategory: ML\nAuthor: Towards Data Science\nBody: Deep learning is a subset of machine learning that uses neural networks with many layers to [...]\n\n</pre> In\u00a0[8]: Copied! <pre>response = article.query.bm25(\n    query=\"What is machine learning?\",\n)\n</pre> response = article.query.bm25(     query=\"What is machine learning?\", ) <p>We can limit the properties on which bm25 search is applied by providing the specific properties. We can even increase the importance of a property for the search a by a factor.</p> <p>BM25 search will be applied on these 3 properties while boosting the 'title' property by a facor of 2</p> In\u00a0[9]: Copied! <pre>response = article.query.bm25(\n    query=\"what is machine learning?\",\n    query_properties=['body', 'title^2', 'category'] ,\n    return_metadata=MetadataQuery(score=True, explain_score=True), # metdata specific to BM25 search\n    limit=3\n)\n\nprint_objects(response.objects)\n</pre> response = article.query.bm25(     query=\"what is machine learning?\",     query_properties=['body', 'title^2', 'category'] ,     return_metadata=MetadataQuery(score=True, explain_score=True), # metdata specific to BM25 search     limit=3 )  print_objects(response.objects) <pre>ID: 66177066615778596449200477828369435490\nMetadata: [{'score': 1.27}, {'explain_score': ', BM25F_learning_propLength:39, BM25F_machine_frequency:4, BM25F_machine_propLength:39, BM25F_learning_frequency:4'}]\nTitle: Machine Learning\nDate: 2021-10-01 00:00:00+00:00\nCategory: ML\nAuthor: Towards Data Science\nBody: Machine learning is a subset of artificial intelligence (AI) that provides systems the ability [...]\n\nID: 235959584379154997552071134050082173029\nMetadata: [{'score': 1.15}, {'explain_score': ', BM25F_machine_frequency:4, BM25F_machine_propLength:51, BM25F_learning_frequency:4, BM25F_learning_propLength:51'}]\nTitle: Machine Learning Basics\nDate: 2023-03-05 00:00:00+00:00\nCategory: ML\nAuthor: TechCrunch\nBody: Machine learning is a branch of artificial intelligence that focuses on building systems that [...]\n\nID: 37499734945959922522607306974367251245\nMetadata: [{'score': 0.83}, {'explain_score': ', BM25F_machine_propLength:55, BM25F_learning_frequency:6, BM25F_learning_propLength:59, BM25F_machine_frequency:1'}]\nTitle: Introduction to Deep Learning\nDate: 2022-07-10 00:00:00+00:00\nCategory: ML\nAuthor: Towards Data Science\nBody: Deep learning is a subset of machine learning that uses neural networks with many layers to [...]\n\n</pre> <p>Let's breakdown the <code>explain_score</code> metadata for the first chunk:</p> <ul> <li><code>BM25F_machine_frequency</code>: 4: The word \"machine\" appears 4 times in the chunk.</li> <li><code>BM25F_machine_propLength</code>: 39: The property (e.g., the \"body\" or \"title\") in which \"machine\" appears has a length of 39 words.</li> <li><code>BM25F_learning_frequency</code>: 4: The word \"learning\" also appears 4 times in the chunk.</li> <li><code>BM25F_learning_propLength</code>: 39: Similar to \"machine\", the property where \"learning\" appears has a length of 39 words.</li> </ul> In\u00a0[10]: Copied! <pre>response = article.query.hybrid(\n    query=\"what is machine learning?\",\n    limit=3\n)\n\nprint_objects(response.objects)\n</pre> response = article.query.hybrid(     query=\"what is machine learning?\",     limit=3 )  print_objects(response.objects) <pre>ID: 66177066615778596449200477828369435490\nMetadata: []\nTitle: Machine Learning\nDate: 2021-10-01 00:00:00+00:00\nCategory: ML\nAuthor: Towards Data Science\nBody: Machine learning is a subset of artificial intelligence (AI) that provides systems the ability [...]\n\nID: 235959584379154997552071134050082173029\nMetadata: []\nTitle: Machine Learning Basics\nDate: 2023-03-05 00:00:00+00:00\nCategory: ML\nAuthor: TechCrunch\nBody: Machine learning is a branch of artificial intelligence that focuses on building systems that [...]\n\nID: 37499734945959922522607306974367251245\nMetadata: []\nTitle: Introduction to Deep Learning\nDate: 2022-07-10 00:00:00+00:00\nCategory: ML\nAuthor: Towards Data Science\nBody: Deep learning is a subset of machine learning that uses neural networks with many layers to [...]\n\n</pre> <p>We can use the argument <code>alpha</code> to set the weightage for each search method.</p> <ul> <li>An alpha of 1 is a pure vector search.</li> <li>An alpha of 0 is a pure keyword search.</li> </ul> In\u00a0[11]: Copied! <pre>response = article.query.hybrid(\n    query=\"what is machine learning?\",\n    alpha=0.25,  # keyword search is being given more wieghtage\n    return_metadata=MetadataQuery(score=True, explain_score=True),\n    limit=3\n)\n\nprint_objects(response.objects)\n</pre> response = article.query.hybrid(     query=\"what is machine learning?\",     alpha=0.25,  # keyword search is being given more wieghtage     return_metadata=MetadataQuery(score=True, explain_score=True),     limit=3 )  print_objects(response.objects) <pre>ID: 66177066615778596449200477828369435490\nMetadata: [{'score': 0.99}, {'explain_score': '\\nHybrid (Result Set keyword,bm25) Document 31c93d4a-ce6a-41ee-a524-6633d6314b62: original score 1.0091017, normalized score: 0.75 - \\nHybrid (Result Set vector,hybridVector) Document 31c93d4a-ce6a-41ee-a524-6633d6314b62: original score 0.6449458, normalized score: 0.24075538'}]\nTitle: Machine Learning\nDate: 2021-10-01 00:00:00+00:00\nCategory: ML\nAuthor: Towards Data Science\nBody: Machine learning is a subset of artificial intelligence (AI) that provides systems the ability [...]\n\nID: 235959584379154997552071134050082173029\nMetadata: [{'score': 0.88}, {'explain_score': '\\nHybrid (Result Set keyword,bm25) Document b18429b5-433b-4050-a98b-5cadf1553065: original score 0.8831322, normalized score: 0.6336288 - \\nHybrid (Result Set vector,hybridVector) Document b18429b5-433b-4050-a98b-5cadf1553065: original score 0.6645762, normalized score: 0.25'}]\nTitle: Machine Learning Basics\nDate: 2023-03-05 00:00:00+00:00\nCategory: ML\nAuthor: TechCrunch\nBody: Machine learning is a branch of artificial intelligence that focuses on building systems that [...]\n\nID: 37499734945959922522607306974367251245\nMetadata: [{'score': 0.65}, {'explain_score': '\\nHybrid (Result Set keyword,bm25) Document 1c362fad-ae27-4e8e-b76d-a1e4e1eefb2d: original score 0.6991587, normalized score: 0.4636732 - \\nHybrid (Result Set vector,hybridVector) Document 1c362fad-ae27-4e8e-b76d-a1e4e1eefb2d: original score 0.5275562, normalized score: 0.18547252'}]\nTitle: Introduction to Deep Learning\nDate: 2022-07-10 00:00:00+00:00\nCategory: ML\nAuthor: Towards Data Science\nBody: Deep learning is a subset of machine learning that uses neural networks with many layers to [...]\n\n</pre> <pre>{'explain_score': '\\nHybrid (Result Set keyword,bm25) Document fe776c9c-a970-4337-b2f1-732d778b997d: original score 1.0120157, normalized score: 0.75 - \\nHybrid (Result Set vector,hybridVector) Document fe776c9c-a970-4337-b2f1-732d778b997d: original score 0.6449458, normalized score: 0.25'}```\n\nAs you can see, the keyword search score has been normalized to 0.75 and the vector search score has been normalised to 0.25. Which means keyword search is being given more weightage during the combination\n</pre> In\u00a0[12]: Copied! <pre>from weaviate.classes.query import Filter\n\nresponse =  article.query.fetch_objects(\n    filters=Filter.by_property(\"category\").equal(\"Programming\"),\n    limit=2\n)\n\nprint_objects(response.objects)\n</pre> from weaviate.classes.query import Filter  response =  article.query.fetch_objects(     filters=Filter.by_property(\"category\").equal(\"Programming\"),     limit=2 )  print_objects(response.objects) <pre>ID: 208507677698874478258804158284056307633\nMetadata: []\nTitle: Data Structures\nDate: 2022-03-12 00:00:00+00:00\nCategory: Programming\nAuthor: GeeksForGeeks\nBody: Data structures are ways of organizing and storing data so that they can be accessed and [...]\n\nID: 253766494100517455433948109859044355170\nMetadata: []\nTitle: Algorithms\nDate: 2021-12-05 00:00:00+00:00\nCategory: Programming\nAuthor: Towards Data Science\nBody: Algorithms are step-by-step instructions or rules designed to perform a task or solve a [...]\n\n</pre> In\u00a0[13]: Copied! <pre>response =  article.query.fetch_objects(\n    filters=(\n        Filter.by_property(\"category\").equal(\"Programming\") &amp;   # use &amp; for AND, | for OR\n        Filter.by_property(\"author\").equal(\"GeeksForGeeks\")\n    ),\n    limit=2\n)\n\nprint_objects(response.objects)\n</pre> response =  article.query.fetch_objects(     filters=(         Filter.by_property(\"category\").equal(\"Programming\") &amp;   # use &amp; for AND, | for OR         Filter.by_property(\"author\").equal(\"GeeksForGeeks\")     ),     limit=2 )  print_objects(response.objects) <pre>ID: 208507677698874478258804158284056307633\nMetadata: []\nTitle: Data Structures\nDate: 2022-03-12 00:00:00+00:00\nCategory: Programming\nAuthor: GeeksForGeeks\nBody: Data structures are ways of organizing and storing data so that they can be accessed and [...]\n\nID: 182361683605136523364033502237211524982\nMetadata: []\nTitle: Understanding Hash Tables\nDate: 2022-10-15 00:00:00+00:00\nCategory: Programming\nAuthor: GeeksForGeeks\nBody: Hash tables are a data structure that implements an associative array, a structure that can [...]\n\n</pre> In\u00a0[14]: Copied! <pre>response =  article.query.near_text(\n    query=\"What is machine learning?\",\n    filters=(\n        Filter.by_property(\"category\").equal(\"ML\")\n    ),\n    limit=2\n)\n\nprint_objects(response.objects)\n</pre> response =  article.query.near_text(     query=\"What is machine learning?\",     filters=(         Filter.by_property(\"category\").equal(\"ML\")     ),     limit=2 )  print_objects(response.objects) <pre>ID: 235959584379154997552071134050082173029\nMetadata: []\nTitle: Machine Learning Basics\nDate: 2023-03-05 00:00:00+00:00\nCategory: ML\nAuthor: TechCrunch\nBody: Machine learning is a branch of artificial intelligence that focuses on building systems that [...]\n\nID: 66177066615778596449200477828369435490\nMetadata: []\nTitle: Machine Learning\nDate: 2021-10-01 00:00:00+00:00\nCategory: ML\nAuthor: Towards Data Science\nBody: Machine learning is a subset of artificial intelligence (AI) that provides systems the ability [...]\n\n</pre> In\u00a0[15]: Copied! <pre>response =  article.query.fetch_objects(\n    filters=(\n        Filter.by_property(\"body\").contains_any([\"cybersecurity\", \"security\"])\n    ),\n    limit=2\n)\n\nprint_objects(response.objects)\n</pre> response =  article.query.fetch_objects(     filters=(         Filter.by_property(\"body\").contains_any([\"cybersecurity\", \"security\"])     ),     limit=2 )  print_objects(response.objects) <pre>ID: 111770961923860747703082376322890795880\nMetadata: []\nTitle: The Importance of Cybersecurity\nDate: 2022-12-12 00:00:00+00:00\nCategory: Cybersecurity\nAuthor: Krebs on Security\nBody: Cybersecurity involves protecting computer systems and networks from information disclosure, [...]\n\nID: 9620050475437321785307488639092868804\nMetadata: []\nTitle: Cryptography\nDate: 2022-08-25 00:00:00+00:00\nCategory: Cybersecurity\nAuthor: TechCrunch\nBody: Cryptography is the study and practice of securing communication and data from unauthorized [...]\n\n</pre> In\u00a0[16]: Copied! <pre>response =  article.query.fetch_objects(\n    filters=(\n        Filter.by_property(\"body\").contains_all([\"cybersecurity\", \"security\"])\n    ),\n    limit=2\n)\n\nprint_objects(response.objects)\n</pre> response =  article.query.fetch_objects(     filters=(         Filter.by_property(\"body\").contains_all([\"cybersecurity\", \"security\"])     ),     limit=2 )  print_objects(response.objects) <pre>ID: 111770961923860747703082376322890795880\nMetadata: []\nTitle: The Importance of Cybersecurity\nDate: 2022-12-12 00:00:00+00:00\nCategory: Cybersecurity\nAuthor: Krebs on Security\nBody: Cybersecurity involves protecting computer systems and networks from information disclosure, [...]\n\n</pre> In\u00a0[17]: Copied! <pre>from datetime import datetime, timezone\n\n# filter for articles published after March 2023\nfilter_time = datetime(2023, 3, 1).replace(tzinfo=timezone.utc)\n\nresponse = article.query.fetch_objects(\n    limit=3,\n    filters=(\n        Filter.by_property(\"date\").greater_than(filter_time) &amp;\n        Filter.by_property(\"category\").equal(\"Web Development\")\n    )\n)\n\nprint_objects(response.objects)\n</pre> from datetime import datetime, timezone  # filter for articles published after March 2023 filter_time = datetime(2023, 3, 1).replace(tzinfo=timezone.utc)  response = article.query.fetch_objects(     limit=3,     filters=(         Filter.by_property(\"date\").greater_than(filter_time) &amp;         Filter.by_property(\"category\").equal(\"Web Development\")     ) )  print_objects(response.objects) <pre>ID: 312048356239543821625715872904303588831\nMetadata: []\nTitle: RESTful API Design\nDate: 2023-04-10 00:00:00+00:00\nCategory: Web Development\nAuthor: Smashing Magazine\nBody: RESTful APIs are an architectural style for designing networked applications. They rely on [...]\n\n</pre>"},{"location":"module-3/retrieval_strategies/#retrieval-strategies","title":"Retrieval Strategies\u00b6","text":"<p>Retrieval Strategies are the different techniques that are used to retrieve the relevant chunks from a document.</p> <ol> <li>Vector Similarity Search: As discussed previously, by calculating metrics such as cosine similarity or euclidean distance, between the query and chunks, we can retrieve the most similar ones.</li> <li>Keyword(BM25) Search: By using the BM25 algorithm, we can retrieve the chunks that contain the most relevant keywords. This is a very common technique used in search engines.</li> <li>Hybrid Search: A combination of the above two techniques.</li> </ol>"},{"location":"module-3/retrieval_strategies/#about-bm25-search","title":"About BM25 Search\u00b6","text":""},{"location":"module-3/retrieval_strategies/#intro-to-bm25","title":"Intro to BM25\u00b6","text":"<p>BM25 is a popular algorithm used for information retrieval, especially in search engines and document ranking systems. It's part of a family of algorithms called \"probabilistic information retrieval models\", designed to rank documents based on their relevance to a user's query. When you enter a query in a search engine, BM25 helps determine which documents (e.g., web pages, articles) are most likely to contain the information you\u2019re looking for. It\u2019s particularly useful when dealing with unstructured data like text, where documents aren\u2019t tagged or labeled, and relevance must be inferred from the content itself.</p> <p>BM25 stands out because it considers term frequency (how often a word appears in a document) and inverse document frequency (how rare or common that word is across all documents). By balancing these factors, BM25 effectively finds documents that are not just packed with the query terms but are also meaningful and relevant in context.</p>"},{"location":"module-3/retrieval_strategies/#how-bm25-works","title":"How BM25 Works\u00b6","text":"<p>At its core, BM25 scores documents based on how well they match a query. It does this by analyzing the terms in both the query and the documents, assessing the importance of each term, and then assigning a relevance score to each document. To understand BM25 better, let's break down the process step by step:</p>"},{"location":"module-3/retrieval_strategies/#1-term-frequency-tf","title":"1. Term Frequency (TF):\u00b6","text":"<p>BM25 looks at how often each term in the query appears in a document. This is called term frequency. The idea is simple: the more frequently a term appears in a document, the more relevant that document might be for the query. However, BM25 doesn\u2019t just count the raw number of occurrences\u2014it uses a formula that gives diminishing returns to higher frequencies. In other words, if a word appears once or twice, it might significantly boost the document\u2019s relevance, but if it appears 100 times, it\u2019s not going to make the document 100 times more relevant. This prevents documents that repeat a keyword excessively from dominating the results.</p> <p>Example: Let's say the query is <code>machine learning</code>, and Document A mentions \"machine\" and \"learning\" three times each, while Document B mentions \"machine\" once and \"learning\" twice. BM25 will score Document A higher based on term frequency alone because it contains both terms more often. But term frequency is just one part of the formula.</p>"},{"location":"module-3/retrieval_strategies/#2-inverse-document-frequency-idf","title":"2. Inverse Document Frequency (IDF):\u00b6","text":"<p>BM25 also considers how common or rare a term is across the entire set of documents. This is called inverse document frequency. If a word appears in almost every document (e.g., \"the\", \"is\"), it\u2019s not very useful for distinguishing relevant documents from irrelevant ones. On the other hand, if a word is rare (like \"neural networks\"), it\u2019s likely to be more informative and relevant when it does appear.</p> <p>BM25 assigns higher importance to terms that are rare across the document collection. This helps ensure that the algorithm doesn\u2019t just return documents filled with common terms, but rather those that include more unique and relevant terms.</p> <p>Example: If \"machine\" appears in 90% of documents and \"learning\" appears in only 10%, BM25 will assign a higher weight to \"learning\" because it\u2019s less common and more likely to help identify relevant documents.</p>"},{"location":"module-3/retrieval_strategies/#3-document-length-normalization","title":"3. Document Length Normalization:\u00b6","text":"<p>Longer documents are more likely to contain any given term simply because they have more content. To avoid bias toward longer documents, BM25 normalizes the term frequency by the document length. This ensures that shorter documents with concentrated, relevant information aren\u2019t penalized.</p> <p>Example: If Document A has 200 words and Document B has 1000 words, but both mention \"machine learning\" 5 times, BM25 will score Document A higher because its shorter length suggests that the term \"machine learning\" is more central to its content.</p>"},{"location":"module-3/retrieval_strategies/#example-query-walkthrough","title":"Example Query Walkthrough:\u00b6","text":"<p>Let\u2019s say the query is <code>\"deep learning for image classification\"</code>, and you have three documents:</p> <ul> <li>Document 1: A short blog post discussing image classification with neural networks and deep learning mentioned twice.</li> <li>Document 2: A lengthy research paper on deep learning that mentions deep learning multiple times but doesn\u2019t focus on image classification specifically.</li> <li>Document 3: A general overview of machine learning, which mentions image classification briefly but without any focus on deep learning.</li> </ul> <p>BM25 will first check how many times each query term appears in the documents. It will find that Document 2 mentions \"deep learning\" many times, so it will score well based on term frequency. However, Document 1 will also score highly because although it mentions \"deep learning\" fewer times, it\u2019s a shorter document where the term is more central. Meanwhile, Document 3 will score lower because, even though it might mention image classification, it doesn\u2019t cover deep learning well enough to be relevant.</p> <p>Next, BM25 will apply inverse document frequency. If \"deep learning\" is a common term across all documents but \"image classification\" is rare, Document 1 and Document 2 will be weighted more heavily for mentioning \"image classification.\" Document 3, which only touches on image classification, will be further penalized for lacking depth on the subject.</p> <p>Lastly, BM25 adjusts for document length. Document 1 is shorter and to the point, so it gets an extra boost, while Document 2, despite being lengthy, will only get marginally higher scores for repeating terms more often.</p> <p>In the end, BM25 will likely rank Document 1 as the most relevant, followed by Document 2, with Document 3 trailing behind.</p>"},{"location":"module-3/retrieval_strategies/#final-bm25-score-calculation","title":"Final BM25 Score Calculation:\u00b6","text":"<p>BM25 combines all the factors\u2014term frequency, inverse document frequency, and document length normalization\u2014into a final score. The higher the BM25 score, the more relevant the document is to the query.</p> <p>What\u2019s great about BM25 is that it\u2019s both simple and highly effective. It doesn\u2019t just focus on raw counts of query terms; it carefully weighs how often terms appear, how common they are across all documents, and whether a term\u2019s appearance is significant in the context of the document\u2019s length.</p>"},{"location":"module-3/retrieval_strategies/#comparing-bm25-with-vector-similarity-search","title":"Comparing BM25 with Vector Similarity Search\u00b6","text":"<p>While BM25 focuses on keyword matching (how relevant a document is based on exact words), vector similarity search looks at the semantic meaning behind the text. In vector search, documents and queries are represented as vectors in a continuous space, and similarity is measured based on the distance between them, usually using cosine similarity or dot product. This allows vector search to find documents with similar meanings, even if the words don\u2019t exactly match.</p> <p>BM25 Advantages:</p> <ul> <li>Works well with small datasets.</li> <li>Doesn\u2019t require a complex model.</li> <li>Easier to explain and debug.</li> </ul> <p>Vector Search Advantages:</p> <ul> <li>Captures semantic meaning, not just exact word matches.</li> <li>Works better for complex queries where words might not exactly match the document terms.</li> </ul> <p>Both methods have their place, but BM25 is particularly useful when you want precise keyword matching and have limited computational resources.</p>"},{"location":"module-3/retrieval_strategies/#setup-weaviate-client","title":"Setup Weaviate Client\u00b6","text":""},{"location":"module-3/retrieval_strategies/#create-collection","title":"Create Collection\u00b6","text":""},{"location":"module-3/retrieval_strategies/#insert-documents","title":"Insert Documents\u00b6","text":""},{"location":"module-3/retrieval_strategies/#vector-similarity-search","title":"Vector Similarity Search\u00b6","text":"<p>We've covered this previously as well, but let's repeat the steps for a quick refresher.</p>"},{"location":"module-3/retrieval_strategies/#hybrid-search","title":"Hybrid Search\u00b6","text":"<p>Hybrid Search is a combination of Vector Search and Keyword Search. The results from the two searches are combined based on a configurable weight</p>"},{"location":"module-3/retrieval_strategies/#search-by-filtering","title":"Search By Filtering\u00b6","text":"<p>Objects/chunks can also be retrieved by just filtering on the properties. This is useful when you want to retrieve chunks that contain specific values in the properties.</p>"},{"location":"module-3/retrieval_strategies/#filter-on-multiple-properties","title":"Filter on multiple properties\u00b6","text":""},{"location":"module-3/retrieval_strategies/#filter-on-properties-with-search","title":"Filter on properties with search\u00b6","text":""},{"location":"module-3/retrieval_strategies/#contains-any-filteration","title":"Contains Any Filteration\u00b6","text":""},{"location":"module-3/retrieval_strategies/#contains-all-filteration","title":"Contains All Filteration\u00b6","text":""},{"location":"module-3/retrieval_strategies/#filter-by-date","title":"Filter by Date\u00b6","text":""},{"location":"module-3/sample/","title":"The Evolution of Technology in the 21st Century","text":""},{"location":"module-3/sample/#introduction","title":"Introduction","text":"<p>Technology has grown at an unprecedented rate in the 21st century, transforming every facet of human life. From the ways we communicate to how we work, learn, and entertain ourselves, technological advancements have redefined the modern world.</p>"},{"location":"module-3/sample/#the-rise-of-the-internet-and-mobile-technology","title":"The Rise of the Internet and Mobile Technology","text":"<p>The early 2000s witnessed the rise of personal computers and the internet, which revolutionized the way people accessed information. Before this period, gathering information meant visiting libraries, reading books, or consulting experts in person.</p> <p>As internet infrastructure improved, mobile technology followed. The introduction of smartphones in the late 2000s, particularly with the release of the iPhone in 2007, marked a turning point.</p>"},{"location":"module-3/sample/#cloud-computing-and-ai","title":"Cloud Computing and AI","text":"<p>One of the most significant advancements of this era has been the growth of cloud computing. Companies no longer needed to invest in expensive hardware to store data. Instead, cloud services like Amazon Web Services (AWS) and Microsoft Azure allowed businesses to store and process data remotely.</p>"},{"location":"module-3/sample/#automation-and-its-challenges","title":"Automation and its Challenges","text":"<p>Automation is another area that has seen rapid growth. Robotics and AI have been integrated into manufacturing, agriculture, and even healthcare.</p> <p>However, this rapid advancement has not come without challenges, such as job displacement and privacy concerns.</p>"},{"location":"module-3/sample/#conclusion","title":"Conclusion","text":"<p>In conclusion, the 21st century has been marked by rapid technological advancements that have reshaped society in countless ways. Balancing innovation with ethical considerations will be key to ensuring a future where technology benefits all of humanity.</p>"},{"location":"module-3/vector-embeddings/intro/","title":"Introduction","text":"<p>Vector embeddings are a way to represent objects (like words, sentences, or even products) as numerical vectors in a continuous space. These vectors capture the relationships and similarities between the objects. For example, words with similar meanings are placed closer together in this vector space, while dissimilar ones are farther apart. Embeddings simplify the representation of complex data so that machines can easily process it. They play a crucial role in tasks like search engines, recommendations, and natural language processing (NLP), where understanding the relationship between entities is key.</p>"},{"location":"module-3/vector-embeddings/intro/#types-of-embeddings","title":"Types of Embeddings","text":"<ul> <li> <p>Word Embeddings: These represent individual words as vectors. For example, \"king\" and \"queen\" would have similar vectors due to their related meanings. Word2Vec and GloVe are popular methods.</p> </li> <li> <p>Sentence Embeddings: These capture the meaning of entire sentences rather than individual words. Models like BERT and Sentence-BERT are commonly used for generating sentence embeddings.</p> </li> <li> <p>Document Embeddings: These represent entire documents or paragraphs. A good example is Doc2Vec, which learns embeddings for documents while preserving contextual information.</p> </li> <li> <p>Product Embeddings: In recommendation systems, products are often represented as vectors. These embeddings capture similarities between products based on user behavior or item attributes, helping with personalized recommendations.</p> </li> </ul>"},{"location":"module-3/vector-embeddings/intro/#examples-of-vector-embeddings","title":"Examples of Vector Embeddings","text":"<p>In text, a word like \u201capple\u201d can be embedded in a vector space, where its nearest neighbors might be \"fruit\" and \"banana.\" In a product embedding space, a vector for a laptop might be closer to \u201ctablet\u201d than to \u201cbook,\u201d indicating the similarity between tech products versus unrelated categories.</p>"},{"location":"module-3/vector-embeddings/intro/#what-do-they-look-like","title":"What Do They Look Like?","text":"<p>Vector embeddings are usually high-dimensional arrays of floating-point numbers. For instance, a word embedding might look like this:</p> <pre><code>[0.12, -0.23, 0.88, 0.65, -0.34, ...]\n</code></pre> <p>These numbers represent different dimensions of relationships the object has with others in the dataset. The exact size of the vector depends on the embedding model, with common sizes being 100, 300, or even 768 dimensions in more advanced models like BERT.</p>"},{"location":"module-3/vector-embeddings/intro/#how-are-text-embeddings-created","title":"How Are Text Embeddings Created?","text":"<p>Text embeddings are created by training models on massive amounts of text data, capturing the context and relationships between words, sentences, or documents. One of the popular models for generating text embeddings is OpenAI\u2019s <code>ada-002</code>, which produces high-quality embeddings for a wide range of NLP tasks. It\u2019s a versatile model that can handle text classification, search, and recommendation tasks by converting text into numerical vectors that represent meaning and context.</p> <p>Other well-known open-source models include Sentence-BERT (SBERT), which builds on the BERT model but optimizes it for generating sentence-level embeddings. SBERT fine-tunes BERT on sentence-pair tasks, enabling it to produce more semantically meaningful embeddings, ideal for applications like semantic search or sentence similarity.</p> <p>For evaluating the quality and performance of these embeddings, the Massive Text Embedding Benchmark (MTEB) is often used. MTEB is a benchmark designed to compare various text embedding models across tasks like classification, clustering, and retrieval. By standardizing evaluation across multiple datasets and languages, MTEB helps determine which models perform best for different real-world use cases.</p>"},{"location":"module-3/vector-embeddings/intro/#real-life-applications-of-vector-embeddings","title":"Real-Life Applications of Vector Embeddings","text":"<p>Vector embeddings are used across various industries to power advanced, data-driven applications.</p> <ol> <li> <p>Search Engines: When you search for something, vector embeddings help match the query with relevant documents. Instead of just relying on keywords, embeddings allow the system to understand the meaning behind the query and retrieve results with similar meanings.</p> </li> <li> <p>Recommendation Systems: In e-commerce platforms like Amazon or streaming services like Netflix, product embeddings are used to recommend similar items. For example, if you like a certain movie, the system will recommend others that are nearby in the embedding space.</p> </li> <li> <p>Natural Language Processing (NLP): Tasks like translation, sentiment analysis, and text classification benefit from embeddings. BERT-based models, for example, convert text into embeddings that capture context, making it easier for machines to understand and process language.</p> </li> <li> <p>Image Recognition: Image embeddings help classify and retrieve similar images. For example, Pinterest uses embeddings to suggest visually similar images based on user interests.</p> </li> <li> <p>Fraud Detection: Financial institutions use embeddings to map out transaction patterns. Fraudulent activities often fall outside the norm, making them easier to detect when mapped into a vector space.</p> </li> </ol> <p>In production, these embeddings are often served from databases or embedding models running in the background, enabling real-time decisions.</p>"},{"location":"module-3/vector-embeddings/similarity_measures/","title":"Similarity Measures","text":"In\u00a0[7]: Copied! <pre>import math\n\ndef euclidean_distance(A, B):\n    if len(A) != len(B):\n        raise ValueError(\"Vectors must be of same length.\")\n    return math.sqrt(sum((a - b) ** 2 for a, b in zip(A, B)))\n\n# Example Usage\nA = [1, 2, 3]\nB = [4, 6, 8]\nprint(euclidean_distance(A, B))\n</pre> import math  def euclidean_distance(A, B):     if len(A) != len(B):         raise ValueError(\"Vectors must be of same length.\")     return math.sqrt(sum((a - b) ** 2 for a, b in zip(A, B)))  # Example Usage A = [1, 2, 3] B = [4, 6, 8] print(euclidean_distance(A, B)) <pre>7.0710678118654755\n</pre> In\u00a0[8]: Copied! <pre>import math\n\ndef cosine_similarity(A, B):\n    if len(A) != len(B):\n        raise ValueError(\"Vectors must be of same length.\")\n    dot_product = sum(a * b for a, b in zip(A, B))\n    magnitude_A = math.sqrt(sum(a ** 2 for a in A))\n    magnitude_B = math.sqrt(sum(b ** 2 for b in B))\n    return dot_product / (magnitude_A * magnitude_B)\n\n# Example Usage\nA = [1, 2, 3]\nB = [4, 5, 6]\nprint(cosine_similarity(A, B))\n</pre> import math  def cosine_similarity(A, B):     if len(A) != len(B):         raise ValueError(\"Vectors must be of same length.\")     dot_product = sum(a * b for a, b in zip(A, B))     magnitude_A = math.sqrt(sum(a ** 2 for a in A))     magnitude_B = math.sqrt(sum(b ** 2 for b in B))     return dot_product / (magnitude_A * magnitude_B)  # Example Usage A = [1, 2, 3] B = [4, 5, 6] print(cosine_similarity(A, B)) <pre>0.9746318461970762\n</pre> <p>Cosine similarity will give you a value between -1 and 1, where 1 means the vectors point in the same direction (are very similar), 0 means they are orthogonal (unrelated), and -1 means they point in completely opposite directions (are very dissimilar).</p> In\u00a0[9]: Copied! <pre>vec1 = [1, 2]\nvec2 = [100, 200]\n\nprint(\"Euclidean Distance:\", euclidean_distance(vec1, vec2))\nprint(\"Cosine Similarity:\", cosine_similarity(vec1, vec2))\n</pre> vec1 = [1, 2] vec2 = [100, 200]  print(\"Euclidean Distance:\", euclidean_distance(vec1, vec2)) print(\"Cosine Similarity:\", cosine_similarity(vec1, vec2))  <pre>Euclidean Distance: 221.37072977247917\nCosine Similarity: 1.0\n</pre> In\u00a0[10]: Copied! <pre>vec1 = [1, 1]   # small magnitude, same direction\nvec2 = [100, 100]  # large magnitude, same direction\n\neuclid = euclidean_distance(vec1, vec2)\ncosine_sim = cosine_similarity(vec1, vec2)\n\nprint(\"Euclidean Distance:\", euclid)\nprint(\"Cosine Similarity:\", cosine_sim)\n</pre> vec1 = [1, 1]   # small magnitude, same direction vec2 = [100, 100]  # large magnitude, same direction  euclid = euclidean_distance(vec1, vec2) cosine_sim = cosine_similarity(vec1, vec2)  print(\"Euclidean Distance:\", euclid) print(\"Cosine Similarity:\", cosine_sim) <pre>Euclidean Distance: 140.0071426749364\nCosine Similarity: 0.9999999999999999\n</pre> <p>Here, despite the large difference in magnitude, cosine similarity will be 1 (perfect similarity), while Euclidean distance will be large. Cosine similarity focuses on the relationship, not size.</p>"},{"location":"module-3/vector-embeddings/similarity_measures/#similarity-measures","title":"Similarity Measures\u00b6","text":"<p>In vector databases, similarity measures are used to determine how close or related two vectors are. When working with embeddings, whether they represent words, products, or images, we need a way to quantify the distance or similarity between these vectors to make decisions, such as retrieving similar items or clustering related objects. Two common similarity measures used in vector databases are Euclidean Distance and Cosine Similarity. Each is suited to different kinds of data and use cases.</p>"},{"location":"module-3/vector-embeddings/similarity_measures/#1-euclidean-distance","title":"1. Euclidean Distance\u00b6","text":""},{"location":"module-3/vector-embeddings/similarity_measures/#definition","title":"Definition\u00b6","text":"<p>Euclidean distance is the straight-line distance between two points in a multi-dimensional space. It\u2019s essentially the generalization of the distance formula between two points on a 2D plane but extended to higher dimensions.</p>"},{"location":"module-3/vector-embeddings/similarity_measures/#mathematical-formula","title":"Mathematical Formula\u00b6","text":"<p>For two vectors A and B with <code>n</code> dimensions, the Euclidean distance is calculated as:</p> <p>$$ d(A, B) = \\sqrt{(A_1 - B_1)^2 + (A_2 - B_2)^2 + \\dots + (A_n - B_n)^2} $$</p>"},{"location":"module-3/vector-embeddings/similarity_measures/#when-to-use-it","title":"When to Use It\u00b6","text":"<p>Use Euclidean distance when the magnitude of the vector is important. It works well in situations where you want to know how far apart two items are in a continuous space. For example, it\u2019s often used in image recognition or clustering algorithms like k-means where physical distance between points is significant.</p>"},{"location":"module-3/vector-embeddings/similarity_measures/#python-function-from-scratch","title":"Python Function (from Scratch)\u00b6","text":""},{"location":"module-3/vector-embeddings/similarity_measures/#2-cosine-similarity","title":"2. Cosine Similarity\u00b6","text":""},{"location":"module-3/vector-embeddings/similarity_measures/#definition","title":"Definition\u00b6","text":"<p>Cosine similarity measures the cosine of the angle between two vectors. Unlike Euclidean distance, it focuses on the direction of the vectors rather than their magnitude, making it useful for comparing the orientation of vectors in space.</p>"},{"location":"module-3/vector-embeddings/similarity_measures/#mathematical-formula","title":"Mathematical Formula\u00b6","text":"<p>For two vectors A and B, the cosine similarity is calculated as:</p> <p>$$ \\text{cosine similarity}(A, B) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|} $$</p> <p>Where $A \\cdot B$ is the dot product of the vectors, and $|A|$ and $|B|$ are the magnitudes (lengths) of vectors $A$ and $B$.</p>"},{"location":"module-3/vector-embeddings/similarity_measures/#when-to-use-it","title":"When to Use It\u00b6","text":"<p>Cosine similarity is commonly used when you care about the direction rather than the magnitude. It\u2019s ideal for textual data where the length of the document (or vector) may vary, but the focus is on how similar the content (direction) is. It\u2019s widely used in NLP tasks like document similarity, sentence similarity, and information retrieval.</p>"},{"location":"module-3/vector-embeddings/similarity_measures/#why-cosine-similarity-over-euclidean-distance-in-vector-dbs","title":"Why Cosine Similarity Over Euclidean Distance in Vector DBs?\u00b6","text":"<p>Cosine similarity is often used over Euclidean distance in vector databases because it focuses on the angle between vectors, not their magnitude. This is useful when the direction matters more than the size. For example, in text similarity (e.g., document search), two documents might have different lengths but similar content. Cosine similarity can measure how similar the documents are based on their word usage patterns, ignoring how many words they contain.</p> <p>Euclidean distance, on the other hand, measures the actual distance between points in space, which can be misleading when the data points have varying magnitudes but similar structures.</p>"},{"location":"module-3/vector-embeddings/similarity_measures/#simple-python-example","title":"Simple Python Example\u00b6","text":""},{"location":"module-3/vector-embeddings/vector_dbs/","title":"Vector Databases","text":"In\u00a0[1]: Copied! <pre>import weaviate\nfrom dotenv import load_dotenv\nimport os\n\nload_dotenv(\"./../../.env\")\n\nclient = weaviate.connect_to_embedded(\n    headers={\n        \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_API_KEY\")\n    }\n)\n</pre> import weaviate from dotenv import load_dotenv import os  load_dotenv(\"./../../.env\")  client = weaviate.connect_to_embedded(     headers={         \"X-OpenAI-Api-Key\": os.getenv(\"OPENAI_API_KEY\")     } ) <pre>{\"action\":\"startup\",\"default_vectorizer_module\":\"none\",\"level\":\"info\",\"msg\":\"the default vectorizer modules is set to \\\"none\\\", as a result all new schema classes without an explicit vectorizer setting, will use this vectorizer\",\"time\":\"2024-09-20T16:14:20+05:30\"}\n{\"action\":\"startup\",\"auto_schema_enabled\":true,\"level\":\"info\",\"msg\":\"auto schema enabled setting is set to \\\"true\\\"\",\"time\":\"2024-09-20T16:14:20+05:30\"}\n{\"level\":\"info\",\"msg\":\"No resource limits set, weaviate will use all available memory and CPU. To limit resources, set LIMIT_RESOURCES=true\",\"time\":\"2024-09-20T16:14:20+05:30\"}\n{\"level\":\"info\",\"msg\":\"module offload-s3 is enabled\",\"time\":\"2024-09-20T16:14:20+05:30\"}\n{\"level\":\"warning\",\"msg\":\"Multiple vector spaces are present, GraphQL Explore and REST API list objects endpoint module include params has been disabled as a result.\",\"time\":\"2024-09-20T16:14:20+05:30\"}\n{\"level\":\"info\",\"msg\":\"open cluster service\",\"servers\":{\"Embedded_at_8079\":65509},\"time\":\"2024-09-20T16:14:20+05:30\"}\n{\"address\":\"192.168.155.215:65510\",\"level\":\"info\",\"msg\":\"starting cloud rpc server ...\",\"time\":\"2024-09-20T16:14:20+05:30\"}\n{\"level\":\"info\",\"msg\":\"starting raft sub-system ...\",\"time\":\"2024-09-20T16:14:20+05:30\"}\n{\"address\":\"192.168.155.215:65509\",\"level\":\"info\",\"msg\":\"tcp transport\",\"tcpMaxPool\":3,\"tcpTimeout\":10000000000,\"time\":\"2024-09-20T16:14:20+05:30\"}\n{\"level\":\"info\",\"msg\":\"loading local db\",\"time\":\"2024-09-20T16:14:20+05:30\"}\n{\"level\":\"info\",\"msg\":\"local DB successfully loaded\",\"time\":\"2024-09-20T16:14:20+05:30\"}\n{\"level\":\"info\",\"msg\":\"schema manager loaded\",\"n\":0,\"time\":\"2024-09-20T16:14:20+05:30\"}\n{\"level\":\"info\",\"metadata_only_voters\":false,\"msg\":\"construct a new raft node\",\"name\":\"Embedded_at_8079\",\"time\":\"2024-09-20T16:14:20+05:30\"}\n{\"id\":\"2-3-1726727697440\",\"last-index\":3,\"last-term\":2,\"level\":\"info\",\"msg\":\"starting restore from snapshot\",\"size-in-bytes\":21578,\"time\":\"2024-09-20T16:14:20+05:30\"}\n{\"level\":\"info\",\"msg\":\"restoring schema from snapshot\",\"time\":\"2024-09-20T16:14:20+05:30\"}\n{\"level\":\"info\",\"msg\":\"successfully restored schema from snapshot\",\"time\":\"2024-09-20T16:14:20+05:30\"}\n{\"last_applied_index\":0,\"last_snapshot_index\":3,\"last_store_log_applied_index\":18,\"level\":\"info\",\"msg\":\"load local db from snapshot\",\"time\":\"2024-09-20T16:14:20+05:30\"}\n{\"action\":\"\",\"id\":\"2-3-1726727697440\",\"last-index\":3,\"last-term\":2,\"level\":\"info\",\"msg\":\"snapshot restore progress\",\"percent-complete\":\"[100.00]%\",\"read-bytes\":21578,\"size-in-bytes\":21578,\"time\":\"2024-09-20T16:14:20+05:30\"}\n{\"id\":\"2-3-1726727697440\",\"last-index\":3,\"last-term\":2,\"level\":\"info\",\"msg\":\"restored from snapshot\",\"size-in-bytes\":21578,\"time\":\"2024-09-20T16:14:20+05:30\"}\n{\"action\":\"raft\",\"index\":1,\"level\":\"info\",\"msg\":\"raft initial configuration\",\"servers\":\"[[{Suffrage:Voter ID:Embedded_at_8079 Address:192.168.155.215:50581}]]\",\"time\":\"2024-09-20T16:14:20+05:30\"}\n{\"last_snapshot_index\":3,\"last_store_applied_index\":3,\"last_store_log_applied_index\":18,\"level\":\"info\",\"msg\":\"raft node constructed\",\"raft_applied_index\":3,\"raft_last_index\":18,\"time\":\"2024-09-20T16:14:20+05:30\"}\n{\"action\":\"raft\",\"follower\":{},\"leader-address\":\"\",\"leader-id\":\"\",\"level\":\"info\",\"msg\":\"raft entering follower state\",\"time\":\"2024-09-20T16:14:20+05:30\"}\n{\"action\":\"raft\",\"last-leader-addr\":\"\",\"last-leader-id\":\"\",\"level\":\"warning\",\"msg\":\"raft heartbeat timeout reached, starting election\",\"time\":\"2024-09-20T16:14:21+05:30\"}\n{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft entering candidate state\",\"node\":{},\"term\":6,\"time\":\"2024-09-20T16:14:21+05:30\"}\n{\"action\":\"raft\",\"level\":\"info\",\"msg\":\"raft election won\",\"tally\":1,\"term\":6,\"time\":\"2024-09-20T16:14:21+05:30\"}\n{\"action\":\"raft\",\"leader\":{},\"level\":\"info\",\"msg\":\"raft entering leader state\",\"time\":\"2024-09-20T16:14:21+05:30\"}\n{\"level\":\"info\",\"msg\":\"reload local db: update schema ...\",\"time\":\"2024-09-20T16:14:21+05:30\"}\n{\"index\":\"LlamaIndex\",\"level\":\"info\",\"msg\":\"reload local index\",\"time\":\"2024-09-20T16:14:21+05:30\"}\n{\"index\":\"Article\",\"level\":\"info\",\"msg\":\"reload local index\",\"time\":\"2024-09-20T16:14:21+05:30\"}\n{\"docker_image_tag\":\"unknown\",\"level\":\"info\",\"msg\":\"configured versions\",\"server_version\":\"1.26.1\",\"time\":\"2024-09-20T16:14:22+05:30\"}\n{\"action\":\"grpc_startup\",\"level\":\"info\",\"msg\":\"grpc server listening at [::]:50050\",\"time\":\"2024-09-20T16:14:22+05:30\"}\n{\"address\":\"192.168.155.215:65509\",\"level\":\"info\",\"msg\":\"current Leader\",\"time\":\"2024-09-20T16:14:22+05:30\"}\n{\"action\":\"raft\",\"command\":0,\"level\":\"info\",\"msg\":\"raft updating configuration\",\"server-addr\":\"192.168.155.215:65509\",\"server-id\":\"Embedded_at_8079\",\"servers\":\"[[{Suffrage:Voter ID:Embedded_at_8079 Address:192.168.155.215:65509}]]\",\"time\":\"2024-09-20T16:14:22+05:30\"}\n{\"action\":\"restapi_management\",\"docker_image_tag\":\"unknown\",\"level\":\"info\",\"msg\":\"Serving weaviate at http://127.0.0.1:8079\",\"time\":\"2024-09-20T16:14:22+05:30\"}\n{\"action\":\"bootstrap\",\"leader\":\"192.168.155.215:65509\",\"level\":\"info\",\"msg\":\"successfully joined cluster\",\"time\":\"2024-09-20T16:14:22+05:30\"}\n{\"action\":\"telemetry_push\",\"level\":\"info\",\"msg\":\"telemetry started\",\"payload\":\"\\u0026{MachineID:710f8666-5a98-40cc-8a35-85a39af6baf2 Type:INIT Version:1.26.1 NumObjects:0 OS:darwin Arch:arm64 UsedModules:[text2vec-openai]}\",\"time\":\"2024-09-20T16:14:22+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/YIxrcKzy5u7i/lsm/objects/segment-1726757276601983000\",\"shard\":\"YIxrcKzy5u7i\",\"time\":\"2024-09-20T16:14:23+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/YIxrcKzy5u7i/lsm/property_title/segment-1726757276619261000\",\"shard\":\"YIxrcKzy5u7i\",\"time\":\"2024-09-20T16:14:23+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/YIxrcKzy5u7i/lsm/property_title_searchable/segment-1726757276631286000\",\"shard\":\"YIxrcKzy5u7i\",\"time\":\"2024-09-20T16:14:23+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/YIxrcKzy5u7i/lsm/property_body/segment-1726757276640918000\",\"shard\":\"YIxrcKzy5u7i\",\"time\":\"2024-09-20T16:14:23+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/YIxrcKzy5u7i/lsm/property_body_searchable/segment-1726757276650957000\",\"shard\":\"YIxrcKzy5u7i\",\"time\":\"2024-09-20T16:14:23+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/YIxrcKzy5u7i/lsm/property_date/segment-1726757276661052000\",\"shard\":\"YIxrcKzy5u7i\",\"time\":\"2024-09-20T16:14:23+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/YIxrcKzy5u7i/lsm/property_category/segment-1726757276681047000\",\"shard\":\"YIxrcKzy5u7i\",\"time\":\"2024-09-20T16:14:23+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/YIxrcKzy5u7i/lsm/property_category_searchable/segment-1726757276690837000\",\"shard\":\"YIxrcKzy5u7i\",\"time\":\"2024-09-20T16:14:23+05:30\"}\n{\"action\":\"lsm_recover_from_active_wal\",\"class\":\"Article\",\"index\":\"article\",\"level\":\"warning\",\"msg\":\"empty write-ahead-log found. Did weaviate crash prior to this or the tenant on/loaded from the cloud? Nothing to recover from this file.\",\"path\":\"/Users/vishwasgowda/.local/share/weaviate/article/YIxrcKzy5u7i/lsm/property__id/segment-1726757276671150000\",\"shard\":\"YIxrcKzy5u7i\",\"time\":\"2024-09-20T16:14:23+05:30\"}\n{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-09-20T16:14:23+05:30\",\"wait_for_cache_prefill\":false}\n{\"level\":\"info\",\"msg\":\"Completed loading shard article_YIxrcKzy5u7i in 46.875541ms\",\"time\":\"2024-09-20T16:14:23+05:30\"}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":3000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-09-20T16:14:23+05:30\",\"took\":515042}\n</pre> <pre>{\"action\":\"tombstone_cleanup_begin\",\"class\":\"Article\",\"level\":\"info\",\"msg\":\"class Article: shard YIxrcKzy5u7i: starting tombstone cleanup\",\"shard\":\"YIxrcKzy5u7i\",\"time\":\"2024-09-20T16:19:23+05:30\",\"tombstones_in_cycle\":2,\"tombstones_total\":2}\n{\"action\":\"tombstone_cleanup_complete\",\"class\":\"Article\",\"duration\":8806291,\"level\":\"info\",\"msg\":\"class Article: shard YIxrcKzy5u7i: completed tombstone cleanup in 8.806291ms\",\"shard\":\"YIxrcKzy5u7i\",\"time\":\"2024-09-20T16:19:23+05:30\",\"tombstones_in_cycle\":2,\"tombstones_total\":2}\n</pre> In\u00a0[11]: Copied! <pre>from weaviate.classes.config import Property, DataType, Configure\n\nif client.collections.exists(\"Article\"):\n    client.collections.delete(\"Article\")\n\nclient.collections.create(\n    \"Article\",\n    properties=[\n        Property(name=\"title\", data_type=DataType.TEXT),\n        Property(name=\"body\", data_type=DataType.TEXT, vectorize_property_name=True),\n        Property(name=\"date\", data_type=DataType.DATE)\n    ],\n    vectorizer_config=Configure.Vectorizer.text2vec_openai(\n        model=\"text-embedding-3-small\"\n    )\n)\n</pre> from weaviate.classes.config import Property, DataType, Configure  if client.collections.exists(\"Article\"):     client.collections.delete(\"Article\")  client.collections.create(     \"Article\",     properties=[         Property(name=\"title\", data_type=DataType.TEXT),         Property(name=\"body\", data_type=DataType.TEXT, vectorize_property_name=True),         Property(name=\"date\", data_type=DataType.DATE)     ],     vectorizer_config=Configure.Vectorizer.text2vec_openai(         model=\"text-embedding-3-small\"     ) ) Out[11]: <pre>&lt;weaviate.collections.collection.sync.Collection at 0x11e090f10&gt;</pre> <pre>{\"level\":\"warning\",\"msg\":\"prop len tracker file /Users/vishwasgowda/.local/share/weaviate/article/YIxrcKzy5u7i/proplengths does not exist, creating new tracker\",\"time\":\"2024-09-19T19:18:16+05:30\"}\n{\"action\":\"hnsw_prefill_cache_async\",\"level\":\"info\",\"msg\":\"not waiting for vector cache prefill, running in background\",\"time\":\"2024-09-19T19:18:16+05:30\",\"wait_for_cache_prefill\":false}\n{\"level\":\"info\",\"msg\":\"Created shard article_YIxrcKzy5u7i in 4.329167ms\",\"time\":\"2024-09-19T19:18:16+05:30\"}\n{\"action\":\"hnsw_vector_cache_prefill\",\"count\":1000,\"index_id\":\"main\",\"level\":\"info\",\"limit\":1000000000000,\"msg\":\"prefilled vector cache\",\"time\":\"2024-09-19T19:18:16+05:30\",\"took\":72833}\n</pre> In\u00a0[16]: Copied! <pre>article = client.collections.get(\"Article\")\n\nuuid = article.data.insert({\n    \"title\": \"Machine Learning\",\n    \"body\": \"Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning focuses on the development of computer programs that can access data and use it to learn for themselves.\",\n    \"date\": \"2021-10-01T00:00:00Z\",\n    \"category\": \"ML\"\n})\n\nuuid\n</pre> article = client.collections.get(\"Article\")  uuid = article.data.insert({     \"title\": \"Machine Learning\",     \"body\": \"Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning focuses on the development of computer programs that can access data and use it to learn for themselves.\",     \"date\": \"2021-10-01T00:00:00Z\",     \"category\": \"ML\" })  uuid Out[16]: <pre>UUID('497564c2-993c-4b5b-bb09-82e43517b9aa')</pre> In\u00a0[37]: Copied! <pre>from weaviate.classes.query import MetadataQuery\nimport textwrap\n\nresponse = article.query.near_text(\n    query=\"ai and ml\",\n    return_metadata=MetadataQuery(distance=True, certainty=True), # return distance and certainty metrics\n    include_vector=True # include the vector of the query\n)\n\n\ndef print_objects(objects):\n    \"\"\"\n        a function to print the retrieved objects\n    \"\"\"\n    for obj in objects:\n        print(f\"ID: {obj.uuid.int}\")\n        print(f\"Distance: {obj.metadata.distance}, Certainty: {obj.metadata.certainty}\")\n        print(f\"Title: {obj.properties['title']}\")\n        print(f\"Date: {obj.properties['date']}\")\n        print(f\"Category: {obj.properties['category']}\")\n        print(f\"Body: {textwrap.shorten(obj.properties['body'], width=100)}\")\n        print()\n\n\nprint_objects(response.objects)\n</pre> from weaviate.classes.query import MetadataQuery import textwrap  response = article.query.near_text(     query=\"ai and ml\",     return_metadata=MetadataQuery(distance=True, certainty=True), # return distance and certainty metrics     include_vector=True # include the vector of the query )   def print_objects(objects):     \"\"\"         a function to print the retrieved objects     \"\"\"     for obj in objects:         print(f\"ID: {obj.uuid.int}\")         print(f\"Distance: {obj.metadata.distance}, Certainty: {obj.metadata.certainty}\")         print(f\"Title: {obj.properties['title']}\")         print(f\"Date: {obj.properties['date']}\")         print(f\"Category: {obj.properties['category']}\")         print(f\"Body: {textwrap.shorten(obj.properties['body'], width=100)}\")         print()   print_objects(response.objects) <pre>ID: 97643186083395424410299917816510790058\nDistance: 0.576338529586792, Certainty: 0.711830735206604\nTitle: Machine Learning\nDate: 2021-10-01 00:00:00+00:00\nCategory: ML\nBody: Machine learning is a subset of artificial intelligence (AI) that provides systems the ability [...]\n\nID: 145885670213049490926508863968058307604\nDistance: 0.8108642101287842, Certainty: 0.5945678949356079\nTitle: Hello World\nDate: 2021-10-01 00:00:00+00:00\nCategory: general\nBody: This is the first article\n\n</pre> In\u00a0[40]: Copied! <pre>objects = article.query.fetch_object_by_id(response.objects[0].uuid)\nobjects.properties\n</pre> objects = article.query.fetch_object_by_id(response.objects[0].uuid) objects.properties Out[40]: <pre>{'title': 'Machine Learning',\n 'date': datetime.datetime(2021, 10, 1, 0, 0, tzinfo=datetime.timezone.utc),\n 'body': 'Machine learning is a subset of artificial intelligence (AI) that provides systems the ability to automatically learn and improve from experience without being explicitly programmed. Machine learning focuses on the development of computer programs that can access data and use it to learn for themselves.',\n 'category': 'ML'}</pre> In\u00a0[41]: Copied! <pre>article.data.update(\n    uuid=response.objects[1].uuid,\n    properties={\n        \"title\": \"Deep Learning\",\n        \"body\": \"Deep learning is a subset of machine learning that is based on artificial neural networks. The learning process is based on the structure of the human brain. Deep learning algorithms attempt to draw similar conclusions as humans would by continually analyzing data with a given logical structure.\",\n    }\n)\n</pre> article.data.update(     uuid=response.objects[1].uuid,     properties={         \"title\": \"Deep Learning\",         \"body\": \"Deep learning is a subset of machine learning that is based on artificial neural networks. The learning process is based on the structure of the human brain. Deep learning algorithms attempt to draw similar conclusions as humans would by continually analyzing data with a given logical structure.\",     } ) In\u00a0[43]: Copied! <pre>object = article.query.fetch_object_by_id(response.objects[1].uuid)\nobject.properties\n</pre> object = article.query.fetch_object_by_id(response.objects[1].uuid) object.properties Out[43]: <pre>{'title': 'Deep Learning',\n 'date': datetime.datetime(2021, 10, 1, 0, 0, tzinfo=datetime.timezone.utc),\n 'body': 'Deep learning is a subset of machine learning that is based on artificial neural networks. The learning process is based on the structure of the human brain. Deep learning algorithms attempt to draw similar conclusions as humans would by continually analyzing data with a given logical structure.',\n 'category': 'general'}</pre> In\u00a0[46]: Copied! <pre>article.data.delete_by_id(uuid=response.objects[1].uuid)\n\nobject = article.query.fetch_object_by_id(response.objects[1].uuid)\nobject\n</pre> article.data.delete_by_id(uuid=response.objects[1].uuid)  object = article.query.fetch_object_by_id(response.objects[1].uuid) object <pre>{\"action\":\"tombstone_cleanup_begin\",\"class\":\"Article\",\"level\":\"info\",\"msg\":\"class Article: shard YIxrcKzy5u7i: starting tombstone cleanup\",\"shard\":\"YIxrcKzy5u7i\",\"time\":\"2024-09-19T20:18:16+05:30\",\"tombstones_in_cycle\":2,\"tombstones_total\":2}\n{\"action\":\"tombstone_cleanup_complete\",\"class\":\"Article\",\"duration\":4504834,\"level\":\"info\",\"msg\":\"class Article: shard YIxrcKzy5u7i: completed tombstone cleanup in 4.504834ms\",\"shard\":\"YIxrcKzy5u7i\",\"time\":\"2024-09-19T20:18:16+05:30\",\"tombstones_in_cycle\":2,\"tombstones_total\":2}\n</pre>"},{"location":"module-3/vector-embeddings/vector_dbs/#vector-databases","title":"Vector Databases\u00b6","text":""},{"location":"module-3/vector-embeddings/vector_dbs/#what-is-a-vector-database","title":"What is a Vector Database?\u00b6","text":"<p>A vector database is a specialized database designed to store and retrieve data in the form of vectors. These vectors are numerical representations of objects such as text, images, or products, allowing us to find similar objects based on different similarity measures. In simple terms, instead of exact matches (like traditional databases), vector databases focus on finding similar things. For example, if you search for a product, the database returns items similar to it, like products with related features or uses.</p>"},{"location":"module-3/vector-embeddings/vector_dbs/#how-ann-approximate-nearest-neighbors-and-hnsw-hierarchical-navigable-small-world-work","title":"How ANN (Approximate Nearest Neighbors) and HNSW (Hierarchical Navigable Small World) Work\u00b6","text":""},{"location":"module-3/vector-embeddings/vector_dbs/#approximate-nearest-neighbors-ann","title":"Approximate Nearest Neighbors (ANN)\u00b6","text":"<p>When dealing with high-dimensional vectors (like text embeddings or image embeddings), finding exact matches between vectors can be computationally expensive and slow. Instead of searching for exact nearest neighbors, ANN focuses on finding approximately similar vectors quickly. ANN is a technique where you sacrifice a little bit of accuracy to gain a lot of speed.</p> <p>In real-world applications, this trade-off is usually acceptable because most of the time, an approximate match is good enough. For example, when you're searching for similar products or images, the system doesn\u2019t need to find the perfect match but just one that\u2019s close enough.</p>"},{"location":"module-3/vector-embeddings/vector_dbs/#hierarchical-navigable-small-world-hnsw","title":"Hierarchical Navigable Small World (HNSW)\u00b6","text":"<p>HNSW is one of the most popular algorithms used for fast ANN searches. Here\u2019s a breakdown of how it works:</p> <ol> <li><p>Building a Graph: HNSW creates a graph structure where each point (vector) is connected to a few other vectors. These connections are made in such a way that the graph resembles a \"small-world network,\" meaning it\u2019s easy to travel from one point to another in a short number of steps.</p> </li> <li><p>Hierarchy of Layers: The graph is divided into several layers. The top layer contains fewer points and connections, while the bottom layer has more. Think of it like a multi-level building. The higher you are in the building, the fewer connections you need to navigate between rooms, and as you go lower, the number of rooms and connections increases. When you search for a vector, you start at the top and move down layer by layer, getting closer to the nearest neighbor.</p> </li> <li><p>Navigating the Graph: When a query vector comes in, HNSW starts by searching in the top layer and moves downward. At each layer, it looks for the most similar vectors based on the distance between them. As it moves through the layers, the search becomes more precise, and it narrows down to the closest vectors in the final layer. The process is fast because it reduces the search space in each layer.</p> </li> <li><p>Efficiency Gains: By organizing the graph in layers and connecting each vector only to a small number of other vectors, HNSW makes the search process quick and efficient, even in very large datasets.</p> </li> </ol>"},{"location":"module-3/vector-embeddings/vector_dbs/#diagram-of-hnsw-process","title":"Diagram of HNSW Process\u00b6","text":""},{"location":"module-3/vector-embeddings/vector_dbs/#using-vector-databases","title":"Using Vector Databases\u00b6","text":"<p>There are many options available for vector databases, both commercial and open-source. Throughout the course we will be using Weaviate as our vector database. Weaviate is an open-source, cloud-native vector database that allows you to store, search, and rank vectors. It pretty much ticks all the boxes for what we need in a vector database.</p>"},{"location":"module-3/vector-embeddings/vector_dbs/#using-weaviate","title":"Using Weaviate\u00b6","text":"<p>There are mainly many ways to install and use Weaviate. You can use it through Docker, or use their serverless cloud instance, or even through cloud marketplaces like AWS, Azure, and Google Cloud. But for now we will use Embedded Weaviate which is quite easy to setup and good enough for experimentation purposes.</p>"},{"location":"module-3/vector-embeddings/vector_dbs/#getting-started-with-weaviate","title":"Getting Started with Weaviate\u00b6","text":""},{"location":"module-3/vector-embeddings/vector_dbs/#collections","title":"Collections\u00b6","text":"<p>A collection is a group of objects that share the same properties. For example a collection named Article will contain all the articles in your database. Each object in a collection is represented as a vector. Similarly another named Author contains all the authors in your database.</p>"},{"location":"module-3/vector-embeddings/vector_dbs/#create-objects","title":"Create Objects\u00b6","text":"<p>Currently, we are not manually handling the creation of vectors for the . Instead, the Weaviate client is going to handle that for us.</p>"},{"location":"module-3/vector-embeddings/vector_dbs/#query-objects-using-similarity-search","title":"Query Objects Using Similarity Search\u00b6","text":"<p>Weaviate uses distance metrics to provide the similarity between vectors. We can use distance metrics to understand how similar two vectors are while still using cosine similarity under the hood using the below formula:</p> <p>$$ distance = 1 - cosine\\_similarity(a, b) $$</p> <p>The distance metric is a value between 0 and 2, where 0 means the vectors are identical, and 2 means they are completely different.</p> <p>Incase you want to use other distance metrics such as dot product, euclidean distance, etc. you can refer to the this doc page understand how you can use them.</p> <p>This doc contains all the distance metrics that weaviate supports.</p>"},{"location":"module-3/vector-embeddings/vector_dbs/#read-objects","title":"Read Objects\u00b6","text":""},{"location":"module-3/vector-embeddings/vector_dbs/#update-objects","title":"Update Objects\u00b6","text":""},{"location":"module-3/vector-embeddings/vector_dbs/#delete-object","title":"Delete Object\u00b6","text":""}]}